{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a5e96e",
   "metadata": {},
   "source": [
    "# Genes\n",
    "The following notebook retrieves all the genes involved in the reactions from the **\"Rxns\" Sheet** in Google Sheet file. Then, information regarding the genes is retrieved from different databases and a **\"Genes\" Sheet** is generated and updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08228a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from google_sheet import GoogleSheet\n",
    "from utils import get_gene_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac38d2d7",
   "metadata": {},
   "source": [
    "### 1. Generate \"rxns\" and \"genes\" datasets\n",
    "The \"rxns\" dataset contains all the reactions with their GPR associations. The \"genes\" dataset contains all the information of the genes/GPR involved in our reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d8026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_FILE_PATH = 'credentials.json'\n",
    "SPREADSHEET_ID = '1MlBXeHIKw8k8fZyXm-sN__AHTRSunJxar_-bqvukZws'\n",
    "\n",
    "# Initialize the GoogleSheet object\n",
    "sheet = GoogleSheet(SPREADSHEET_ID, KEY_FILE_PATH)\n",
    "\n",
    "# Read data from the Google Sheet\n",
    "sheet_rxns = 'Rxns'\n",
    "sheet_genes = 'Genes'\n",
    "\n",
    "rxns = sheet.read_google_sheet(sheet_rxns)\n",
    "genes = sheet.read_google_sheet(sheet_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de13c811",
   "metadata": {},
   "source": [
    "### 2. Create the a \"gene_list\" with all the genes involved in our reconstruction\n",
    "We extract the gene IDs from the GPR annotations in the **\"rxns\" df**. This information is only retrieved from the **GPR_final** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f61d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3045"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generation of gene_list from all the genes in the \"Whole Cell Network Reconstruction in CHO Cells\" dataset\n",
    "import re\n",
    "\n",
    "gene_list = []\n",
    "human_gene_list = []\n",
    "for index, row in rxns.iterrows():\n",
    "    if row['GPR_final'] != '':\n",
    "        gprs = str(row['GPR_final'])\n",
    "        gpr = re.findall(r'\\b[hH]?\\d+\\b', gprs)\n",
    "        for g in gpr:\n",
    "            if g.lower().startswith('h'):  # we convert to lower case to catch both 'h' and 'H'\n",
    "                human_gene_list.append(int(g[1:]))  # remove 'h' and convert to int before appending\n",
    "            else:\n",
    "                gene_list.append(int(g))  # convert to int before appending\n",
    "\n",
    "gene_list = list(set(gene_list))\n",
    "len(gene_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c5c853",
   "metadata": {},
   "source": [
    "### 3. Replace remaining Human Gene IDs in our dataset with CHO Gene IDs\n",
    "Using the **cho2human_mapping** file, we replace the Human gene IDs with those of CHO, these IDs were not spotted when we first added the Recon3D reactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd3c0d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a dictionary with human gene IDs as keys and CHO gene IDs as values\n",
    "orthologs = pd.read_csv('../Data/Orthologs/cho2human_mapping.tsv', sep='\\t')\n",
    "human_to_cho_dict = dict(zip(orthologs['HUMAN_ID'], orthologs['CHO_ID']))\n",
    "\n",
    "def replace_human_ids_with_cho_ids(s):\n",
    "    replaced_dict = {}\n",
    "    if isinstance(s, str):\n",
    "        genes = re.findall(r'\\b[hH]?\\d+\\b', s)\n",
    "        for gene in genes:\n",
    "            if gene.lower().startswith('h'):  # if gene ID starts with 'h' or 'H'\n",
    "                human_id = int(gene[1:])  # remove 'h' and convert to int\n",
    "                if human_id in human_to_cho_dict:  # if human gene ID is in the dictionary\n",
    "                    cho_id = human_to_cho_dict[human_id]  # get corresponding CHO gene ID\n",
    "                    s = s.replace(gene, str(cho_id))  # replace human gene ID with CHO gene ID in the string\n",
    "                    replaced_dict[gene] = cho_id\n",
    "    return s, replaced_dict\n",
    "\n",
    "# Initialize a dictionary to store replacements\n",
    "replacements = {}\n",
    "\n",
    "# Apply the function and update the replacements dictionary\n",
    "for i in range(len(rxns)):\n",
    "    rxns.at[i, 'GPR_final'], replacements_dict = replace_human_ids_with_cho_ids(rxns.at[i, 'GPR_final'])\n",
    "    replacements.update(replacements_dict)\n",
    "\n",
    "# Now, 'replacements' is a dictionary where keys are the original gene IDs and values are the replaced CHO gene IDs\n",
    "replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc309360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No changes to the original Rxns Sheet\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "#### ---------------------------- ####\n",
    "#### ---- Update Rxns Sheet ----- ####\n",
    "#### ---------------------------- ####\n",
    "######################################\n",
    "if replacements:\n",
    "    sheet.update_google_sheet(sheet_rxns, rxns)\n",
    "    print(\"Google Sheet updated.\")\n",
    "elif not replacements:\n",
    "    print(\"No changes to the original Rxns Sheet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed00e36d",
   "metadata": {},
   "source": [
    "### 3. Add the genes from the \"gene_list\" to the genes df\n",
    "Using a list of all the genes included in the dataset we can retrieve information from the NIH database regarding Gene Symbol, Gene Name, Gene Ensembl ID, and mRNA ID and protein ID using the function get_gene_info()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "236d1799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55622e982a4a4132a248114e9e6ca772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3045 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30100754813\n",
      "Gene 30100754813 does not have PICR Ensembl ID\n",
      "Gene (30100754813, 'ycf15') is a Vitis cinerea Gene\n",
      "A total of 0 Genes were added to the dataset\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from urllib.error import HTTPError\n",
    "from Bio.Entrez.Parser import ValidationError\n",
    "\n",
    "max_retries = 5  # Set the maximum number of retries\n",
    "c = 0\n",
    "\n",
    "for g in tqdm(gene_list):\n",
    "    if str(g) not in list(genes['Gene Entrez ID']):\n",
    "        retry = True\n",
    "        retries = 0\n",
    "        while retry:\n",
    "            try:\n",
    "                print(g)\n",
    "                organism, gene_symbol, gene_name, gene_description, picr_ensembl_id, chok1gs_ensembl_id, mRNA_ncbi_id, protein_ncbi_id, go_terms = get_gene_info(g)\n",
    "                if organism == 'Cricetulus griseus':\n",
    "                    new_row_data = {'Gene Entrez ID': g, 'Gene Symbol': gene_symbol, 'Gene Name': gene_name, 'Gene Description': gene_description,\n",
    "                                    'PICR Ensembl ID': picr_ensembl_id, 'CHOK1GS Ensembl ID': chok1gs_ensembl_id, 'Transcript ID': mRNA_ncbi_id,\n",
    "                                    'Protein ID': protein_ncbi_id, 'GO Terms': go_terms}\n",
    "                    new_row_df = pd.DataFrame(new_row_data, index=[len(genes)])\n",
    "                    genes = pd.concat([genes, new_row_df])\n",
    "                    c+=1\n",
    "                    retry = False\n",
    "                elif organism != 'Cricetulus griseus':\n",
    "                    print(f'Gene {g,gene_symbol} is a {organism} Gene')\n",
    "                    break\n",
    "            except ValidationError:\n",
    "                print(f'Gene {g} not found')\n",
    "                retry = False\n",
    "                continue\n",
    "            except HTTPError:\n",
    "                retries += 1\n",
    "                if retries > max_retries:\n",
    "                    print(f'HTTP Error, reached maximum retries ({max_retries}) for gene {g}')\n",
    "                    break\n",
    "                else:\n",
    "                    print(f'HTTP Error, retrying with gene {g}')\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "print(f'A total of {c} Genes were added to the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2abe8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new genes added.\n",
      "No changes to the original Genes Sheet.\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "#### ----------------------------- ####\n",
    "#### ---- Update Genes Sheet ----- ####\n",
    "#### ----------------------------- ####\n",
    "#######################################\n",
    "if c > 0:\n",
    "    sheet.update_google_sheet(sheet_genes, genes)\n",
    "    print(\"Google Sheet updated.\")\n",
    "elif c == 0:\n",
    "    print(\"No new genes added.\")\n",
    "    print(\"No changes to the original Genes Sheet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2218925",
   "metadata": {},
   "source": [
    "### 4. Eliminate unwanted genes\n",
    "We iterate over the entire dataset to spot **Human genes** in order to eliminate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b810d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the DataFrame to avoid changing the original while iterating\n",
    "erased = 0\n",
    "genes_copy = genes.copy()\n",
    "\n",
    "for index, row in tqdm(genes.iterrows(), total=genes.shape[0]):\n",
    "    g = row['Gene Entrez ID']\n",
    "    retry = True\n",
    "    retries = 0\n",
    "    while retry:\n",
    "        try:\n",
    "            organism, gene_symbol, gene_name, gene_description, picr_ensembl_id, chok1gs_ensembl_id, mRNA_ncbi_id, protein_ncbi_id, go_terms = get_gene_info(g)\n",
    "            if organism == 'Homo sapiens':\n",
    "                genes_copy = genes_copy.drop(index)\n",
    "                print(f'Gene {g,gene_symbol} erased from dataset')\n",
    "                erased+=1\n",
    "                retry = False\n",
    "            else:\n",
    "                retry = False\n",
    "        except ValidationError:\n",
    "            print(f'Gene {g} not found')\n",
    "            retry = False\n",
    "            continue\n",
    "        except HTTPError:\n",
    "            retries += 1\n",
    "            if retries > max_retries:\n",
    "                print(f'HTTP Error, reached maximum retries ({max_retries}) for gene {g}')\n",
    "                break\n",
    "            else:\n",
    "                print(f'HTTP Error, retrying with gene {g}')\n",
    "                time.sleep(1)\n",
    "\n",
    "# Replace the original DataFrame with the updated one\n",
    "genes = genes_copy\n",
    "print(f'A total of {erased} Genes were erased from the original dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a459ea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "#### ----------------------------- ####\n",
    "#### ---- Update Genes Sheet ----- ####\n",
    "#### ----------------------------- ####\n",
    "#######################################\n",
    "if erased > 0:\n",
    "    sheet.update_google_sheet(sheet_genes, genes)\n",
    "    print(\"Google Sheet updated.\")\n",
    "elif erased == 0:\n",
    "    print(\"No erased genes.\")\n",
    "    print(\"No changes to the original Genes Sheet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3b506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in tqdm(gene_list):\n",
    "    if g not in list(genes['Gene Entrez ID']):\n",
    "        try:\n",
    "            gene_symbol, gene_name, gene_description, picr_ensembl_id, chok1gs_ensembl_id, mRNA_ncbi_id, protein_ncbi_id, go_terms = get_gene_info(g)\n",
    "            new_row_data = {'Gene Entrez ID': g, 'Gene Symbol': gene_symbol, 'Gene Name': gene_name, 'Gene Description': gene_description,\n",
    "                            'PICR Ensembl ID': picr_ensembl_id, 'CHOK1GS Ensembl ID': chok1gs_ensembl_id, 'Transcript ID': mRNA_ncbi_id,\n",
    "                            'Protein ID': protein_ncbi_id, 'GO Terms': go_terms}\n",
    "            new_row_df = pd.DataFrame(new_row_data, index=[len(genes)])\n",
    "            genes = pd.concat([genes, new_row_df])\n",
    "        except KeyError:\n",
    "            print(f'Gene {g} not found')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfcbfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch information from the NIH database\n",
    "\n",
    "\n",
    "# Complete null or blank information in the already generated \"Genes Sheet\" dataset\n",
    "for i,row in genes.iterrows():\n",
    "    if row['Gene Entrez ID'] == '':\n",
    "        for g in gene_list:\n",
    "            gene_sheet_list = [str(x) for x in genes['Gene Entrez ID']]\n",
    "            if g not in gene_sheet_list:\n",
    "                gene_symbol, gene_name, gene_description, picr_ensembl_id, chok1gs_ensembl_id, mRNA_ncbi_id, protein_ncbi_id, go_terms = get_gene_info(g)\n",
    "                row['Gene Entrez ID'] = g\n",
    "                row['Gene Symbol'] = gene_symbol\n",
    "                row['Gene Name'] = gene_name\n",
    "                row['Gene Description'] = gene_description\n",
    "                row['PICR Ensembl ID'] = picr_ensembl_id\n",
    "                row['CHOK1GS Ensembl ID'] = chok1gs_ensembl_id\n",
    "                row['Transcript ID'] = mRNA_ncbi_id\n",
    "                row['Protein ID'] = protein_ncbi_id\n",
    "                row['GO Terms'] = go_terms\n",
    "                break          \n",
    "    elif row['Gene Entrez ID'] != '' and (row['Gene Symbol'] == '' or row['Gene Name'] == '' or row['PICR Ensembl ID'] == '' or row['Transcript ID'] == '' or row['Protein ID'] == ''):\n",
    "        row['Gene Symbol'] = gene_symbol\n",
    "        row['Gene Name'] = gene_name\n",
    "        row['Gene Description'] = gene_description\n",
    "        row['PICR Ensembl ID'] = picr_ensembl_id\n",
    "        row['CHOK1GS Ensembl ID'] = chok1gs_ensembl_id\n",
    "        row['Transcript ID'] = mRNA_ncbi_id\n",
    "        row['Protein ID'] = protein_ncbi_id\n",
    "        row['GO Terms'] = go_terms\n",
    "'''\n",
    "# Add genes from the gene_list that are not yet in the \"Genes Sheet\" dataset\n",
    "for g in gene_list:\n",
    "    # the first try/except is to avoid overwritting data in case there already some info in the dataset\n",
    "    try:\n",
    "        gene_sheet_list = [str(x) for x in df['Gene Entrez ID']]\n",
    "        id = max(df['Index']) + 2\n",
    "    except:\n",
    "        gene_sheet_list = []\n",
    "        id = 2\n",
    "    if gene not in gene_sheet_list:\n",
    "        try:\n",
    "            gene_symbol, gene_name, gene_description, picr_ensembl_id, chok1gs_ensembl_id, mRNA_ncbi_id, protein_ncbi_id, go_terms = get_gene_info(gene)\n",
    "            print(id-1)\n",
    "            genes_sheet.update_cell(id,1,id-1)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,2,gene)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,3,gene_symbol)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,4,gene_name)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,5,gene_description)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,6,picr_ensembl_id)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,7,chok1gs_ensembl_id)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,8,mRNA_ncbi_id)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,9,protein_ncbi_id)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,10,go_terms)\n",
    "        except:\n",
    "            print('Google API quota exceeded')\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "            \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f702b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73daf8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gene_info('100750772')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b59d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "Entrez.email = 'account1@theta-ocean-377718.iam.gserviceaccount.com'\n",
    "handle = Entrez.efetch(db='gene', id='3979190', retmode='xml')\n",
    "record = Entrez.read(handle)[0]\n",
    "\n",
    "#gene_name = record['Entrezgene_gene']['Gene-ref']['Gene-ref_desc']\n",
    "#gene_symbol = record['Entrezgene_gene']['Gene-ref']['Gene-ref_locus']\n",
    "\n",
    "human_handle = Entrez.efetch(db='gene', id='3979190', retmode='xml')\n",
    "human_record = Entrez.read(human_handle)[0]\n",
    "if 'Entrezgene_comments' in human_record and 'Gene-commentary_comment' in human_record['Entrezgene_comments'][0]:\n",
    "    human_gene_description = human_record['Entrezgene_comments'][0]['Gene-commentary_comment'][0]['String']\n",
    "elif 'Entrezgene_summary' in human_record:\n",
    "    human_gene_description = human_record['Entrezgene_summary']\n",
    "else:\n",
    "    human_gene_description = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d44cdb",
   "metadata": {},
   "source": [
    "#### Get the CHO genome and map the IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e34657fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Tmpo 100759640 XP_027297290 115343 9 ['A0A8C2MJ65', 'A0A8C2MR44', 'A0A8C2MIA7', 'A0A8C2MR44', 'A0A061IGN9', 'A0A8C2MR44', 'A0A8C2MIJ5', 'A0A8C2MJ65', 'A0A8C2MR44', 'A0A8C2MIA7', 'A0A8C2MR44', 'A0A061IGN9', 'A0A8C2MR44', 'A0A8C2MIJ5'] ['7112', '21917', '207151', '507284'] ['human', 'mouse', 'C86562', 'Tmpo']\n",
      "1 Mtmr11 100759793 XP_003498681 1258620 17 ['A0A061IIN7', 'A0A9J7J5B9', 'A0A061IIN7', 'A0A9J7J5B9'] ['10903', '194126'] ['human', 'mouse']\n",
      "2 Ip6k2 100759816 XP_003504281 25049 7 ['A0A8C2LDB9', 'A0A3L7HPE7', 'A0A8C2LDB9', 'A0A3L7HPE7'] ['51447', '76500'] ['human', 'mouse']\n",
      "3 Abhd17c 100759841 XP_003511747 285934 3 ['A0A8C2M4H6', 'A0A8C2M4H6'] ['58489', '70178'] ['human', 'mouse']\n",
      "4 Anxa2 100760539 XP_003513709 121574 9 ['A0A8C2QG32', 'A0A8C2QG32'] ['302', '12306', '1624282'] ['human', 'mouse', 'BioGRID']\n",
      "5 Impdh1 100760550 XP_035297305 1376992 13 ['A0A8C2LEI0', 'A0A9J7EZ82', 'A0A8C2LEI0', 'A0A9J7F4T8', 'A0A8C2LEI0', 'A0A9J7EZ82'] ['3614', '23917'] ['human', 'mouse']\n",
      "6 Ncor1 100760832 XP_007647518 1933786 45 ['A0A8C2LWE2', 'A0A8C2LWE2', 'A0A9J7GCS7', 'A0A8C2LWE2', 'A0A9J7GCT0', 'A0A8C2LWE2', 'A0A9J7GDW8', 'A0A8C2LWE2', 'A0A9J7GDV6', 'A0A8C2LWE2', 'A0A9J7GDY4', 'A0A8C2LWE2', 'A0A9J7JXG3', 'A0A8C2LWE2', 'A0A9J7GFN8', 'A0A8C2LWE2', 'A0A9J7GIE5', 'A0A8C2LWE2', 'A0A9J7GFN5', 'A0A8C2LWE2', 'A0A9J7JZ29', 'A0A8C2LWE2', 'A0A9J7GHD3', 'A0A8C2LWE2', 'A0A9J7JPT3', 'A0A8C2LWE2', 'A0A9J7KB76', 'A0A8C2LWE2', 'A0A9J7JZ14', 'A0A8C2LWE2', 'A0A9J7GID2', 'A0A8C2LWE2', 'A0A9J7GCR8', 'A0A8C2LWE2', 'A0A9J7GHE4', 'A0A8C2LWE2', 'A0A9J7GDV7', 'A0A8C2LWE2', 'A0A9J7GD97', 'A0A8C2LWE2', 'A0A9J7JPT8', 'A0A8C2LWE2', 'A0A9J7JXF7', 'A0A8C2LWE2', 'A0A9J7JVP4', 'A0A8C2LWE2', 'A0A9J7H091', 'A0A8C2LWE2', 'A0A9J7GCR6', 'A0A8C2LWE2', 'A0A9J7JZ06', 'A0A8C2LWE2', 'A0A9J7GDU7', 'A0A8C2LWE2', 'A0A9J7JZ35', 'A0A8C2LWE2', 'A0A9J7H599', 'A0A8C2LWE2', 'A0A9J7H1H8', 'A0A8C2LWE2', 'A0A9J7GFM0', 'A0A8C2LWE2', 'A0A9J7H294', 'A0A8C2LWE2', 'A0A9J7GDU6', 'A0A8C2LWE2', 'A0A9J7GFP9', 'A0A8C2LUB6'] ['9611', '20185'] ['human', 'mouse']\n",
      "7 Tpm4 100761146 XP_003499135 2394949 12 ['A0A061IQ68', 'A0A9J7JAZ6', 'A0A9J7F541', 'A0A061IQ68', 'A0A9J7JAZ6', 'A0A9J7F541', 'A0A8C2QIX5'] ['7171', '326618'] ['human', 'mouse']\n",
      "8 Rab34 100761520 XP_007652219 89008 11 ['A0A9J7K0Q7', 'G3IGH9', 'A0A9J7K0Q7', 'G3IGH9'] ['83871', '19376', '1625263'] ['human', 'mouse', 'BioGRID']\n",
      "9 Apeh 100761732 XP_003500396 1761728 22 ['G3H8F2', 'G3H8F2'] ['327', '235606'] ['human', 'mouse']\n",
      "10 Supt5h 100761749 XP_035312677 1300070 29 ['A0A8C2M4V7', 'A0A8C2M4V7', 'A0A9J7GLD6', 'A0A8C2M4V7', 'A0A9J7GLD6'] ['6829', '20924', '146961'] ['human', 'mouse', 'D19S190']\n",
      "11 Cnot1 100761778 XP_027297348 343858 49 ['A0A061I9G1', 'A0A8C2MEC7', 'A0A8C2MEC7', 'A0A8C2MEC7', 'A0A061I9G1', 'A0A8C2M8W4', 'A0A061I9G1', 'A0A061I9G1', 'A0A061I9G1', 'A0A061I9G1', 'A0A9J7JIL0', 'A0A061IE12', 'A0A8C2MEC7', 'A0A8C2MEC7', 'A0A9J7GSN7', 'A0A8C2MEC7', 'A0A9J7FP35', 'A0A061I9G1', 'A0A061ID33', 'A0A061I9G1', 'A0A061IG75', 'A0A061I9G1', 'A0A9J7FJC2', 'A0A061I9G1', 'A0A9J7FKI3'] ['23019', '234594', '547198'] ['human', 'mouse', 'Cnot1']\n",
      "12 Copa 100762124 XP_003500327 585647 33 ['G3H7Y0', 'G3H7Y0'] ['1314', '12847', '1625867', '141376'] ['human', 'mouse', 'BioGRID', 'Copa']\n",
      "13 Immt 100762629 XP_007642636 1292799 15 ['A0A9J7JX72', 'G3HJK8', 'A0A9J7GGW2', 'G3HJK8', 'A0A9J7JR25', 'G3HJK8', 'A0A9J7GG24', 'G3HJK8', 'A0A9J7GGW7', 'G3HJK8', 'A0A8C2M207', 'G3HJK8', 'A0A9J7GFM3', 'G3HJK8', 'A0A8C2M331', 'G3HJK8', 'A0A9J7K0H5', 'G3HJK8', 'A0A9J7JYY5', 'G3HJK8', 'A0A9J7GGU9', 'G3HJK8', 'A0A9J7GFM6', 'G3HJK8', 'A0A8C2M2U8', 'G3HJK8', 'A0A9J7GIM7', 'G3HJK8', 'A0A9J7GIL0', 'G3HJK8', 'A0A9J7JX72', 'G3HJK8', 'A0A9J7GGW2', 'G3HJK8', 'A0A9J7JR25', 'G3HJK8', 'A0A9J7GG24', 'G3HJK8', 'A0A9J7GGW7', 'G3HJK8', 'A0A8C2M207', 'G3HJK8', 'A0A9J7GFM3', 'G3HJK8', 'A0A8C2M331', 'G3HJK8', 'A0A9J7K0H5', 'G3HJK8', 'A0A9J7JYY5', 'G3HJK8', 'A0A9J7GGU9', 'G3HJK8', 'A0A9J7GFM6', 'G3HJK8', 'A0A8C2M2U8', 'G3HJK8', 'A0A9J7GIM7', 'G3HJK8', 'A0A9J7GIL0', 'G3HJK8'] ['10989', '76614', '194429'] ['human', 'mouse', 'fc74f02.x1']\n",
      "14 Kpnb1 100762896 XP_007638520 988713 20 ['A0A8C2MAC8', 'A0A8C2MAC8'] ['3837', '16211', '79462', '225255'] ['human', 'mouse', 'STS-H47054', 'UniSTS:225255']\n",
      "15 Nap1l1 100763316 XP_003506630 904765 14 ['A0A8C2MME2', 'A0A9J7F5X8', 'A0A8C2MME2', 'A0A9J7F5Z9', 'A0A8C2MME2', 'A0A9J7F5X8', 'A0A8C2MME2', 'A0A9J7F5X8', 'A0A8C2MME2', 'A0A9J7F0U5'] ['4673', '53605'] ['human', 'mouse']\n",
      "16 Ptcd3 100763681 XP_003503944 1336685 24 ['A0A8C2LV87', 'A0A8C2LV87'] ['55037', '69956'] ['human', 'mouse']\n",
      "17 Psip1 100763870 XP_003501745 1703533 15 ['A0A061IJB5', 'G3HCB0', 'A0A061IJB5', 'G3HCB0', 'A0A8C2QKG4', 'A0A8C2MI53', 'A0A9J7FBG5'] ['11168', '101739'] ['human', 'mouse']\n",
      "18 Ddb1 100764133 XP_007652670 42700 28 ['A0A8C2MEY8', 'A0A9J7FL88', 'A0A8C2MEY8', 'G3II69', 'A0A8C2MEY8', 'A0A9J7FL88', 'A0A8C2MEY8', 'G3II69'] ['1642', '13194', '212233'] ['human', 'mouse', 'RH128925']\n",
      "19 Ddx3x 100764307 XP_003495414 3264801 17 ['A0A061HXV1', 'G3GSH5', 'A0A061HXV1', 'A0A9J7GLX5', 'A0A061HXV1', 'G3GSH5', 'A0A061HXV1', 'A0A9J7GLX5'] ['1654', '13205', '278276', '125746', '266902', '109215', '124886', '506840', '211163'] ['human', 'mouse', 'DDX3', 'U42386', 'DBX', 'G49473', 'L25126', 'Ddx3x', 'RH127853']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "import math\n",
    "import time\n",
    "import ssl\n",
    "from urllib.error import HTTPError\n",
    "import socket\n",
    "from Bio.Entrez.Parser import CorruptedXMLError\n",
    "\n",
    "def get_uniprot_from_dict(dictionary, uniprotIDs, target_key, target_value1,  target_value2):\n",
    "    for key, value in dictionary.items():\n",
    "        if key == target_key and (value == target_value1 or value == target_value2):\n",
    "            uniprotIDs.append(dictionary.get('Dbtag_tag', {}).get('Object-id', {}).get('Object-id_str'))            \n",
    "        if isinstance(value, dict):\n",
    "            get_uniprot_from_dict(value, uniprotIDs, target_key, target_value1, target_value2)\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, dict):\n",
    "                    get_uniprot_from_dict(item, uniprotIDs, target_key, target_value1, target_value2)        \n",
    "    return uniprotIDs\n",
    "def get_human_mouse_orthologs(dictionary, orthologs, target_key, target_value1):\n",
    "    for key, value in dictionary.items():\n",
    "        if key == target_key and (value == target_value1):\n",
    "            orthologs.append(dictionary.get('Dbtag_tag', {}).get('Object-id', {}).get('Object-id_id'))        \n",
    "        if isinstance(value, dict):\n",
    "            get_human_mouse_orthologs(value, orthologs, target_key, target_value1)\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, dict):\n",
    "                    get_human_mouse_orthologs(item, orthologs, target_key, target_value1)        \n",
    "    return orthologs\n",
    "    \n",
    "\n",
    "                    \n",
    "Entrez.email = \"athand01@gmail.com\"\n",
    "\n",
    "u_g = pd.read_excel('../CHO_Genome.xlsx')\n",
    "\n",
    "ncbi_geneName_list = []\n",
    "ncbi_protein_NP_weirdName = []\n",
    "ncbi_geneID_list = []\n",
    "ncbi_gene_exon_size = []\n",
    "ncbi_genomic_location = []\n",
    "uniprot_IDs = []\n",
    "orthologs_genes = []\n",
    "orthologs_organism = []\n",
    "counter = 0\n",
    "for ncbi_gene in u_g['NCBI GeneID'][500:520]:\n",
    "\n",
    "    protein_NP_weirdName = []\n",
    "    if not math.isnan(ncbi_gene):   \n",
    "        ncbi_gene = int(ncbi_gene)                  \n",
    "        max_retries = 3\n",
    "        retries = 0\n",
    "        gene_found = True\n",
    "        while retries < max_retries and gene_found:\n",
    "\n",
    "            try:\n",
    "\n",
    "                search_results = Entrez.esearch(db=\"gene\", term=ncbi_gene)            \n",
    "                record = Entrez.read(search_results)\n",
    "\n",
    "                # Check if any gene records were found\n",
    "                if int(record[\"Count\"]) > 0:\n",
    "\n",
    "                    # Get the Gene ID of the first result\n",
    "                    gene_id = record[\"IdList\"][0]\n",
    "\n",
    "                    # Fetch the gene information, maximum 3 tries\n",
    "                    fetch_tries = 0\n",
    "                    fetch_found = True\n",
    "                    while fetch_tries < 3 and fetch_found:\n",
    "\n",
    "                        gene_info = Entrez.efetch(db=\"gene\", id=gene_id, retmode=\"xml\")           \n",
    "                        fetch_tries += 1\n",
    "                        try:\n",
    "                            gene_record = Entrez.read(gene_info)\n",
    "                            fetch_found = False\n",
    "                        except CorruptedXMLError as xml_error:\n",
    "                            time.sleep(3)\n",
    "                            fetch_tries += 1\n",
    "\n",
    "                    # Get the gene name and gene NCBI ID\n",
    "                    gene_name = gene_record[0]['Entrezgene_gene']['Gene-ref']['Gene-ref_locus']\n",
    "                    gene_ncbiID = gene_record[0]['Entrezgene_track-info']['Gene-track']['Gene-track_geneid']\n",
    "\n",
    "                    # Get UniprotIDs\n",
    "                    gene_uniprotIDs = (get_uniprot_from_dict(gene_record[0], [], 'Dbtag_db', 'UniProtKB/TrEMBL', 'UniProtKB/Swiss-Prot'))\n",
    "\n",
    "                    # Get the location in the genome\n",
    "                    locus = gene_record[0].get('Entrezgene_locus', {})\n",
    "                    start = locus[0]['Gene-commentary_seqs'][0]['Seq-loc_int']['Seq-interval']['Seq-interval_from']\n",
    "                    end = locus[0]['Gene-commentary_seqs'][0]['Seq-loc_int']['Seq-interval']['Seq-interval_to']\n",
    "                    gene_location = start\n",
    "\n",
    "                    # Get number of Exons\n",
    "                    properties = gene_record[0]['Entrezgene_properties']\n",
    "                    exon = None\n",
    "                    for prop in properties:\n",
    "                        if prop['Gene-commentary_label'] == 'Exon count':\n",
    "                            exon = prop['Gene-commentary_text']\n",
    "                            break\n",
    "                    if exon is None:\n",
    "                        print(gene_record[0])\n",
    "                        KeyError\n",
    "                    \n",
    "                    # Get the gene weird NP name\n",
    "                    try:\n",
    "                        protein_NP_weirdName = gene_record[0]['Entrezgene_locus'][0]['Gene-commentary_products'][0]['Gene-commentary_products'][0]['Gene-commentary_accession']\n",
    "                    except:\n",
    "                        protein_NP_weirdName = gene_record[0]['Entrezgene_locus'][0]['Gene-commentary_products'][0]['Gene-commentary_accession']\n",
    "\n",
    "                    # Get Human and Mouse Orthologs\n",
    "                    orthologs_organism_list = []\n",
    "                    orthologs = []     \n",
    "                    for Entrezgene_comments_LOOP in gene_record[0]['Entrezgene_comments']:\n",
    "                        if 'Gene-commentary_comment' in Entrezgene_comments_LOOP:\n",
    "                            for Gene_commentary_comment_LOOP in Entrezgene_comments_LOOP['Gene-commentary_comment']:\n",
    "                                if 'Gene-commentary_source' in Gene_commentary_comment_LOOP:\n",
    "                                    orthologs.append(Gene_commentary_comment_LOOP['Gene-commentary_source'][0]['Other-source_src']['Dbtag']['Dbtag_tag']['Object-id']['Object-id_id'])\n",
    "                                    orthologs_organism_list.append(Gene_commentary_comment_LOOP['Gene-commentary_source'][0]['Other-source_anchor'])                    \n",
    "                    \n",
    "                # If there are no matches for the EntrezID at NCBI then return -----\n",
    "                else:\n",
    "                    gene_ncbiID = '-----'\n",
    "                    gene_name = '-----'\n",
    "                    protein_NP_weirdName = '-----'\n",
    "                    exon = '-----'\n",
    "                    gene_location = '-----'                    \n",
    "                    uniprot_IDs = '-----'\n",
    "\n",
    "                gene_found = False\n",
    "                search_results.close()\n",
    "    \n",
    "            # Handle exceptions\n",
    "            except HTTPError as e:\n",
    "\n",
    "                retries += 1\n",
    "                time.sleep(3)\n",
    "            except ssl.SSLError as e:\n",
    "\n",
    "                retries += 1\n",
    "                time.sleep(3)\n",
    "            except ConnectionResetError as e:\n",
    "\n",
    "                retries += 1\n",
    "                time.sleep(3)\n",
    "            except socket.error as e:\n",
    "\n",
    "                retries += 1\n",
    "                time.sleep(3)\n",
    "    \n",
    "        # If the maximum fetch attempts reached, return ------\n",
    "        if retries >= max_retries:\n",
    "            gene_name = '-----'\n",
    "            gene_ncbiID = '-----'\n",
    "            protein_NP_weirdName = '-----'\n",
    "            exon = '-----'\n",
    "            gene_location = '-----'\n",
    "            uniprot_IDs = '-----'\n",
    "    \n",
    "    # If for some reason the ncbi_gene is nto a number, then return the ncbi_gene for all cases\n",
    "    else:\n",
    "        gene_name = ncbi_gene\n",
    "        gene_ncbiID = ncbi_gene\n",
    "        protein_NP_weirdName = ncbi_gene\n",
    "        exon = ncbi_gene\n",
    "        gene_location = ncbi_gene\n",
    "\n",
    "    ncbi_geneName_list.append(gene_name)\n",
    "    ncbi_geneID_list.append(gene_ncbiID)\n",
    "    ncbi_protein_NP_weirdName.append(protein_NP_weirdName)\n",
    "    ncbi_gene_exon_size.append(exon)\n",
    "    ncbi_genomic_location.append(gene_location)\n",
    "    uniprot_IDs.append(gene_uniprotIDs)\n",
    "    orthologs_genes.append(orthologs)\n",
    "    orthologs_organism.append(orthologs_organism_list)\n",
    "    print(counter, gene_name, gene_ncbiID, protein_NP_weirdName, gene_location, exon, gene_uniprotIDs, orthologs, orthologs_organism_list)\n",
    "    counter += 1\n",
    "    if counter % 5000:\n",
    "        data = {\n",
    "            'NCBI_ID': ncbi_geneID_list,\n",
    "            'Gene_Name': ncbi_geneName_list,\n",
    "            'NP_Name': ncbi_protein_NP_weirdName,\n",
    "            'Uniprot_ID': uniprot_IDs,\n",
    "            'Ortholog_Genes': orthologs_genes,\n",
    "            'Ortholog_Organisms': orthologs_organism\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        file_path = 'GeneIDs_' + str(counter) + '.xlsx'\n",
    "        df.to_excel(file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
