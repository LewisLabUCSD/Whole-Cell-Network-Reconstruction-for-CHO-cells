{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a5e96e",
   "metadata": {},
   "source": [
    "# Genes\n",
    "The following notebook retrieves all the genes involved in the reactions from the **\"Rxns\" Sheet** in Google Sheet file. Then, information regarding the genes is retrieved from different databases and a **\"Genes\" Sheet** is generated and updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08228a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from google_sheet import GoogleSheet\n",
    "from utils import get_gene_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac38d2d7",
   "metadata": {},
   "source": [
    "### 1. Generate \"rxns\" and \"genes\" datasets\n",
    "The \"rxns\" dataset contains all the reactions with their GPR associations. The \"genes\" dataset contains all the information of the genes/GPR involved in our reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d8026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_FILE_PATH = 'credentials.json'\n",
    "SPREADSHEET_ID = '1MlBXeHIKw8k8fZyXm-sN__AHTRSunJxar_-bqvukZws'\n",
    "\n",
    "# Initialize the GoogleSheet object\n",
    "sheet = GoogleSheet(SPREADSHEET_ID, KEY_FILE_PATH)\n",
    "\n",
    "# Read data from the Google Sheet\n",
    "sheet_rxns = 'Rxns'\n",
    "sheet_genes = 'Genes'\n",
    "\n",
    "rxns = sheet.read_google_sheet(sheet_rxns)\n",
    "genes = sheet.read_google_sheet(sheet_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de13c811",
   "metadata": {},
   "source": [
    "### 2. Create the a \"gene_list\" with all the genes involved in our reconstruction\n",
    "We extract the gene IDs from the GPR annotations in the **\"rxns\" df**. This information is only retrieved from the **GPR_final** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f61d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3045"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generation of gene_list from all the genes in the \"Whole Cell Network Reconstruction in CHO Cells\" dataset\n",
    "import re\n",
    "\n",
    "gene_list = []\n",
    "human_gene_list = []\n",
    "for index, row in rxns.iterrows():\n",
    "    if row['GPR_final'] != '':\n",
    "        gprs = str(row['GPR_final'])\n",
    "        gpr = re.findall(r'\\b[hH]?\\d+\\b', gprs)\n",
    "        for g in gpr:\n",
    "            if g.lower().startswith('h'):  # we convert to lower case to catch both 'h' and 'H'\n",
    "                human_gene_list.append(int(g[1:]))  # remove 'h' and convert to int before appending\n",
    "            else:\n",
    "                gene_list.append(int(g))  # convert to int before appending\n",
    "\n",
    "gene_list = list(set(gene_list))\n",
    "len(gene_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c5c853",
   "metadata": {},
   "source": [
    "### 3. Replace remaining Human Gene IDs in our dataset with CHO Gene IDs\n",
    "Using the **cho2human_mapping** file, we replace the Human gene IDs with those of CHO, these IDs were not spotted when we first added the Recon3D reactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd3c0d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a dictionary with human gene IDs as keys and CHO gene IDs as values\n",
    "orthologs = pd.read_csv('../Data/Orthologs/cho2human_mapping.tsv', sep='\\t')\n",
    "human_to_cho_dict = dict(zip(orthologs['HUMAN_ID'], orthologs['CHO_ID']))\n",
    "\n",
    "def replace_human_ids_with_cho_ids(s):\n",
    "    replaced_dict = {}\n",
    "    if isinstance(s, str):\n",
    "        genes = re.findall(r'\\b[hH]?\\d+\\b', s)\n",
    "        for gene in genes:\n",
    "            if gene.lower().startswith('h'):  # if gene ID starts with 'h' or 'H'\n",
    "                human_id = int(gene[1:])  # remove 'h' and convert to int\n",
    "                if human_id in human_to_cho_dict:  # if human gene ID is in the dictionary\n",
    "                    cho_id = human_to_cho_dict[human_id]  # get corresponding CHO gene ID\n",
    "                    s = s.replace(gene, str(cho_id))  # replace human gene ID with CHO gene ID in the string\n",
    "                    replaced_dict[gene] = cho_id\n",
    "    return s, replaced_dict\n",
    "\n",
    "# Initialize a dictionary to store replacements\n",
    "replacements = {}\n",
    "\n",
    "# Apply the function and update the replacements dictionary\n",
    "for i in range(len(rxns)):\n",
    "    rxns.at[i, 'GPR_final'], replacements_dict = replace_human_ids_with_cho_ids(rxns.at[i, 'GPR_final'])\n",
    "    replacements.update(replacements_dict)\n",
    "\n",
    "# Now, 'replacements' is a dictionary where keys are the original gene IDs and values are the replaced CHO gene IDs\n",
    "replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc309360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No changes to the original Rxns Sheet\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "#### ---------------------------- ####\n",
    "#### ---- Update Rxns Sheet ----- ####\n",
    "#### ---------------------------- ####\n",
    "######################################\n",
    "if replacements:\n",
    "    sheet.update_google_sheet(sheet_rxns, rxns)\n",
    "    print(\"Google Sheet updated.\")\n",
    "elif not replacements:\n",
    "    print(\"No changes to the original Rxns Sheet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed00e36d",
   "metadata": {},
   "source": [
    "### 3. Add the genes from the \"gene_list\" to the genes df\n",
    "Using a list of all the genes included in the dataset we can retrieve information from the NIH database regarding Gene Symbol, Gene Name, Gene Ensembl ID, and mRNA ID and protein ID using the function get_gene_info()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "236d1799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55622e982a4a4132a248114e9e6ca772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3045 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30100754813\n",
      "Gene 30100754813 does not have PICR Ensembl ID\n",
      "Gene (30100754813, 'ycf15') is a Vitis cinerea Gene\n",
      "A total of 0 Genes were added to the dataset\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from urllib.error import HTTPError\n",
    "from Bio.Entrez.Parser import ValidationError\n",
    "\n",
    "max_retries = 5  # Set the maximum number of retries\n",
    "c = 0\n",
    "\n",
    "for g in tqdm(gene_list):\n",
    "    if str(g) not in list(genes['Gene Entrez ID']):\n",
    "        retry = True\n",
    "        retries = 0\n",
    "        while retry:\n",
    "            try:\n",
    "                print(g)\n",
    "                organism, gene_symbol, gene_name, gene_description, picr_ensembl_id, chok1gs_ensembl_id, mRNA_ncbi_id, protein_ncbi_id, go_terms = get_gene_info(g)\n",
    "                if organism == 'Cricetulus griseus':\n",
    "                    new_row_data = {'Gene Entrez ID': g, 'Gene Symbol': gene_symbol, 'Gene Name': gene_name, 'Gene Description': gene_description,\n",
    "                                    'PICR Ensembl ID': picr_ensembl_id, 'CHOK1GS Ensembl ID': chok1gs_ensembl_id, 'Transcript ID': mRNA_ncbi_id,\n",
    "                                    'Protein ID': protein_ncbi_id, 'GO Terms': go_terms}\n",
    "                    new_row_df = pd.DataFrame(new_row_data, index=[len(genes)])\n",
    "                    genes = pd.concat([genes, new_row_df])\n",
    "                    c+=1\n",
    "                    retry = False\n",
    "                elif organism != 'Cricetulus griseus':\n",
    "                    print(f'Gene {g,gene_symbol} is a {organism} Gene')\n",
    "                    break\n",
    "            except ValidationError:\n",
    "                print(f'Gene {g} not found')\n",
    "                retry = False\n",
    "                continue\n",
    "            except HTTPError:\n",
    "                retries += 1\n",
    "                if retries > max_retries:\n",
    "                    print(f'HTTP Error, reached maximum retries ({max_retries}) for gene {g}')\n",
    "                    break\n",
    "                else:\n",
    "                    print(f'HTTP Error, retrying with gene {g}')\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "print(f'A total of {c} Genes were added to the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2abe8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new genes added.\n",
      "No changes to the original Genes Sheet.\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "#### ----------------------------- ####\n",
    "#### ---- Update Genes Sheet ----- ####\n",
    "#### ----------------------------- ####\n",
    "#######################################\n",
    "if c > 0:\n",
    "    sheet.update_google_sheet(sheet_genes, genes)\n",
    "    print(\"Google Sheet updated.\")\n",
    "elif c == 0:\n",
    "    print(\"No new genes added.\")\n",
    "    print(\"No changes to the original Genes Sheet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2218925",
   "metadata": {},
   "source": [
    "### 4. Eliminate unwanted genes\n",
    "We iterate over the entire dataset to spot **Human genes** in order to eliminate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b810d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the DataFrame to avoid changing the original while iterating\n",
    "erased = 0\n",
    "genes_copy = genes.copy()\n",
    "\n",
    "for index, row in tqdm(genes.iterrows(), total=genes.shape[0]):\n",
    "    g = row['Gene Entrez ID']\n",
    "    retry = True\n",
    "    retries = 0\n",
    "    while retry:\n",
    "        try:\n",
    "            organism, gene_symbol, gene_name, gene_description, picr_ensembl_id, chok1gs_ensembl_id, mRNA_ncbi_id, protein_ncbi_id, go_terms = get_gene_info(g)\n",
    "            if organism == 'Homo sapiens':\n",
    "                genes_copy = genes_copy.drop(index)\n",
    "                print(f'Gene {g,gene_symbol} erased from dataset')\n",
    "                erased+=1\n",
    "                retry = False\n",
    "            else:\n",
    "                retry = False\n",
    "        except ValidationError:\n",
    "            print(f'Gene {g} not found')\n",
    "            retry = False\n",
    "            continue\n",
    "        except HTTPError:\n",
    "            retries += 1\n",
    "            if retries > max_retries:\n",
    "                print(f'HTTP Error, reached maximum retries ({max_retries}) for gene {g}')\n",
    "                break\n",
    "            else:\n",
    "                print(f'HTTP Error, retrying with gene {g}')\n",
    "                time.sleep(1)\n",
    "\n",
    "# Replace the original DataFrame with the updated one\n",
    "genes = genes_copy\n",
    "print(f'A total of {erased} Genes were erased from the original dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a459ea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "#### ----------------------------- ####\n",
    "#### ---- Update Genes Sheet ----- ####\n",
    "#### ----------------------------- ####\n",
    "#######################################\n",
    "if erased > 0:\n",
    "    sheet.update_google_sheet(sheet_genes, genes)\n",
    "    print(\"Google Sheet updated.\")\n",
    "elif erased == 0:\n",
    "    print(\"No erased genes.\")\n",
    "    print(\"No changes to the original Genes Sheet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3b506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in tqdm(gene_list):\n",
    "    if g not in list(genes['Gene Entrez ID']):\n",
    "        try:\n",
    "            gene_symbol, gene_name, gene_description, picr_ensembl_id, chok1gs_ensembl_id, mRNA_ncbi_id, protein_ncbi_id, go_terms = get_gene_info(g)\n",
    "            new_row_data = {'Gene Entrez ID': g, 'Gene Symbol': gene_symbol, 'Gene Name': gene_name, 'Gene Description': gene_description,\n",
    "                            'PICR Ensembl ID': picr_ensembl_id, 'CHOK1GS Ensembl ID': chok1gs_ensembl_id, 'Transcript ID': mRNA_ncbi_id,\n",
    "                            'Protein ID': protein_ncbi_id, 'GO Terms': go_terms}\n",
    "            new_row_df = pd.DataFrame(new_row_data, index=[len(genes)])\n",
    "            genes = pd.concat([genes, new_row_df])\n",
    "        except KeyError:\n",
    "            print(f'Gene {g} not found')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfcbfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch information from the NIH database\n",
    "\n",
    "\n",
    "# Complete null or blank information in the already generated \"Genes Sheet\" dataset\n",
    "for i,row in genes.iterrows():\n",
    "    if row['Gene Entrez ID'] == '':\n",
    "        for g in gene_list:\n",
    "            gene_sheet_list = [str(x) for x in genes['Gene Entrez ID']]\n",
    "            if g not in gene_sheet_list:\n",
    "                gene_symbol, gene_name, gene_description, picr_ensembl_id, chok1gs_ensembl_id, mRNA_ncbi_id, protein_ncbi_id, go_terms = get_gene_info(g)\n",
    "                row['Gene Entrez ID'] = g\n",
    "                row['Gene Symbol'] = gene_symbol\n",
    "                row['Gene Name'] = gene_name\n",
    "                row['Gene Description'] = gene_description\n",
    "                row['PICR Ensembl ID'] = picr_ensembl_id\n",
    "                row['CHOK1GS Ensembl ID'] = chok1gs_ensembl_id\n",
    "                row['Transcript ID'] = mRNA_ncbi_id\n",
    "                row['Protein ID'] = protein_ncbi_id\n",
    "                row['GO Terms'] = go_terms\n",
    "                break          \n",
    "    elif row['Gene Entrez ID'] != '' and (row['Gene Symbol'] == '' or row['Gene Name'] == '' or row['PICR Ensembl ID'] == '' or row['Transcript ID'] == '' or row['Protein ID'] == ''):\n",
    "        row['Gene Symbol'] = gene_symbol\n",
    "        row['Gene Name'] = gene_name\n",
    "        row['Gene Description'] = gene_description\n",
    "        row['PICR Ensembl ID'] = picr_ensembl_id\n",
    "        row['CHOK1GS Ensembl ID'] = chok1gs_ensembl_id\n",
    "        row['Transcript ID'] = mRNA_ncbi_id\n",
    "        row['Protein ID'] = protein_ncbi_id\n",
    "        row['GO Terms'] = go_terms\n",
    "'''\n",
    "# Add genes from the gene_list that are not yet in the \"Genes Sheet\" dataset\n",
    "for g in gene_list:\n",
    "    # the first try/except is to avoid overwritting data in case there already some info in the dataset\n",
    "    try:\n",
    "        gene_sheet_list = [str(x) for x in df['Gene Entrez ID']]\n",
    "        id = max(df['Index']) + 2\n",
    "    except:\n",
    "        gene_sheet_list = []\n",
    "        id = 2\n",
    "    if gene not in gene_sheet_list:\n",
    "        try:\n",
    "            gene_symbol, gene_name, gene_description, picr_ensembl_id, chok1gs_ensembl_id, mRNA_ncbi_id, protein_ncbi_id, go_terms = get_gene_info(gene)\n",
    "            print(id-1)\n",
    "            genes_sheet.update_cell(id,1,id-1)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,2,gene)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,3,gene_symbol)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,4,gene_name)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,5,gene_description)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,6,picr_ensembl_id)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,7,chok1gs_ensembl_id)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,8,mRNA_ncbi_id)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,9,protein_ncbi_id)\n",
    "            time.sleep(5)\n",
    "            genes_sheet.update_cell(id,10,go_terms)\n",
    "        except:\n",
    "            print('Google API quota exceeded')\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "            \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b59d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "Entrez.email = 'account1@theta-ocean-377718.iam.gserviceaccount.com'\n",
    "handle = Entrez.efetch(db='gene', id='3979190', retmode='xml')\n",
    "record = Entrez.read(handle)[0]\n",
    "\n",
    "#gene_name = record['Entrezgene_gene']['Gene-ref']['Gene-ref_desc']\n",
    "#gene_symbol = record['Entrezgene_gene']['Gene-ref']['Gene-ref_locus']\n",
    "\n",
    "human_handle = Entrez.efetch(db='gene', id='3979190', retmode='xml')\n",
    "human_record = Entrez.read(human_handle)[0]\n",
    "if 'Entrezgene_comments' in human_record and 'Gene-commentary_comment' in human_record['Entrezgene_comments'][0]:\n",
    "    human_gene_description = human_record['Entrezgene_comments'][0]['Gene-commentary_comment'][0]['String']\n",
    "elif 'Entrezgene_summary' in human_record:\n",
    "    human_gene_description = human_record['Entrezgene_summary']\n",
    "else:\n",
    "    human_gene_description = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d44cdb",
   "metadata": {},
   "source": [
    "#### Get the CHO genome and map the IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f04660af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "import math\n",
    "import time\n",
    "import ssl\n",
    "from urllib.error import HTTPError\n",
    "import socket\n",
    "from Bio.Entrez.Parser import CorruptedXMLError\n",
    "import requests\n",
    "\n",
    "def get_uniprot_from_dict(dictionary, uniprotIDs, target_key, target_value1,  target_value2):\n",
    "    for key, value in dictionary.items():\n",
    "        if key == target_key and (value == target_value1 or value == target_value2):\n",
    "            uniprotIDs.append(dictionary.get('Dbtag_tag', {}).get('Object-id', {}).get('Object-id_str'))            \n",
    "        if isinstance(value, dict):\n",
    "            get_uniprot_from_dict(value, uniprotIDs, target_key, target_value1, target_value2)\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, dict):\n",
    "                    get_uniprot_from_dict(item, uniprotIDs, target_key, target_value1, target_value2)        \n",
    "    return uniprotIDs\n",
    "\n",
    "def get_human_mouse_orthologs(dictionary, orthologs, target_key, target_value1):\n",
    "    for key, value in dictionary.items():\n",
    "        if key == target_key and (value == target_value1):\n",
    "            orthologs.append(dictionary.get('Dbtag_tag', {}).get('Object-id', {}).get('Object-id_id'))        \n",
    "        if isinstance(value, dict):\n",
    "            get_human_mouse_orthologs(value, orthologs, target_key, target_value1)\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, dict):\n",
    "                    get_human_mouse_orthologs(item, orthologs, target_key, target_value1)        \n",
    "    return orthologs           \n",
    "\n",
    "\n",
    "\n",
    "# Entrez.email = \"athand01@gmail.com\"\n",
    "Entrez.email = \"a.antonakoudis@sartorius.com\"\n",
    "u_g = pd.read_excel('../CHO_Genome.xlsx')\n",
    "GO_terms = pd.read_csv('orthologs&GO.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd708214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UniProt_Data_Request(uniprot_id, session=None):\n",
    "\n",
    "    name = []\n",
    "    weight = []\n",
    "    length = []\n",
    "    annotation_score = []\n",
    "    existance = []\n",
    "    subcellular_locations_list = []\n",
    "    tissue_specificity = []\n",
    "    max_retries = 3\n",
    "    retries = 0\n",
    "    if session is None:\n",
    "        session = requests.Session()\n",
    "        certificate_path = '../../../../../../Downloads/Zscaler Root CA.crt'\n",
    "        session.verify = certificate_path\n",
    "\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            url = f\"https://www.uniprot.org/uniprot/{uniprot_id}.json\"\n",
    "            response = session.get(url, headers={\"Accept\": \"application/json\"}, timeout=150)\n",
    "            if response.status_code == 200:\n",
    "                entry = response.json()\n",
    "                if 'recommendedName' in entry['proteinDescription']:\n",
    "                    name  = entry['proteinDescription']['recommendedName']['fullName']['value']\n",
    "                elif 'submissionNames' in entry['proteinDescription']:\n",
    "                    name = entry['proteinDescription']['submissionNames'][0]['fullName']['value']\n",
    "                annotation_score = entry['annotationScore']\n",
    "                weight = entry['sequence']['molWeight']\n",
    "                length = entry['sequence']['length']\n",
    "                existance = entry['proteinExistence']              \n",
    "\n",
    "                for references in entry['references']:\n",
    "                    if 'referenceComments' in references:     \n",
    "                        for ref_comments in references['referenceComments']:\n",
    "                            if ref_comments['type'] == 'TISSUE':\n",
    "                                for ref_comments_tissues in ref_comments['type']:\n",
    "                                    tissue_specificity = ref_comments['value']\n",
    "\n",
    "                subcellular_locations_list = []\n",
    "                if 'comments' in entry:\n",
    "                    for i in entry['comments']:\n",
    "                        if 'subcellularLocations' in  i:\n",
    "                            for k in i['subcellularLocations']:\n",
    "                                subcellular_location = k['location']['value']\n",
    "                                subcellular_locations_list.append(subcellular_location)                \n",
    "                return name, weight, length, annotation_score, existance, subcellular_locations_list, tissue_specificity\n",
    "            else:\n",
    "                raise Exception(f\"API request failed for UniProt ID {uniprot_id}: Status code {response.status_code}\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # Handle request-related errors\n",
    "            print(f\"Request Error: {e}\")\n",
    "            retries += 1\n",
    "            if retries < max_retries:\n",
    "                print(\"Retrying after a delay...\")\n",
    "                time.sleep(1)  # Wait for 5 seconds before retrying\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle unexpected errors\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            retries += 1\n",
    "            if retries < max_retries:\n",
    "                print(\"Retrying after a delay...\")\n",
    "                time.sleep(1)  # Wait for 5 seconds before retrying\n",
    "\n",
    "    return name, weight, length, annotation_score, existance, subcellular_locations_list, tissue_specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b183b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import SeqIO\n",
    "\n",
    "def get_exon_info(gff_file, genome_file, transcript_id):\n",
    "    # Find the location ID\n",
    "    location_id = None\n",
    "    with open(gff_file, 'r') as gff:\n",
    "        for line in gff:\n",
    "            if not line.startswith('#'):\n",
    "                if f'ID=rna-{transcript_id}.' in line:\n",
    "                    location_id = line.split('\\t')[0]\n",
    "                    break\n",
    "\n",
    "    if location_id is None:\n",
    "        print(f\"Location ID not found for transcript ID '{transcript_id}' in the GFF file.\")\n",
    "        return\n",
    "\n",
    "    # Load the whole genome\n",
    "    sequences = list(SeqIO.parse(genome_file, \"fasta\"))\n",
    "    matching_sequences = [record for record in sequences if record.name.startswith(location_id)]\n",
    "\n",
    "    output_file = f'../Notebooks/Website Data/{transcript_id}-EXONS.txt'\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"ERROR: File '{output_file}' already exists. Please choose a different transcript_id.\")\n",
    "    else:\n",
    "        match_count = 0\n",
    "        with open(output_file, 'w') as output, open(gff_file, 'r') as gff:\n",
    "            for line in gff:\n",
    "                if not line.startswith('#'):\n",
    "                    if f'ID=exon-{transcript_id}' in line:\n",
    "                        parts = line.split('\\t')\n",
    "                        if len(parts) >= 5:\n",
    "                            start, end = map(int, parts[3:5])\n",
    "                            match_count += 1\n",
    "                            output.write(f\"Exon-{match_count}: Start: {start}, End: {end}, Sequence: {matching_sequences[0].seq[start:end]}\\n\")\n",
    "\n",
    "        if match_count > 0:\n",
    "            print(f\"Total matches: {match_count}\")\n",
    "            print(f\"Exon information saved to '{output_file}'\")\n",
    "        else:\n",
    "            print(f\"No matches found for the pattern 'exon-{transcript_id}' in the GFF file.\")\n",
    "\n",
    "gff_file = '../../ncbi_dataset/ncbi_dataset/data/GCF_000223135.1/genomic.gff'\n",
    "genome_file = '../../ncbi_dataset/ncbi_dataset/data/GCF_000223135.1/GCF_000223135.1_CriGri_1.0_genomic.fna'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "770ed42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists\n",
    "# Genome Sheet\n",
    "Assembly_ID_List = []\n",
    "GenBank_List = []\n",
    "RefSeq_List = []\n",
    "WGS_Accession_List = []\n",
    "Release_Data_List = []\n",
    "References_List = []\n",
    "Nb_Genes_List = []\n",
    "Assembly_Type_List = []\n",
    "Assembly_Level_List = []\n",
    "Description_List = []\n",
    "Sumbitter_List = []\n",
    "Cell_Line_LIst = []\n",
    "\n",
    "# Gene Sheet\n",
    "Gene_Symbol_List = []\n",
    "Gene_Synonyms_List = []\n",
    "Gene_Name_List = []\n",
    "Gene_Description_List = []\n",
    "GO_Terms_List = []\n",
    "COGs_List = []\n",
    "Exon_Count_List = []\n",
    "Chromosome_List = []\n",
    "Strand_List = []\n",
    "Human_Ortholog_Entrez_List = []\n",
    "Mouse_Ortholog_Entrez_List = []\n",
    "Assembly_Specific_Gene_Symbol_List = []\n",
    "Gene_References_List = []\n",
    "\n",
    "# Assembly Specific Genes Sheet\n",
    "Assembly_Specific_Gene_Symbol_List = []\n",
    "Gene_Symbol_List = []\n",
    "Gene_Entrez_ID_List = []\n",
    "Location_Sequence_List = []\n",
    "Position_List = []\n",
    "Transcript_Sequence_ID_List = []\n",
    "Assembly_ID_List = []\n",
    "\n",
    "# Transcripts Sheet\n",
    "Transcript_Sequence_ID_List = []\n",
    "Protein_Sequence_ID_List = []\n",
    "Transcript_Sequence_List = []\n",
    "Protein_Uniprot_ID_List = []\n",
    "Exon_Info_List = []\n",
    "Assembly_ID_List = []\n",
    "\n",
    "# Proteins Sheet\n",
    "Protein_Uniprot_ID_List = []\n",
    "Protein_Name_List = []\n",
    "Function_List = []\n",
    "Protein_existence_List = []\n",
    "Annotation_Score_List = []\n",
    "Amino_Acid_Count_List = []\n",
    "Protein_Sequence_List = []\n",
    "Weigth_Da_List = []\n",
    "Gene_Symbol_List = []\n",
    "Subcellular_Location_List = []\n",
    "Tissue_Specificity_List = []\n",
    "PDB_Structure_List = []\n",
    "PDB_Visualization_List = []\n",
    "Protein_Sequence_ID_List = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e34657fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 |GENE:  Scap ----- [] ----- 100689048 ----- SREBF chaperone ----- This gene encodes a prote ... ----- ['GO:0005789', 'GO:000013 ... ----- [] ----- 22 ----- 4 ----- plus ----- 22937 ----- 235623\n",
      "ASSEMBLY SPECIFC GENE: S1, S2,  100689048 ----- NW_003614047 ----- 910892 ----- 941247 ----- NM_001244036 ----- Reference CriGri_1.0 Primary Assembly\n",
      "TRANSCRIPTS:  NM_001244036 ----- NP_001230965 ----- GCGGCGGAGCGGGAGGGGAAAGGTA ----- Reference CriGri_1.0 Primary Assembly\n",
      "Total matches: 22\n",
      "Exon information saved to '../Notebooks/Website Data/NM_001244036-EXONS.txt'\n",
      "PROTEINS:  G3HKR2 ----- Sterol regulatory element-binding protein cleavage-activating protein ----- 3: Inferred from homology ----- 2.0 ----- 1276 ----- MTLTERLREKISQAFYNHGLLCASY ----- 139528 kDa ----- ['Cytoplasmic vesicle, COPII-coated vesicle membrane', 'Endoplasmic reticulum membrane', 'Golgi apparatus membrane'] ----- [] ----- NP_001230965\n",
      "PROTEINS:  P97260 ----- Sterol regulatory element-binding protein cleavage-activating protein ----- 1: Evidence at protein level ----- 5.0 ----- 1276 ----- MTLTERLREKISQAFYNHGLLCASY ----- 139514 kDa ----- ['Endoplasmic reticulum membrane', 'Golgi apparatus membrane', 'Cytoplasmic vesicle, COPII-coated vesicle membrane'] ----- Ovary ----- NP_001230965\n",
      "PROTEINS:  Q2WEK9 ----- Sterol regulatory element-binding protein cleavage-activating protein ----- 1: Evidence at protein level ----- 5.0 ----- 1276 ----- MTLTERLREKISQAFYNHGLLCASY ----- 139514 kDa ----- ['Endoplasmic reticulum membrane', 'Golgi apparatus membrane', 'Cytoplasmic vesicle, COPII-coated vesicle membrane'] ----- Ovary ----- NP_001230965\n",
      "ASSEMBLY SPECIFC GENE: S1, S2,  100689048 ----- NC_048597 ----- 217832647 ----- 217863219 ----- NM_001244036 ----- Alternate CriGri-PICRH-1.0\n",
      "TRANSCRIPTS:  NM_001244036 ----- NP_001230965 ----- GCGGCGGAGCGGGAGGGGAAAGGTA ----- Alternate CriGri-PICRH-1.0\n",
      "ERROR: File '../Notebooks/Website Data/NM_001244036-EXONS.txt' already exists. Please choose a different transcript_id.\n",
      "PROTEINS:  G3HKR2 ----- Sterol regulatory element-binding protein cleavage-activating protein ----- 3: Inferred from homology ----- 2.0 ----- 1276 ----- MTLTERLREKISQAFYNHGLLCASY ----- 139528 kDa ----- ['Cytoplasmic vesicle, COPII-coated vesicle membrane', 'Endoplasmic reticulum membrane', 'Golgi apparatus membrane'] ----- [] ----- NP_001230965\n",
      "PROTEINS:  P97260 ----- Sterol regulatory element-binding protein cleavage-activating protein ----- 1: Evidence at protein level ----- 5.0 ----- 1276 ----- MTLTERLREKISQAFYNHGLLCASY ----- 139514 kDa ----- ['Endoplasmic reticulum membrane', 'Golgi apparatus membrane', 'Cytoplasmic vesicle, COPII-coated vesicle membrane'] ----- Ovary ----- NP_001230965\n",
      "PROTEINS:  Q2WEK9 ----- Sterol regulatory element-binding protein cleavage-activating protein ----- 1: Evidence at protein level ----- 5.0 ----- 1276 ----- MTLTERLREKISQAFYNHGLLCASY ----- 139514 kDa ----- ['Endoplasmic reticulum membrane', 'Golgi apparatus membrane', 'Cytoplasmic vesicle, COPII-coated vesicle membrane'] ----- Ovary ----- NP_001230965\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for gene_EntrezID in u_g['NCBI GeneID'][counter:counter + 1]:\n",
    "    if not math.isnan(gene_EntrezID):   \n",
    "        gene_EntrezID = int(gene_EntrezID)        \n",
    "        go_terms = []          \n",
    "        max_retries = 3\n",
    "        retries = 0\n",
    "        gene_found = True\n",
    "        while retries < max_retries and gene_found:\n",
    "            try:\n",
    "                search_results = Entrez.esearch(db=\"gene\", term = gene_EntrezID)            \n",
    "                record = Entrez.read(search_results)\n",
    "\n",
    "                # Check if any gene records were found\n",
    "                if int(record[\"Count\"]) > 0:\n",
    "\n",
    "                    # Get the Gene ID of the first result\n",
    "                    gene_id = record[\"IdList\"][0]\n",
    "\n",
    "                    # Fetch the gene information, maximum 3 tries\n",
    "                    fetch_tries = 0\n",
    "                    fetch_found = True\n",
    "                    while fetch_tries < 3 and fetch_found:\n",
    "\n",
    "                        gene_info = Entrez.efetch(db=\"gene\", id=gene_id, retmode=\"xml\")           \n",
    "                        fetch_tries += 1\n",
    "                        try:\n",
    "                            gene_record = Entrez.read(gene_info)\n",
    "                            fetch_found = False\n",
    "                        except CorruptedXMLError as xml_error:\n",
    "                            time.sleep(3)\n",
    "                            fetch_tries += 1\n",
    "\n",
    "                    # Get the gene name and gene NCBI ID\n",
    "                    if 'Gene-ref_locus' in gene_record[0]['Entrezgene_gene']['Gene-ref']:\n",
    "                        gene_symbol = gene_record[0]['Entrezgene_gene']['Gene-ref']['Gene-ref_locus']                        \n",
    "                    else:\n",
    "                        gene_symbol = gene_record[0]['Entrezgene_gene']['Gene-ref']['Gene-ref_locus-tag']\n",
    "                \n",
    "                    # Get the Gene Synonyms\n",
    "                    if 'Gene-ref_syn' in gene_record[0]['Entrezgene_gene']['Gene-ref']:\n",
    "                        gene_synonyms = gene_record[0]['Entrezgene_gene']['Gene-ref']['Gene-ref_syn']\n",
    "                    else:\n",
    "                        gene_synonyms = []\n",
    "                    gene_ncbiID = gene_record[0]['Entrezgene_track-info']['Gene-track']['Gene-track_geneid']\n",
    "\n",
    "                    # Get the Gene Name\n",
    "                    gene_name = gene_record[0]['Entrezgene_gene']['Gene-ref']['Gene-ref_desc']\n",
    "\n",
    "                    # Get the chromosome\n",
    "                    chromosome = int(gene_record[0]['Entrezgene_source']['BioSource']['BioSource_subtype'][0]['SubSource_name'])\n",
    "\n",
    "                    # Get number of Exons\n",
    "                    exon_count = int(gene_record[0]['Entrezgene_properties'][0]['Gene-commentary_text'])\n",
    "\n",
    "                    # Get the Strand\n",
    "                    strand = gene_record[0]['Entrezgene_locus'][0]['Gene-commentary_seqs'][0]['Seq-loc_int']['Seq-interval']['Seq-interval_strand']['Na-strand'].attributes['value']\n",
    "                    \n",
    "                    # Get Human and Mouse Orthologs\n",
    "                    orthologs_organism_list = []\n",
    "                    orthologs = []     \n",
    "                    if 'Entrezgene_comments' in gene_record[0]:\n",
    "                        for Entrezgene_comments_LOOP in gene_record[0]['Entrezgene_comments']:\n",
    "                            if 'Gene-commentary_comment' in Entrezgene_comments_LOOP:\n",
    "                                for Gene_commentary_comment_LOOP in Entrezgene_comments_LOOP['Gene-commentary_comment']:\n",
    "                                    if 'Gene-commentary_source' in Gene_commentary_comment_LOOP:\n",
    "                                        if 'Object-id_id' in Gene_commentary_comment_LOOP['Gene-commentary_source'][0]['Other-source_src']['Dbtag']['Dbtag_tag']['Object-id']:\n",
    "                                            orthologs.append(Gene_commentary_comment_LOOP['Gene-commentary_source'][0]['Other-source_src']['Dbtag']['Dbtag_tag']['Object-id']['Object-id_id'])\n",
    "                                        else:\n",
    "                                            orthologs.append(Gene_commentary_comment_LOOP['Gene-commentary_source'][0]['Other-source_src']['Dbtag']['Dbtag_tag']['Object-id']['Object-id_str'])\n",
    "                                        orthologs_organism_list.append(Gene_commentary_comment_LOOP['Gene-commentary_source'][0]['Other-source_anchor'])                    \n",
    "                    if 'human' in orthologs_organism_list:\n",
    "                        human_ortholog_EntrezID = orthologs[orthologs_organism_list.index('human')]                                            \n",
    "                        search_results_human = Entrez.esearch(db=\"gene\", term=human_ortholog_EntrezID)     \n",
    "                        record_human = Entrez.read(search_results_human)\n",
    "                        gene_id_human = record_human[\"IdList\"][0]\n",
    "                        gene_info_human = Entrez.efetch(db=\"gene\", id=gene_id_human, retmode=\"xml\")           \n",
    "                        gene_record_human = Entrez.read(gene_info_human)\n",
    "                        gene_description = gene_record_human[0]['Entrezgene_summary']\n",
    "                    else:\n",
    "                        human_ortholog_EntrezID = []\n",
    "                        gene_description = []\n",
    "                    if 'mouse' in orthologs_organism_list:\n",
    "                        mouse_ortholog_EntrezID = orthologs[orthologs_organism_list.index('mouse')]\n",
    "                    else:\n",
    "                        mouse_ortholog_EntrezID = []\n",
    "                    \n",
    "                    # Get GO terms\n",
    "                    result = GO_terms[GO_terms['CHO GeneID'] == str(gene_EntrezID)]['GO_ids'].values\n",
    "                    if result.size > 0:\n",
    "                        go_terms = result[0]\n",
    "                    else:\n",
    "                        go_terms = []\n",
    "\n",
    "                    # Get the COG terms\n",
    "                    cogs = []\n",
    "\n",
    "                gene_found = False\n",
    "                search_results.close()\n",
    "    \n",
    "            # Handle exceptions\n",
    "            except HTTPError as e:\n",
    "\n",
    "                retries += 1\n",
    "                time.sleep(3)\n",
    "            except ssl.SSLError as e:\n",
    "\n",
    "                retries += 1\n",
    "                time.sleep(3)\n",
    "            except ConnectionResetError as e:\n",
    "\n",
    "                retries += 1\n",
    "                time.sleep(3)\n",
    "            except socket.error as e:\n",
    "\n",
    "                retries += 1\n",
    "                time.sleep(3)\n",
    "        \n",
    "    # Loop over the Genes\n",
    "    print(counter, \"|GENE: \", gene_symbol, \"-----\", gene_synonyms, \"-----\", gene_EntrezID, \"-----\", gene_name, \"-----\", gene_description[0:25], \"... -----\", go_terms[0:25], \"... -----\", cogs, \"-----\", exon_count, \"-----\", chromosome, \"-----\", strand, \"-----\", human_ortholog_EntrezID, \"-----\", mouse_ortholog_EntrezID)\n",
    "    \n",
    "    # Append information\n",
    "    Gene_Symbol_List.append(gene_symbol)\n",
    "    Gene_Synonyms_List.append(gene_synonyms)\n",
    "    Gene_Name_List.append(gene_name)\n",
    "    Gene_Description_List.append(gene_description)\n",
    "    GO_Terms_List.append(go_terms)\n",
    "    COGs_List.append(cogs)\n",
    "    Exon_Count_List.append(exon_count)\n",
    "    Chromosome_List.append(chromosome)\n",
    "    Strand_List.append(strand)\n",
    "    Human_Ortholog_Entrez_List.append(human_ortholog_EntrezID)\n",
    "    Mouse_Ortholog_Entrez_List.append(mouse_ortholog_EntrezID)\n",
    "    Assembly_Specific_Gene_Symbol_List.append([])\n",
    "    Gene_References_List.append([])\n",
    "\n",
    "    # Loop over the assembly specifics\n",
    "    for assembly_specific_info in gene_record[0]['Entrezgene_locus']:    \n",
    "        assembly_id = assembly_specific_info['Gene-commentary_heading']\n",
    "        location_sequence = assembly_specific_info['Gene-commentary_accession']\n",
    "        start_range = assembly_specific_info['Gene-commentary_seqs'][0]['Seq-loc_int']['Seq-interval']['Seq-interval_from']\n",
    "        end_range = assembly_specific_info['Gene-commentary_seqs'][0]['Seq-loc_int']['Seq-interval']['Seq-interval_to']\n",
    "        \n",
    "        # Loop over the transcripts of the Assembly\n",
    "        for assembly_specific_transcript in assembly_specific_info['Gene-commentary_products']:\n",
    "            transcript_sequence_ID = assembly_specific_transcript['Gene-commentary_accession']\n",
    "            print(\"ASSEMBLY SPECIFC GENE: S1, S2, \", gene_EntrezID, \"-----\", location_sequence, \"-----\", start_range, \"-----\", end_range, \"-----\", transcript_sequence_ID, \"-----\", assembly_id)\n",
    "\n",
    "            # Loop over the Transcripts and proteins\n",
    "            # for transcripts in assembly_specific_gene['Gene-commentary_products']:\n",
    "            mRNA_handle = Entrez.efetch(db=\"nucleotide\", id=transcript_sequence_ID, rettype=\"fasta\")\n",
    "            mRNA_record = mRNA_handle.read()\n",
    "            mRNA_sequence = ''.join(mRNA_record.split('\\n')[1:])           \n",
    "            #\n",
    "            # Get Exon information from the gff file \n",
    "            # Downloadable from the assembly page\n",
    "            #\n",
    "            for assembly_specific_transcript_products in assembly_specific_transcript['Gene-commentary_products']:\n",
    "                protein_sequence_ID = assembly_specific_transcript_products['Gene-commentary_accession']\n",
    "                print(\"TRANSCRIPTS: \", transcript_sequence_ID, \"-----\", protein_sequence_ID, \"-----\", mRNA_sequence[0:25], '-----', assembly_id)  \n",
    "                get_exon_info(gff_file, genome_file, transcript_sequence_ID)\n",
    "\n",
    "\n",
    "                for Entrez_Comments in gene_record[0]['Entrezgene_comments']:\n",
    "                    if 'Gene-commentary_comment' in Entrez_Comments:\n",
    "                        for comments in Entrez_Comments['Gene-commentary_comment']:\n",
    "                            # print(comments)  \n",
    "                            if 'Gene-commentary_products' in comments:\n",
    "                                for product_per_assembly in comments['Gene-commentary_products']:                                \n",
    "                                    if product_per_assembly['Gene-commentary_heading'] == 'mRNA Sequence':\n",
    "                                        mRNA = product_per_assembly['Gene-commentary_accession']\n",
    "                                        if mRNA == transcript_sequence_ID:  \n",
    "                                            for protein_per_transcript_per_assemlby in product_per_assembly['Gene-commentary_products']:\n",
    "                                                protein_sequence_ID = protein_per_transcript_per_assemlby['Gene-commentary_accession']\n",
    "                                                protein_handle = Entrez.efetch(db=\"protein\", id=protein_sequence_ID, rettype=\"fasta\")\n",
    "                                                protein_record = protein_handle.read()\n",
    "                                                protein_sequence = ''.join(protein_record.split('\\n')[1:])  \n",
    "                                                uniprotID_list = []\n",
    "                                                for protein_comments in protein_per_transcript_per_assemlby['Gene-commentary_comment']:\n",
    "                                                    # print(protein_comments['Gene-commentary_heading'])\n",
    "                                                    if protein_comments['Gene-commentary_heading'] == 'UniProtKB':\n",
    "                                                        # print(protein_comments)\n",
    "                                                        for uniprotID_protein_per_assembly in protein_comments['Gene-commentary_comment'][0]['Gene-commentary_source']:\n",
    "                                                            protein_uniprot_id = uniprotID_protein_per_assembly['Other-source_src']['Dbtag']['Dbtag_tag']['Object-id']['Object-id_str']\n",
    "                                                            uniprotID_list.append(protein_uniprot_id)\n",
    "                                                subcellular_locations_list = []\n",
    "                                                for UniprotID in uniprotID_list:\n",
    "                                                    name, weight, length, annotation_score, existance, subcellular_locations_list, tissue_specificity = UniProt_Data_Request(UniprotID)   \n",
    "                                                    print(\"PROTEINS: \", UniprotID, \"-----\", name, \"-----\", existance, \"-----\", annotation_score, \"-----\", length, \"-----\", protein_sequence[0:25], \"-----\", weight, \"kDa -----\", subcellular_locations_list, \"-----\", tissue_specificity, \"-----\", protein_sequence_ID)                         \n",
    "                                    else:       \n",
    "                                            \n",
    "                                        if 'Gene-commentary_products' in product_per_assembly:\n",
    "                                            # print(product_per_assembly)  \n",
    "                                            for transcript_per_assembly in product_per_assembly['Gene-commentary_products']:      \n",
    "                                                mRNA = transcript_per_assembly['Gene-commentary_accession']      \n",
    "                                                # print(mRNA, transcript_sequence_ID, transcript_per_assembly)        \n",
    "                                                if mRNA == transcript_sequence_ID:                                                  \n",
    "                                                    for protein_per_transcript_per_assemlby in transcript_per_assembly['Gene-commentary_products']:\n",
    "                                                        # print(2)\n",
    "                                                        protein_sequence_ID = protein_per_transcript_per_assemlby['Gene-commentary_accession']\n",
    "                                                        protein_handle = Entrez.efetch(db=\"protein\", id=protein_sequence_ID, rettype=\"fasta\")\n",
    "                                                        protein_record = protein_handle.read()\n",
    "                                                        protein_sequence = ''.join(protein_record.split('\\n')[1:])  \n",
    "                                                        uniprotID_list = []\n",
    "                                                        for protein_comments in protein_per_transcript_per_assemlby['Gene-commentary_comment']:\n",
    "                                                            \n",
    "                                                            # print(protein_comments['Gene-commentary_heading'])\n",
    "                                                            if protein_comments['Gene-commentary_heading'] == 'UniProtKB':\n",
    "                                                                for uniprotID_protein_per_assembly in protein_comments['Gene-commentary_comment'][0]['Gene-commentary_source']:\n",
    "                                                                    protein_uniprot_id = uniprotID_protein_per_assembly['Other-source_src']['Dbtag']['Dbtag_tag']['Object-id']['Object-id_str']\n",
    "                                                                    uniprotID_list.append(protein_uniprot_id)\n",
    "                                                        subcellular_locations_list = []\n",
    "                                                        for UniprotID in uniprotID_list:\n",
    "                                                            name, weight, length, annotation_score, existance, subcellular_locations_list, tissue_specificity = UniProt_Data_Request(UniprotID)   \n",
    "                                                            print(\"PROTEINS: \", UniprotID, \"-----\", name, \"-----\", existance, \"-----\", annotation_score, \"-----\", length, \"-----\", protein_sequence[0:25], \"-----\", weight, \"kDa -----\", subcellular_locations_list, \"-----\", tissue_specificity, \"-----\", protein_sequence_ID)                         \n",
    "\n",
    "    print(\"-----------------------------------------------------------------------------------------\")\n",
    "    counter += 1\n",
    "\n",
    "    # if counter % 1000 == 0:\n",
    "    #     data = {\n",
    "    #         'NCBI_ID': ncbi_geneID_list,\n",
    "    #         'Gene_Name': ncbi_geneName_list,\n",
    "    #         'NP_Name': ncbi_protein_NP_weirdName,\n",
    "    #         'Uniprot_ID': uniprot_IDs,\n",
    "    #         'Ortholog_Genes': orthologs_genes,\n",
    "    #         'Ortholog_Organisms': orthologs_organism,\n",
    "    #         'Exon Number': ncbi_gene_exon_size,\n",
    "    #         'Sequence': aa_sequences\n",
    "    #     }\n",
    "    #     df = pd.DataFrame(data)\n",
    "    #     file_path = 'GeneIDs_' + str(counter) + '.xlsx'\n",
    "    #     df.to_excel(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2a23951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Gene_Symbol': Gene_Symbol_List,\n",
    "    'Gene_Synonyms': Gene_Synonyms_List,\n",
    "    'Gene_Name': Gene_Name_List,\n",
    "    'Gene_Description': Gene_Description_List,\n",
    "    'GO_Terms': GO_Terms_List,\n",
    "    'COGs': COGs_List,\n",
    "    'Exon_Count': Exon_Count_List,\n",
    "    'Chromosome': Chromosome_List,\n",
    "    'Strand': Strand_List,\n",
    "    'Human_Ortholog_Entrez': Human_Ortholog_Entrez_List,\n",
    "    'Mouse_Ortholog_Entrez': Mouse_Ortholog_Entrez_List,\n",
    "    'Assembly_Specific_Gene_Symbol': Assembly_Specific_Gene_Symbol_List,\n",
    "    'Gene_References': Gene_References_List,\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "df.to_excel('../Notebooks/Website Data/website_data.xlsx', sheet_name='Genes', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975cf6b",
   "metadata": {},
   "source": [
    "#### Combine different DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61015c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "All_Genes = pd.DataFrame()\n",
    "\n",
    "for i in range(1000, 35000, 1000):\n",
    "    Genes_temp = pd.read_excel('GeneIDs_' + str(i) + '.xlsx')\n",
    "    All_Genes = pd.concat([All_Genes, Genes_temp], ignore_index=True)\n",
    "All_Genes.to_excel('All_Genes.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
