{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "887d45b9",
   "metadata": {},
   "source": [
    "# Metabolites\n",
    "\n",
    "## Description\n",
    "In this notebook we create a dataframe containing all the available information for the metabolites accounted in our reconstruction.<br>\n",
    "[A. Generation of Metabolites dataset](#generation) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[1.Retreive info from our reconstruction](#rxns) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.Retrieve information from Recon3D, iCHO2291 and iCHO1766](#met) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[3.Add all the metabolites information into our metabolites dataset](#combine) <br><br>\n",
    "[B. Metabolites Curation](#curation) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.Update missing information in metabolites dataset](#missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67917966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import gspread\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "\n",
    "import cobra\n",
    "from cobra.io import read_sbml_model\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fc8106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "\n",
    "def df_to_dict(df, key_col):\n",
    "    \"\"\"\n",
    "    This function takes a pandas dataframe and a key column, and returns a dictionary\n",
    "    with the key column as the dictionary keys and the rest of the columns as the values.\n",
    "    \"\"\"\n",
    "    # Create an empty dictionary to hold the key-value pairs\n",
    "    my_dict = {}\n",
    "    \n",
    "    # Loop through each row in the dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        # Use the value in the key column as the dictionary key\n",
    "        key_value = row[key_col]\n",
    "        \n",
    "        # Use the rest of the columns as the dictionary values\n",
    "        value_dict = row.drop(key_col).to_dict()\n",
    "        \n",
    "        # Add the key-value pair to the dictionary\n",
    "        my_dict[key_value] = value_dict\n",
    "    \n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7ec3f1",
   "metadata": {},
   "source": [
    "<a id='generation'></a>\n",
    "## A. Generation of Metabolites dataset\n",
    "We start by creating a list of all the metabolites included in the reactions of our reconstruction (1). Then we create a dataset containing all the metabolites info from Recon3D, iCHO2291 and iCHO1766 models, including supplementary information from Recon 3D (2). Now we can map back this information into the metabolites from our reconstruction and generate an excell file for uploading into Google Sheets (3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df425e3",
   "metadata": {},
   "source": [
    "<a id='rxns'></a>\n",
    "### 1. Retrieve a list of all the metabolites from our reconstruction\n",
    "The list of all the reactions and the metabolites involved are in the Rxns Sheet in the Google Sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6873b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give service account details to gspread\n",
    "sa = gspread.service_account(filename='credentials.json')\n",
    "\n",
    "# sa is a gspread client, which can be used for connecting to the sheets\n",
    "# by using the open method and the sheet name.\n",
    "cho_recon = sa.open('CHO Network Reconstruction + Recon3D')\n",
    "\n",
    "# we also need to specify the page name before getting the data. In this case we use the Rxns sheet.\n",
    "rxns_sheet = cho_recon.worksheet('Rxns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2519b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can extract the data using the get_all_records method and create a pd DataFrame\n",
    "df = pd.DataFrame(rxns_sheet.get_all_records())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6618c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cobra model to identify the metabolites involved in our reconstruction\n",
    "model = cobra.Model(\"iCHOxxxx\")\n",
    "lr = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    r = cobra.Reaction(row['Reaction'])\n",
    "    lr.append(r)\n",
    "    \n",
    "model.add_reactions(lr)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c283ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the built in function \"build_reaction_from_string\" we can identify the metabolites\n",
    "for i,r in enumerate(tqdm(model.reactions)):\n",
    "    r.build_reaction_from_string(df['Reaction Formula'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9114e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first create a list of the metabolites and then a pandas df with it\n",
    "metabolites_list = []\n",
    "for met in model.metabolites:\n",
    "    metabolites_list.append(met.id)\n",
    "    \n",
    "metabolites = pd.DataFrame(metabolites_list, columns =['BiGG ID'])\n",
    "metabolites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9e37d9",
   "metadata": {},
   "source": [
    "<a id='met'></a>\n",
    "### 2. Retrieve information from all the metabolites on Recon3D, iCHO2291 and iCHO1766\n",
    "We use two datasets for this, first we take information from the Recon3D.xml, iCHO2291.xml and iCHO1766 files from which we get the metabolite ID, Name, Formula and Compartment. We then add the metadata for the available metabolites from Recon3D supplementary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fdb29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the Recon3D model\n",
    "recon3d_model = read_sbml_model('../Data/GPR_Curation/Recon3D.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df9b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dataset containing all the metabolites, chemical formula of each metabolite and compartment\n",
    "num_rows = len(recon3d_model.metabolites)\n",
    "recon3d_model_metabolites = pd.DataFrame(index=range(num_rows), columns=['BiGG ID', 'Name', 'Formula', 'Compartment'])\n",
    "for i,met in enumerate(recon3d_model.metabolites):\n",
    "    id_ = met.id\n",
    "    name = met.name\n",
    "    formula = met.formula\n",
    "    comp = met.compartment\n",
    "    recon3d_model_metabolites.iloc[i] = [id_, name, formula, comp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999568aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon3d_model_metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b2f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the Yeo's model\n",
    "iCHO2291_model = read_sbml_model('../Data/Reconciliation/models/iCHO2291.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff3f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dataset containing all the metabolites, chemical formula of each metabolite and compartment from Yeo's model\n",
    "num_rows = len(iCHO2291_model.metabolites)\n",
    "iCHO2291_model_metabolites = pd.DataFrame(index=range(num_rows), columns=['BiGG ID', 'Name', 'Formula', 'Compartment'])\n",
    "for i,met in enumerate(iCHO2291_model.metabolites):\n",
    "    id_ = met.id\n",
    "    name = met.name\n",
    "    formula = met.formula\n",
    "    comp = met.compartment\n",
    "    iCHO2291_model_metabolites.iloc[i] = [id_, name, formula, comp]\n",
    "    \n",
    "iCHO2291_model_metabolites['BiGG ID'] = iCHO2291_model_metabolites['BiGG ID'].str.replace(\"[\", \"_\", regex=False)\n",
    "iCHO2291_model_metabolites['BiGG ID'] = iCHO2291_model_metabolites['BiGG ID'].str.replace(\"]\", \"\", regex=False)\n",
    "iCHO2291_model_metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae64f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Hefzi's model\n",
    "iCHO1766_model = read_sbml_model('../Data/Reconciliation/models/iCHOv1_final.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a570b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dataset containing all the metabolites, chemical formula of each metabolite and compartment from Hefzi's model\n",
    "num_rows = len(iCHO1766_model.metabolites)\n",
    "iCHO1766_model_metabolites = pd.DataFrame(index=range(num_rows), columns=['BiGG ID', 'Name', 'Formula', 'Compartment'])\n",
    "for i,met in enumerate(iCHO1766_model.metabolites):\n",
    "    id_ = met.id\n",
    "    name = met.name\n",
    "    formula = met.formula\n",
    "    comp = met.compartment\n",
    "    iCHO1766_model_metabolites.iloc[i] = [id_, name, formula, comp]\n",
    "\n",
    "iCHO1766_model_metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2fb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_metabolites = pd.concat([recon3d_model_metabolites, iCHO2291_model_metabolites, iCHO1766_model_metabolites])\n",
    "models_metabolites = models_metabolites.groupby('BiGG ID').first()\n",
    "models_metabolites = models_metabolites.reset_index(drop = False)\n",
    "models_metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generation of a dataset containing all the information from Recon3D metabolites Supplementary Data.\n",
    "recon3d_metabolites_meta = pd.read_excel('../Data/Metabolites/metabolites.recon3d.xlsx', header = 0)\n",
    "recon3d_metabolites_meta['BiGG ID'] = recon3d_metabolites_meta['BiGG ID'].str.replace(\"[\", \"_\", regex=False)\n",
    "recon3d_metabolites_meta['BiGG ID'] = recon3d_metabolites_meta['BiGG ID'].str.replace(\"]\", \"\", regex=False)\n",
    "recon3d_metabolites_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec5b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of the \"recon3d_metabolites_meta\" into a dict to map it into the \"recon3d_model_metabolites\"\n",
    "recon3dmet_dict = df_to_dict(recon3d_metabolites_meta, 'BiGG ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c4e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping into the \"recon3d_model_metabolites\" dataset\n",
    "models_metabolites[['KEGG','CHEBI', 'PubChem','Inchi', 'Hepatonet', 'EHMNID', 'SMILES', 'INCHI2',\n",
    "                          'CC_ID','Stereoisomer Information of Metabolite Identified', 'Charge of the Metabolite Identified',\n",
    "    'CID_ID','PDB (ligand-expo) Experimental Coordinates  File Url', 'Pub Chem Url',\n",
    "    'ChEBI Url']] = models_metabolites['BiGG ID'].apply(lambda x: pd.Series(recon3dmet_dict.get(x, None), dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a69fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca8ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the final Recon3D Metabolites dataset into a dictionary to map it into our dataset\n",
    "final_met_dict = df_to_dict(models_metabolites, 'BiGG ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f8c927",
   "metadata": {},
   "source": [
    "<a id='combine'></a>\n",
    "### 3. Add all the metabolites information into our metabolites dataset\n",
    "With the dictionary created in **Step 2** we can use the information to map it in the metabolites dataset created in **Step 1** which contains all the metabolites of our reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f2e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metabolites[['Name', 'Formula', 'Compartment', 'KEGG','CHEBI', 'PubChem','Inchi', 'Hepatonet', 'EHMNID', 'SMILES',\n",
    "             'INCHI2','CC_ID','Stereoisomer Information of Metabolite Identified', 'Charge of the Metabolite Identified',\n",
    "    'CID_ID','PDB (ligand-expo) Experimental Coordinates  File Url', 'Pub Chem Url',\n",
    "    'ChEBI Url']] = metabolites['BiGG ID'].apply(lambda x: pd.Series(final_met_dict.get(x, None), dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed53515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the Compartment column in the final dataset\n",
    "for i,row in metabolites.iterrows():\n",
    "    if row['Compartment'] == 'c':\n",
    "        metabolites.loc[i, 'Compartment'] = 'c - cytosol'\n",
    "    if row['Compartment'] == 'l':\n",
    "        metabolites.loc[i, 'Compartment'] = 'l - lysosome'\n",
    "    if row['Compartment'] == 'm':\n",
    "        metabolites.loc[i, 'Compartment'] = 'm - mitochondria'\n",
    "    if row['Compartment'] == 'r':\n",
    "        metabolites.loc[i, 'Compartment'] = 'r - endoplasmic reticulum'\n",
    "    if row['Compartment'] == 'e':\n",
    "        metabolites.loc[i, 'Compartment'] = 'e - extracellular space'\n",
    "    if row['Compartment'] == 'x':\n",
    "        metabolites.loc[i, 'Compartment'] = 'x - peroxisome/glyoxysome'\n",
    "    if row['Compartment'] == 'n':\n",
    "        metabolites.loc[i, 'Compartment'] = 'n - nucleus'\n",
    "    if row['Compartment'] == 'g':\n",
    "        metabolites.loc[i, 'Compartment'] = 'g - golgi apparatus'\n",
    "    if row['Compartment'] == 'im':\n",
    "        metabolites.loc[i, 'Compartment'] = 'im - intermembrane space of mitochondria'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcbe9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metabolites.to_excel('../Data/Metabolites/metabolites.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea810d78",
   "metadata": {},
   "source": [
    "### 4. Unique metabolite identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87044260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give service account details to gspread\n",
    "sa = gspread.service_account(filename='credentials.json')\n",
    "\n",
    "# sa is a gspread client, which can be used for connecting to the sheets\n",
    "# by using the open method and the sheet name.\n",
    "cho_recon = sa.open('CHO Network Reconstruction + Recon3D')\n",
    "\n",
    "# we also need to specify the page name before getting the data. In this case we use the Rxns sheet.\n",
    "metabolites_sheet = cho_recon.worksheet('Metabolites')\n",
    "\n",
    "# We can extract the data using the get_all_records method and create a pd DataFrame\n",
    "metabolites = pd.DataFrame(metabolites_sheet.get_all_records())\n",
    "metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0000243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duplicated rxns by BiGG ID = \", len(metabolites['BiGG ID']) - len(metabolites['BiGG ID'].unique()))\n",
    "print(\"Duplicated rxns by Name = \", len(metabolites['Name']) - len(metabolites['Name'].unique()))\n",
    "print(\"Duplicated rxns by Formula = \", len(metabolites['Formula']) - len(metabolites['Formula'].unique()))\n",
    "print(\"Duplicated rxns by KEGG = \", len(metabolites['KEGG']) - len(metabolites['KEGG'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d88b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the metabolites by formula and create an excel file to curate them manually.\n",
    "grouped_by_formula = metabolites.groupby('Formula', group_keys=True).apply(lambda x:x)\n",
    "grouped_by_formula.to_excel('../Data/Metabolites/grouped_by_formula_recon3d.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a403d884",
   "metadata": {},
   "source": [
    "<a id='curation'></a>\n",
    "## B. Metabolites Curation\n",
    "In this second part of the notebook we curate missing information in the metabolites dataset generated above. Since many metabolites have been manually curated in the \"Metabolites\" google sheet file, we generate a new dataframe using the gspread library to obtain the metabolites dataset with all the changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344cfb7a",
   "metadata": {},
   "source": [
    "<a id='missing'></a>\n",
    "### 5. Update missing information in metabolites dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb61a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give service account details to gspread\n",
    "sa = gspread.service_account(filename='credentials.json')\n",
    "\n",
    "# sa is a gspread client, which can be used for connecting to the sheets\n",
    "# by using the open method and the sheet name.\n",
    "cho_recon = sa.open('CHO Network Reconstruction + Recon3D')\n",
    "\n",
    "# we also need to specify the page name before getting the data. In this case we use the Rxns sheet.\n",
    "metabolites_sheet = cho_recon.worksheet('Metabolites')\n",
    "rxns_sheet = cho_recon.worksheet('Rxns')\n",
    "attributes_sheet = cho_recon.worksheet('Attributes')\n",
    "\n",
    "# We can extract the data using the get_all_records method and create a pd DataFrame\n",
    "metabolites = pd.DataFrame(metabolites_sheet.get_all_records())\n",
    "rxns = pd.DataFrame(rxns_sheet.get_all_records())\n",
    "attributes = pd.DataFrame(attributes_sheet.get_all_records())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d747138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get BiGG descriptive names\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Unknown Mets: metabolites without names\n",
    "unkown_mets = metabolites[metabolites['Name'] == '']\n",
    "\n",
    "Descriptive_Names = [''] * len(unkown_mets)\n",
    "Formulae = [''] * len(Descriptive_Names)\n",
    "Changed = [True] * len(Descriptive_Names)\n",
    "\n",
    "for Met_Counter, metID in enumerate(tqdm(unkown_mets['BiGG ID'].iloc[:])):\n",
    "    print(Met_Counter)\n",
    "    input_str = metID[:-2]\n",
    "    response = requests.get(f\"http://bigg.ucsd.edu/universal/metabolites/{input_str}\")\n",
    "    time.sleep(1)\n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        D_Name = \"BiGG ID not found in BiGG\"\n",
    "        Formulae_B = \"BiGG ID not found in BiGG\"\n",
    "        Changed[Met_Counter] = False       \n",
    "    else:    \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        N_Header = soup.find('h4', string='Descriptive name:')\n",
    "        D_Name = N_Header.find_next_sibling('p').text\n",
    "        N_Formulae = soup.find('h4', string='Formulae in BiGG models: ')\n",
    "        Formulae_B = N_Formulae.find_next_sibling('p').text    \n",
    "        if D_Name is None:\n",
    "            D_Name = \"Name not found in BiGG\"            \n",
    "        elif Formulae_B is None:\n",
    "            Formulae_B = \"Formula not found in BiGG\"                \n",
    "    Descriptive_Names[Met_Counter] = D_Name\n",
    "    Formulae[Met_Counter] = Formulae_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f84cd90",
   "metadata": {},
   "source": [
    "### Update empty metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2337154",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Met_Counter, metID in enumerate(unkown_mets['BiGG ID']):\n",
    "    print('before',unkown_mets['BiGG ID'].iloc[Met_Counter])\n",
    "    print('before',unkown_mets['Formula'].iloc[Met_Counter])\n",
    "    print('before',unkown_mets['Name'].iloc[Met_Counter])\n",
    "    if unkown_mets['Formula'].iloc[Met_Counter] == '':\n",
    "        unkown_mets['Formula'].iloc[Met_Counter] = Formulae[Met_Counter]  \n",
    "    unkown_mets['Name'].iloc[Met_Counter] = Descriptive_Names[Met_Counter]\n",
    "    print('..............................................')\n",
    "    print('after',unkown_mets['BiGG ID'].iloc[Met_Counter])\n",
    "    print('after',unkown_mets['Formula'].iloc[Met_Counter])\n",
    "    print('after',unkown_mets['Name'].iloc[Met_Counter])\n",
    "    print('..............................................')\n",
    "    print('..............................................')\n",
    "    print('..............................................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15986e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metabolites.update(unkown_mets)\n",
    "\n",
    "# Manual Curation\n",
    "for bigg_id in metabolites['BiGG ID']:\n",
    "    # xtra = Xanthurenic acid; C10H6NO4\n",
    "    # http://bigg.ucsd.edu/models/iCHOv1/reactions/r0647\n",
    "    if 'xtra' in bigg_id:\n",
    "        metabolites.loc[metabolites['BiGG ID'] == bigg_id, 'Name'] = 'Xanthurenic acid'\n",
    "        metabolites.loc[metabolites['BiGG ID'] == bigg_id, 'Formula'] = 'C10H6NO4'\n",
    "    # chedxch = Bilirubin-monoglucuronoside; C39H42N4O122-\n",
    "    # Reactions name = 'ATP-binding Cassette (ABC) TCDB:3.A.1.208.2' --> https://metabolicatlas.org/identifier/TCDB/3.A.1.208.2\n",
    "    elif 'chedxch' in bigg_id:\n",
    "        metabolites.loc[metabolites['BiGG ID'] == bigg_id, 'Name'] = 'Bilirubin-monoglucuronoside'\n",
    "        metabolites.loc[metabolites['BiGG ID'] == bigg_id, 'Formula'] = 'C39H42N4O122-'\n",
    "    # chatGTP\n",
    "    elif '3hoc246_6Z_9Z_12Z_15Z_18Z_21Zcoa' in bigg_id:\n",
    "        metabolites.loc[metabolites['BiGG ID'] == bigg_id, 'Name'] = 'CoA molecule that has a 24-carbon fatty acid with six double bonds, with the location of the double bonds specified by the numbers and Zs'\n",
    "    # chatGTP\n",
    "    elif 'c247_2Z_6Z_9Z_12Z_15Z_18Z_21Zcoa' in bigg_id:\n",
    "        metabolites.loc[metabolites['BiGG ID'] == bigg_id, 'Name'] = 'CoA molecule that has a modified version of the same 24-carbon fatty acid, with a hydroxyl group added at the third carbon position'\n",
    "    # chatGTP\n",
    "    elif '3hoc143_5Z_8Z_11Zcoa' in bigg_id:\n",
    "        metabolites.loc[metabolites['BiGG ID'] == bigg_id, 'Name'] = 'CoA molecule that has a 14-carbon fatty acid with three double bonds, with the location of the double bonds specified by the numbers and Zs.'\n",
    "    # chatGTP\n",
    "    elif '3oc143_5Z_8Z_11Zcoa' in bigg_id:\n",
    "        metabolites.loc[metabolites['BiGG ID'] == bigg_id, 'Name'] = 'CoA molecule that has a modified version of the same 14-carbon fatty acid, with the hydroxyl group removed and one of the double bonds converted to a keto group'\n",
    "    # chatGTP\n",
    "    elif 'acgalgalacglcgalgluside' in bigg_id:\n",
    "        metabolites.loc[metabolites['BiGG ID'] == bigg_id, 'Name'] = 'Complex glycosphingolipid that contains multiple sugar residues'\n",
    "\n",
    "    # 12e8hdx WTF?\n",
    "    # hdxur Dead End\n",
    "\n",
    "metabolites.to_excel('../Data/Metabolites/metabolites_final.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb3abfc",
   "metadata": {},
   "source": [
    "### 6. Identification of duplicated metabolites\n",
    "The idea here is to add the metabolites from the reactions added from Recon 3D, at the same time that we do not over write data from our own Metabolites dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ea6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give service account details to gspread\n",
    "sa = gspread.service_account(filename='credentials.json')\n",
    "\n",
    "# sa is a gspread client, which can be used for connecting to the sheets\n",
    "# by using the open method and the sheet name.\n",
    "cho_recon = sa.open('CHO Network Reconstruction + Recon3D_v2')\n",
    "\n",
    "# we also need to specify the page name before getting the data. In this case we use the Rxns sheet.\n",
    "met_sheet = cho_recon.worksheet('Metabolites')\n",
    "rxns_sheet = cho_recon.worksheet('Rxns')\n",
    "attributes_sheet = cho_recon.worksheet('Attributes')\n",
    "\n",
    "# We can extract the data using the get_all_records method and create a pd DataFrame\n",
    "met = pd.DataFrame(met_sheet.get_all_records())\n",
    "rxns = pd.DataFrame(rxns_sheet.get_all_records())\n",
    "attributes = pd.DataFrame(attributes_sheet.get_all_records())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d42b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert metabolites names to lower case and remove the compartment\n",
    "met['Name'] = met['Name'].str.lower()\n",
    "met_copy = met.copy()\n",
    "met_copy['BiGG ID'] = met_copy['BiGG ID'].str[:-2]\n",
    "met_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838db9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list with duplicated metabolites\n",
    "\n",
    "grouped = met_copy.groupby(['Name', 'Formula'])\n",
    "\n",
    "# Initialize an empty dictionary to store the results\n",
    "duplicated_metabolites = []\n",
    "\n",
    "# Iterate over the grouped DataFrame\n",
    "for (Name, Formula), group in grouped:\n",
    "    # Check if the group has more than one element (i.e., duplicate) and filter out those metabolites whose names are unknown\n",
    "    if group['BiGG ID'].nunique() > 1 and Name != 'bigg id not found in bigg':\n",
    "        unique_ids = group['BiGG ID'].unique()\n",
    "        duplicated_metabolites.append((Name, Formula, unique_ids))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c80894",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(duplicated_metabolites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6eefb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate empty dict to store the existence of each duplicated metabolite in BiGG\n",
    "duplicated_dict = {}\n",
    "\n",
    "\n",
    "for metabolite in tqdm(duplicated_metabolites):\n",
    "    duplicated_dict[metabolite[0]] = {}\n",
    "    for big_id in metabolite[2]:\n",
    "        time.sleep(1)\n",
    "        # Check if the metabolite is in BiGG \"OK\" or not \"NO\"\n",
    "        response = requests.get(f\"http://bigg.ucsd.edu/universal/metabolites/{big_id}\")\n",
    "        if response.status_code == 200:\n",
    "            duplicated_dict[metabolite[0]][big_id] = 'OK'\n",
    "        else:\n",
    "            duplicated_dict[metabolite[0]][big_id] ='NO'\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f4d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91e7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the 'OK' subkey for each key in duplicated_dict\n",
    "ok_dict = {}\n",
    "\n",
    "# Iterate over keys in duplicated_dict\n",
    "for key in duplicated_dict:\n",
    "    # Create an empty list to store 'NO' subkeys for this key\n",
    "    no_list = []\n",
    "    # Iterate over subkeys and values in sub-dictionary\n",
    "    for subkey, value in duplicated_dict[key].items():\n",
    "        # If the value is 'OK', save the subkey to a variable\n",
    "        if value == 'OK':\n",
    "            ok_dict[key] = subkey\n",
    "        # If the value is 'NO', add the subkey to the list\n",
    "        elif value == 'NO':\n",
    "            no_list.append(subkey)\n",
    "    # Replace all 'NO' subkeys with the 'OK' subkey for this key\n",
    "    if key in ok_dict:\n",
    "        ok_subkey = ok_dict[key]\n",
    "        for no_subkey in no_list:\n",
    "            met['BiGG ID'] = met['BiGG ID'].str.replace(no_subkey, ok_subkey)\n",
    "            rxns['Reaction Formula'] = rxns['Reaction Formula'].str.replace(no_subkey, ok_subkey)\n",
    "            attributes['Reaction Formula'] = attributes['Reaction Formula'].str.replace(no_subkey, ok_subkey)\n",
    "    # Reset the 'ok_subkey' and 'no_subkey' variables at the end of each iteration over keys\n",
    "    ok_dict[key] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb146c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "met = met.groupby('BiGG ID').first()\n",
    "met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c68e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "met.to_excel('met.xlsx')\n",
    "rxns.to_excel('rxns.xlsx')\n",
    "attributes.to_excel('attribute.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e61ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcb713e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740198b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe from Google Sheet:\n",
      "      Curated      Reaction                               Reaction Name  \\\n",
      "0         PD  10FTHF5GLUtl      5-glutamyl-10fthf transport, lysosomal   \n",
      "1         PD  10FTHF5GLUtm  5-glutamyl-10fthf transport, mitochondrial   \n",
      "2         PD  10FTHF6GLUtl      6-glutamyl-10fthf transport, lysosomal   \n",
      "3         PD  10FTHF6GLUtm  6-glutamyl-10fthf transport, mitochondrial   \n",
      "4         PD  10FTHF7GLUtl      7-glutamyl-10fthf transport, lysosomal   \n",
      "...      ...           ...                                         ...   \n",
      "8195                 r2534      major facilitator(mfs) tcdb:2.a.1.44.1   \n",
      "8196                 r2535      major facilitator(mfs) tcdb:2.a.1.44.1   \n",
      "8197                 r2537                          utilized transport   \n",
      "8198                 r2538                          utilized transport   \n",
      "8199                 r2539               postulated transport reaction   \n",
      "\n",
      "                                       Reaction Formula  \\\n",
      "0                         10fthf5glu_c --> 10fthf5glu_l   \n",
      "1                         10fthf5glu_m --> 10fthf5glu_c   \n",
      "2                         10fthf6glu_c --> 10fthf6glu_l   \n",
      "3                         10fthf6glu_m --> 10fthf6glu_c   \n",
      "4                         10fthf7glu_c --> 10fthf7glu_l   \n",
      "...                                                 ...   \n",
      "8195                              thr_L_e  <=> thr_L_c    \n",
      "8196                                hom_L_e <=> hom_L_c   \n",
      "8197                        lnlncgcoa_c <=> lnlncgcoa_r   \n",
      "8198                        dlnlcgcoa_c <=> dlnlcgcoa_r   \n",
      "8199  L2aadp6sa_c + L2aadp_m <=> L2aadp6sa_m + L2aadp_c   \n",
      "\n",
      "                     Subsystem GPR_hef GPR_fou    GPR_yeo GPR_Recon3D  \\\n",
      "0         TRANSPORT, LYSOSOMAL                                          \n",
      "1     TRANSPORT, MITOCHONDRIAL                                          \n",
      "2         TRANSPORT, LYSOSOMAL                                          \n",
      "3     TRANSPORT, MITOCHONDRIAL                                          \n",
      "4         TRANSPORT, LYSOSOMAL                                          \n",
      "...                        ...     ...     ...        ...         ...   \n",
      "8195  TRANSPORT, EXTRACELLULAR                  100757617   100757617   \n",
      "8196                 Transport                  100757617   100757617   \n",
      "8197                 Transport    None    None       None        None   \n",
      "8198                 Transport    None    None       None        None   \n",
      "8199                 Transport    None    None       None        None   \n",
      "\n",
      "      GPR_final Conf. Score  \\\n",
      "0                         1   \n",
      "1                         1   \n",
      "2                         1   \n",
      "3                         1   \n",
      "4                         1   \n",
      "...         ...         ...   \n",
      "8195  100757617        None   \n",
      "8196  100757617        None   \n",
      "8197       None        None   \n",
      "8198       None        None   \n",
      "8199       None        None   \n",
      "\n",
      "                                         Curation Notes References  \n",
      "0     No information available in the literature abo...       None  \n",
      "1     No information available in the literature abo...       None  \n",
      "2     No information available in the literature abo...       None  \n",
      "3     No information available in the literature abo...       None  \n",
      "4     No information available in the literature abo...       None  \n",
      "...                                                 ...        ...  \n",
      "8195                                               None       None  \n",
      "8196                                               None       None  \n",
      "8197                                               None       None  \n",
      "8198                                               None       None  \n",
      "8199                                               None       None  \n",
      "\n",
      "[8200 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "from google_sheet import GoogleSheet\n",
    "\n",
    "KEY_FILE_PATH = '/Users/pablodigiusto/Documents/GitHub/Whole-Cell-Network-Reconstruction-for-CHO-cells/Notebooks/credentials.json'\n",
    "SPREADSHEET_ID = '1ue3VOG07G1IGaQ6xBkEcu7Q1rB8mbncO1pP_T9Eb7gw'\n",
    "\n",
    "# Initialize the GoogleSheet object\n",
    "sheet = GoogleSheet(SPREADSHEET_ID, KEY_FILE_PATH)\n",
    "\n",
    "# Read data from the Google Sheet\n",
    "sheet_name = 'Rxns'\n",
    "dataframe = sheet.read_google_sheet(sheet_name)\n",
    "print(\"Dataframe from Google Sheet:\\n\", dataframe)\n",
    "\n",
    "# Make some changes to the dataframe\n",
    "# ...\n",
    "\n",
    "# Update the Google Sheet with the modified DataFrame\n",
    "sheet.update_google_sheet(sheet_name, dataframe)\n",
    "print(\"Google Sheet updated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
