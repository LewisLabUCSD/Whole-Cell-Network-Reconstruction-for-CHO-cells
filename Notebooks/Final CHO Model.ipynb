{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15ecee4b",
   "metadata": {},
   "source": [
    "# Final CHO Model\n",
    "This notebook is to asses the validity of our reconstruction and how complete it is.\n",
    "\n",
    "[1. Generation of the dataset and model reconstruction](#generation) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1.1 Retrieve information from the Google Sheet datasets reactions and metabolites**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1.2 Build a model and feed it the information from the df generated** <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1.3 Save and validate the model** <br>\n",
    "\n",
    "[2. Identification of Blocked Reactions and Dead-End Metabolites](#blocked&deadends) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**2.1 Retrieve information from the Google Sheet datasets reactions and metabolites**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**2.2 Build a model and feed it the information from the df generated** <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**2.3 Save and validate the model** <br>\n",
    "\n",
    "[3. Generation of the Mass Flow Graph](#MFG) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**3.1 Generation of the \"D-Matrix\"**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**3.2 Plotting the \"D-Matrix\", Normalized Flow Graph (NFG)** <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**3.3 Generation of the \"FluxOpenValue\" matrix** <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**3.4 Generation of the \"Mass Flow Graph (MFG) Matrix\"** <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**3.5 Plotting the \"MFG Matrix\"** <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12c1047d",
   "metadata": {},
   "source": [
    "## 1. Generation of the dataset and model reconstruction <a id='generation'></a>\n",
    "Here we generate the CHO model from the dataset stored in the Google Sheet file. We first use the google_sheet module to extract all the necessary information from the original dataset. Then we use those dataset and the COBRApy library to: (1) Create a new model and add reactions from the **Rxns Sheet**, (2) Add information on each reaction obtained from the **Rxns Sheet** and **Attributes Sheet**, (3) Add boundary reactions from the **BoundaryRxns Sheet**, and (4) Add information for each metabolite from the **Metabolites Sheet**. Finally we save the model as a SBML file and validate it using the cobrapy built-in function \"validate_sbml_model( )\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77cf3103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cobra\n",
    "from cobra import Model, Reaction, Metabolite\n",
    "from cobra.io import validate_sbml_model, write_sbml_model\n",
    "from tqdm.notebook import tqdm\n",
    "from google_sheet import GoogleSheet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db8ed354",
   "metadata": {},
   "source": [
    "### 1.1 Retrieve information from the Google Sheet datasets reactions and metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "719281dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- Generate datasets from Google Sheet ----- #####\n",
    "\n",
    "#Credential file\n",
    "KEY_FILE_PATH = 'credentials.json'\n",
    "\n",
    "# #CHO Network Reconstruction + Recon3D_v2 Google Sheet ID\n",
    "# SPREADSHEET_ID = '1MlBXeHIKw8k8fZyXm-sN__AHTRSunJxar_-bqvukZws'\n",
    "\n",
    "#CHO Network Reconstruction + Recon3D_v3 Google Sheet ID\n",
    "SPREADSHEET_ID = '1MlBXeHIKw8k8fZyXm-sN__AHTRSunJxar_-bqvukZws'\n",
    "\n",
    "# Initialize the GoogleSheet object\n",
    "sheet = GoogleSheet(SPREADSHEET_ID, KEY_FILE_PATH)\n",
    "\n",
    "# Read data from the Google Sheet\n",
    "sheet_met = 'Metabolites'\n",
    "sheet_rxns = 'Rxns'\n",
    "sheet_attributes = 'Attributes'\n",
    "sheet_boundary = 'BoundaryRxns'\n",
    "\n",
    "metabolites = sheet.read_google_sheet(sheet_met)\n",
    "rxns = sheet.read_google_sheet(sheet_rxns)\n",
    "rxns_attributes = sheet.read_google_sheet(sheet_attributes)\n",
    "boundary_rxns = sheet.read_google_sheet(sheet_boundary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77bcd212",
   "metadata": {},
   "source": [
    "### 1.2 Build a model and feed it the information from the df generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "927503f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Name</strong></td>\n",
       "                <td>iCHO</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>156fb6b60</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of metabolites</strong></td>\n",
       "                <td>0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of reactions</strong></td>\n",
       "                <td>10692</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of genes</strong></td>\n",
       "                <td>0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of groups</strong></td>\n",
       "                <td>0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Objective expression</strong></td>\n",
       "                <td>0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Compartments</strong></td>\n",
       "                <td></td>\n",
       "            </tr>\n",
       "          </table>"
      ],
      "text/plain": [
       "<Model iCHO at 0x156fb6b60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### ----- Create a model and add reactions ----- #####\n",
    "model = Model(\"iCHO\")\n",
    "lr = []\n",
    "for _, row in rxns.iterrows():\n",
    "    r = Reaction(row['Reaction'])\n",
    "    lr.append(r)    \n",
    "model.add_reactions(lr)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c619ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- Add information to each one of the reactions ----- #####\n",
    "for i,r in enumerate(tqdm(model.reactions)):\n",
    "    print(r.id)\n",
    "    r.build_reaction_from_string(rxns['Reaction Formula'][i])\n",
    "    r.name = rxns['Reaction Name'][i]\n",
    "    r.subsystem = rxns['Subsystem'][i]\n",
    "    r.gene_reaction_rule = str(rxns['GPR_final'][i])\n",
    "    r.lower_bound = float(rxns_attributes['Lower bound'][i])\n",
    "    r.upper_bound = float(rxns_attributes['Upper bound'][i])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4567f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4039a340ee41b796b1747ecc460c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Name</strong></td>\n",
       "                <td>iCHO</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>156fb6b60</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of metabolites</strong></td>\n",
       "                <td>8004</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of reactions</strong></td>\n",
       "                <td>11668</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of genes</strong></td>\n",
       "                <td>3182</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of groups</strong></td>\n",
       "                <td>0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Objective expression</strong></td>\n",
       "                <td>0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Compartments</strong></td>\n",
       "                <td></td>\n",
       "            </tr>\n",
       "          </table>"
      ],
      "text/plain": [
       "<Model iCHO at 0x156fb6b60>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### ----- Add Boundary Reactions ----- #####\n",
    "dr = []\n",
    "for _, row in boundary_rxns.iterrows():\n",
    "    r = Reaction(row['Reaction'])\n",
    "    dr.append(r)    \n",
    "model.add_reactions(dr)\n",
    "\n",
    "boundary_rxns_dict = boundary_rxns.set_index('Reaction').to_dict()\n",
    "boundary_rxns_dict\n",
    "\n",
    "for i,r in enumerate(tqdm(model.reactions)):\n",
    "    if r in dr:\n",
    "        r.build_reaction_from_string(boundary_rxns_dict['Reaction Formula'][r.id])\n",
    "        r.name = boundary_rxns_dict['Reaction Name'][r.id]\n",
    "        r.subsystem = boundary_rxns_dict['Subsystem'][r.id]\n",
    "        r.lower_bound = float(boundary_rxns_dict['Lower bound'][r.id])\n",
    "        r.upper_bound = float(boundary_rxns_dict['Upper bound'][r.id]) \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d22a76a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- Add information for each metabolite ----- #####\n",
    "metabolites_dict = metabolites.set_index('BiGG ID').to_dict('dict')\n",
    "metabolites_dict['Name']\n",
    "for met in model.metabolites:\n",
    "    met.name = metabolites_dict['Name'][f'{met}']\n",
    "    met.formula = metabolites_dict['Formula'][f'{met}']\n",
    "    met.compartment = metabolites_dict['Compartment'][f'{met}'].split(' - ')[0]    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82092731",
   "metadata": {},
   "source": [
    "### 1.3 Save and validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "612e8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- Build the S matrix ----- #####\n",
    "S = cobra.util.create_stoichiometric_matrix(model, array_type='dense')\n",
    "model.S = S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8faa6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- Save the model ----- #####\n",
    "write_sbml_model(model, \"iCHOv3_CHO_23052023.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "308f68ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SBML errors in validation, check error log for details.\n",
      "COBRA errors in validation, check error log for details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SBML_FATAL': [],\n",
       " 'SBML_ERROR': [\"E0 (Error): SBML component consistency (fbc, L178736); An <objective> must have one <listOfFluxObjectives>.; An <objective> object must have one and only one instance of the <listOfFluxObjectives> object. \\nReference: L3V1 Fbc V3, Section 3.6\\n <objective> 'obj' has no listOfFluxObjectives.\\n\"],\n",
       " 'SBML_SCHEMA_ERROR': [],\n",
       " 'SBML_WARNING': [],\n",
       " 'COBRA_FATAL': [],\n",
       " 'COBRA_ERROR': ['No objective coefficients in model. Unclear what should be optimized'],\n",
       " 'COBRA_WARNING': [],\n",
       " 'COBRA_CHECK': []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### ----- Test for errors in the recostruction ----- ######\n",
    "\n",
    "# import tempfile\n",
    "# from pprint import pprint\n",
    "# from cobra.io import write_sbml_model, validate_sbml_model\n",
    "# with tempfile.NamedTemporaryFile(suffix='.xml') as f_sbml:\n",
    "#     write_sbml_model(model, filename=f_sbml.name)\n",
    "#     report = validate_sbml_model(filename=f_sbml.name)\n",
    "# pprint(report)\n",
    "\n",
    "from cobra.io import read_sbml_model, validate_sbml_model\n",
    "(_, errors) = validate_sbml_model(\"iCHOv3_CHO+Recon_v3.xml\")\n",
    "errors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f2da40b",
   "metadata": {},
   "source": [
    "## 2. Identification of Blocked Reactions and Dead-End Metabolites <a id='blocked&deadends'></a>\n",
    "In this second part of the notebook we use two different functions from the utils module to: (1) Run a flux variability analysis and identify blocked reactions, and (2) identify dead-end metabolites. Finally we add Extracellular Exchange reactions for the dead-end metabolites that are in the extracellular compartment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ed9b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- Read Model ----- #####\n",
    "from cobra.io import read_sbml_model\n",
    "model = read_sbml_model(\"iCHOv3_CHO+Recon_v3.xml\")\n",
    "\n",
    "for rxn_exchange in model.exchanges:\n",
    "    rxn_exchange.bounds = (-1000, 1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0919b458",
   "metadata": {},
   "source": [
    "### 2.1 Identification of Blocked Reactions\n",
    "The runMinMax_Single( ) function from the utils module runs an FVA (flux variability analysis) to find the ranges of each reaction's metabolic flux at the optimum. The results are stored in the \"FVA_Results.txt\" file with all the reactions IDs and its respective fluxes. Reactions with no flux (**Blocked Reactions**) are stored in another file called \"Blocked_Reactions.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fac986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- FVA ----- #####\n",
    "import importlib\n",
    "# from utils import runMinMax_GF\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "model.solver = 'gurobi'\n",
    "\n",
    "\n",
    "for rxn in model.reactions:\n",
    "    rxn.bounds = -1000, 1000\n",
    "minmax = utils.runMinMax_Single(model, end_rxn_index=None)\n",
    "\n",
    "##### Print Reactions with the min and max fluxes #####\n",
    "with open('FVA_Results.txt', 'w') as f:\n",
    "    for i, j in enumerate(minmax):\n",
    "        print(model.reactions[i].id, \"Min: \",j[0], \"Max: \", j[1], file=f)\n",
    "        \n",
    "##### Print Blocked Reactions #####\n",
    "with open('Blocked_Reactions.txt', 'w') as f:\n",
    "    for i, j in enumerate(minmax):\n",
    "        if j[0] == 0 and j[1] == 0:\n",
    "            print(model.reactions[i].id, \"Min: \",j[0], \"Max: \", j[1], file=f)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26ab78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- Print the amount  and % of blocked reactions ----- #####\n",
    "blocked_reactions = []\n",
    "for i, j in enumerate(minmax):\n",
    "        if j[0] == 0 and j[1] == 0:\n",
    "            blocked_reactions.append(model.reactions[i].id)\n",
    "            \n",
    "print('##### ----- Blocked Reactions ----- #####')\n",
    "print(f'The model has {len(model.reactions)} total reactions')\n",
    "print(f'The model has {len(blocked_reactions)} ({round(len(blocked_reactions)/len(model.reactions)*100)}%) blocked reactions')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69857e39",
   "metadata": {},
   "source": [
    "### 2.1 Identification of Dead-Ends Metabolites\n",
    "The detect_dead_ends( ) function from the utils module returns a list with all the **dead-end** metabolites in our model. A dead-end metabolite refers to a metabolite that is either only consumed but not produced, or only produced but not consumed, in a given metabolic network. The results are stored in the \"Dead-ends.txt\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29332b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- Detect Dead-Ends ----- #####\n",
    "from utils import detect_dead_ends\n",
    "dead_ends = detect_dead_ends(model)\n",
    "model.solver = 'gurobi' #change 'gurobi' for 'glpk'\n",
    "\n",
    "with open('Dead_ends.txt', 'w') as f:\n",
    "    for i,j in enumerate(dead_ends):\n",
    "        if j:\n",
    "            print(model.metabolites[i], file=f)\n",
    "            \n",
    "rxn_c = 0\n",
    "met_c = 0\n",
    "for i,j in enumerate(dead_ends):\n",
    "    if j:\n",
    "        met_c += 1\n",
    "        print(\"\\n\", model.metabolites[i],\": \")\n",
    "        for met_rxn in model.metabolites[i].reactions:\n",
    "            rxn_c += 1\n",
    "            print(met_rxn)\n",
    "            print(rxn_c)\n",
    "\n",
    "print(f'Percentage of Dead-End metabolites is {round(met_c/len(model.metabolites)*100)}%' )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "699099c9",
   "metadata": {},
   "source": [
    "### 2.3 Addition of Extracellular Exchange Reanctions\n",
    "The following cell adds **EXTRACELLULAR EXCHANGE** reactions to the dead-end metabolites in the extracellular compartment from the list generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60831416",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- Automatically add EXTRACELLULAR EXCHANGE reactions to the \"BoundaryRxns\" Sheet ----- #####\n",
    "for i,j in enumerate(dead_ends):\n",
    "    if j:\n",
    "        if str(model.metabolites[i]).endswith('_e'):\n",
    "            new_row_data = {'Curated': '', 'Reaction': 'EX_'+str(model.metabolites[i]), 'Reaction Name': 'Exchange of '+model.metabolites[i].name, 'Reaction Formula': str(model.metabolites[i])+' <=>', 'Subsystem': 'EXTRACELLULAR EXCHANGE',\n",
    "                                    'Reversible': 1, 'Lower bound': -1000, 'Upper bound': 1000, 'Objective': 0}\n",
    "            new_row_df = pd.DataFrame(new_row_data, index=[len(boundary_rxns)])\n",
    "            boundary_rxns = pd.concat([boundary_rxns, new_row_df])\n",
    "\n",
    "#Check for duplicated reactions added to the boundary_rxns dataset, IF NOT: update the google sheet file\n",
    "if not boundary_rxns['Reaction'].duplicated().any() and not boundary_rxns['Reaction Formula'].duplicated().any():\n",
    "    sheet.update_google_sheet(sheet_boundary, boundary_rxns)\n",
    "    print(\"BoundaryRxns Google Sheet updated.\")\n",
    "else:\n",
    "    print('Duplicated values found in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef010881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from cobra.flux_analysis import gapfill\n",
    "#\n",
    "#recon3d = cobra.io.read_sbml_model('../Data/GPR_Curation/Recon3D.xml')\n",
    "#solution = gapfill(model, recon3d, demand_reactions=False)\n",
    "#\n",
    "#for r in solution[0]:\n",
    "#    print(r.id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25038fb8",
   "metadata": {},
   "source": [
    "### Test CHO - Recon GEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "576c5620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iCHO_recon3dfrom cobra.io import read_sbml_model\n",
    "# read_sbml_model(\".xml\")\n",
    "\n",
    "model_EX = [i for i, rxn in enumerate(model.reactions) if 'EX_' in rxn.id]\n",
    "model_SK = [i for i, rxn in enumerate(model.reactions) if 'SK_' in rxn.id]\n",
    "model_DM = [i for i, rxn in enumerate(model.reactions) if 'DM_' in rxn.id]\n",
    "for i in model_EX:\n",
    "    model.reactions[i].bounds = -1000, 1000\n",
    "\n",
    "for i in model_SK:\n",
    "    model.reactions[i].bounds = -1000, 1000\n",
    "\n",
    "for i in model_DM:\n",
    "    model.reactions[i].bounds = 0, 1000\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7374e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.objective = \"biomass\" # \n",
    "sol1 = model.optimize()\n",
    "print(sol1.objective_value)\n",
    "\n",
    "model.objective = \"biomass_prod\" # \n",
    "sol2 = model.optimize()\n",
    "print(sol2.objective_value)\n",
    "\n",
    "model.objective = \"biomass_producing\" # \n",
    "sol3 = model.optimize()\n",
    "print(sol3.objective_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af33f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- Test model KOs ----- #####\n",
    "for reaction in model.reactions:\n",
    "    with model as model:\n",
    "        reaction.knock_out()\n",
    "        model.optimize()\n",
    "        print('%s blocked (bounds: %s), new growth rate %f' %\n",
    "              (reaction.id, str(reaction.bounds), model.objective.value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a70e7b26",
   "metadata": {},
   "source": [
    "## 3. Generation of the Mass Flow Graph <a id='MFG'></a>\n",
    "Based on the publication **_Flux-dependent graphs for metabolic networks_** by _Beguerisse-Diaz et al. (2018)_ (https://www.nature.com/articles/s41540-018-0067-y). Here we use our model to build the **D Matrix** and plot the corresponding graph, then the **M Matrix** and plot the corresponding graph, and finally we generate the **PageRank** file with all the reactions in our reconstruction sorted by importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055cf1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from scipy.linalg import pinv\n",
    "import cobra"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5712b3cb",
   "metadata": {},
   "source": [
    "### 3.1 Generation of the \"D-Matrix\"\n",
    "The \"D-Matrix\" defines the weight of the edge between reaction nodes Ri and Rj as the probability that any metabolite chosen at random is produced by Ri (reaction i) and consumed by Rj (reaction j). Summing over all metabolites and normalizing, we obtain the edge weights of the adjacency matrix of the NFG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae976df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to generate S, n and m: 0.2956509590148926 seconds\n",
      "Time taken to generate S2m: 133.36353611946106 seconds\n",
      "Time taken to generate S2mplus and S2minus: 0.9967398643493652 seconds\n",
      "Time taken to generate Wplus and Wminus: 443.2345368862152 seconds\n",
      "Time taken to generate the D-Matrix: 260.75412487983704 seconds\n",
      "Time taken to remove unused reactions from the D-Matrix: 4.670567989349365 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load the model (Assuming SBML format)\n",
    "import time\n",
    "#model = cobra.io.read_sbml_model('/Users/pablodigiusto/Downloads/e_coli_core.xml')\n",
    "\n",
    "# Extract stoichiometric matrix, m=reactions, n=metabolites\n",
    "start = time.time()\n",
    "S = cobra.util.array.create_stoichiometric_matrix(model)\n",
    "n, m = S.shape\n",
    "end = time.time()\n",
    "print(f\"Time taken to generate S, n and m: {end - start} seconds\")\n",
    "\n",
    "# Create S2m matrix\n",
    "start = time.time()\n",
    "r = np.array([reaction.reversibility for reaction in model.reactions]) # m-dimensional reversibility vector with components rj = 1 if reaction Rj is reversible and rj = 0 if it is irreversible.\n",
    "Im = np.eye(m) # m × m identity matrix\n",
    "diagR = r * Im # m × m matrix contains r in its main diagonal\n",
    "S2m2 = np.block([[Im, np.zeros((m, m))], [np.zeros((m, m)), np.diag(r)]])\n",
    "S2m1 = np.hstack((S, -S))\n",
    "S2m = S2m1 @ S2m2 # unfolded version of the stoichiometric matrix of the 2m forward and reverse reactions.\n",
    "end = time.time()\n",
    "print(f\"Time taken to generate S2m: {end - start} seconds\")\n",
    "\n",
    "# Create S2mplus and S2mminus matrices\n",
    "start = time.time()\n",
    "#S2mplus = (np.abs(S2m) + S2m) / 2 # production stoichiometric matrix\n",
    "#S2mminus = (np.abs(S2m) - S2m) / 2 # consumption stoichiometric matrix\n",
    "Wplus_sum = np.einsum('ij->i', S2mplus)\n",
    "Wminus_sum = np.einsum('ij->i', S2mminus)\n",
    "\n",
    "# Prevent division by zero\n",
    "Wplus_sum[Wplus_sum == 0] = np.inf\n",
    "Wminus_sum[Wminus_sum == 0] = np.inf\n",
    "\n",
    "Wplus = 1.0 / Wplus_sum\n",
    "Wminus = 1.0 / Wminus_sum\n",
    "end = time.time()\n",
    "print(f\"Time taken to generate S2mplus and S2minus: {end - start} seconds\")\n",
    "\n",
    "# Calculate weights\n",
    "start = time.time()\n",
    "Wplus = pinv(np.diag(S2mplus @ np.ones((2*m, 1)).flatten()))\n",
    "Wminus = pinv(np.diag(S2mminus @ np.ones((2*m, 1)).flatten()))\n",
    "end = time.time()\n",
    "print(f\"Time taken to generate Wplus and Wminus: {end - start} seconds\")\n",
    "\n",
    "# Calculate D matrix\n",
    "start = time.time()\n",
    "D = 1/n * (Wplus @ S2mplus).T @ (Wminus @ S2mminus)\n",
    "end = time.time()\n",
    "print(f\"Time taken to generate the D-Matrix: {end - start} seconds\")\n",
    "\n",
    "# Remove unused reactions\n",
    "start = time.time()\n",
    "IDr = np.nonzero(np.sum(D, axis=0) == 0)[0]\n",
    "IDr = IDr[IDr > m]\n",
    "\n",
    "D = np.delete(D, IDr, axis=0)\n",
    "D = np.delete(D, IDr, axis=1)\n",
    "end = time.time()\n",
    "print(f\"Time taken to remove unused reactions from the D-Matrix: {end - start} seconds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ef1fa64",
   "metadata": {},
   "source": [
    "### 3.2 Plotting the \"D-Matrix\", Normalized Flow Graph (NFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43150760",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m G \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mfrom_numpy_array(D, create_using\u001b[38;5;241m=\u001b[39mnx\u001b[38;5;241m.\u001b[39mDiGraph)\n\u001b[1;32m      3\u001b[0m weights \u001b[38;5;241m=\u001b[39m [G[u][v][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m u,v \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39medges()]\n\u001b[0;32m----> 4\u001b[0m normalized_weights \u001b[38;5;241m=\u001b[39m [(w \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m(weights)) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mmax\u001b[39m(weights) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m(weights)) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m15\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.0001\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.0001\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m weights]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Create a dictionary mapping node indices to reaction names for labeling\u001b[39;00m\n\u001b[1;32m      9\u001b[0m reaction_names \u001b[38;5;241m=\u001b[39m [r\u001b[38;5;241m.\u001b[39mid \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mreactions]\n",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m G \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mfrom_numpy_array(D, create_using\u001b[38;5;241m=\u001b[39mnx\u001b[38;5;241m.\u001b[39mDiGraph)\n\u001b[1;32m      3\u001b[0m weights \u001b[38;5;241m=\u001b[39m [G[u][v][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m u,v \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39medges()]\n\u001b[0;32m----> 4\u001b[0m normalized_weights \u001b[38;5;241m=\u001b[39m [(w \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m(weights)) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m(weights)) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m15\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.0001\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.0001\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m weights]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Create a dictionary mapping node indices to reaction names for labeling\u001b[39;00m\n\u001b[1;32m      9\u001b[0m reaction_names \u001b[38;5;241m=\u001b[39m [r\u001b[38;5;241m.\u001b[39mid \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mreactions]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Convert D matrix into a graph\n",
    "G = nx.from_numpy_array(D, create_using=nx.DiGraph)\n",
    "weights = [G[u][v]['weight'] for u,v in G.edges()]\n",
    "normalized_weights = [(w - min(weights)) / (max(weights) - min(weights)) * (15 - 0.0001) + 0.0001 for w in weights]\n",
    "\n",
    "\n",
    "\n",
    "# Create a dictionary mapping node indices to reaction names for labeling\n",
    "reaction_names = [r.id for r in model.reactions]\n",
    "node_labels = {i: reaction_name for i, reaction_name in enumerate(reaction_names)}\n",
    "\n",
    "# Calculate the degrees of each node\n",
    "degrees = [val for (node, val) in G.degree()]\n",
    "\n",
    "# Normalize the degrees for color mapping\n",
    "normalized_degrees = [(d - min(degrees)) / (max(degrees) - min(degrees)) for d in degrees]\n",
    "\n",
    "# Use a colormap to map normalized degrees to colors\n",
    "cmap = plt.get_cmap('OrRd')  # Choose a colormap here\n",
    "node_colors = [cmap(deg) for deg in normalized_degrees]\n",
    "\n",
    "\n",
    "# Plot the graph\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, width=normalized_weights, node_color=node_colors, edge_color='lightgray', node_size=700, ax=ax)\n",
    "\n",
    "# Labels\n",
    "label_pos = {node: (x + 0.01, y + 0.03) for node, (x, y) in pos.items()}\n",
    "nx.draw_networkx_labels(G, label_pos, labels=node_labels, font_size=17, ax=ax)\n",
    "\n",
    "plt.title('Network Flux Graph (NFG)')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b769e605",
   "metadata": {},
   "source": [
    "### 3.3 Generation of the \"FluxOpenValue\" matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34e70e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0.,  1000.,     0.],\n",
       "       [    0.,  1000.,     0.],\n",
       "       [    0.,  1000.,     0.],\n",
       "       ...,\n",
       "       [-1000.,  1000.,     0.],\n",
       "       [-1000.,  1000.,     0.],\n",
       "       [-1000.,  1000.,     0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model (Assuming SBML format)\n",
    "# Perform FBA\n",
    "model.objective = 'biomass'\n",
    "solution = model.optimize()\n",
    "\n",
    "# Initialize lists to store bounds and fluxes\n",
    "lower_bounds = []\n",
    "upper_bounds = []\n",
    "fluxes = []\n",
    "\n",
    "# Iterate over reactions\n",
    "for reaction in model.reactions:\n",
    "    lower_bounds.append(reaction.lower_bound)\n",
    "    upper_bounds.append(reaction.upper_bound)\n",
    "    fluxes.append(solution.fluxes[reaction.id])\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "lower_bounds = np.array(lower_bounds)\n",
    "upper_bounds = np.array(upper_bounds)\n",
    "fluxes = np.array(fluxes)\n",
    "\n",
    "# Stack arrays horizontally\n",
    "FluxOpenValue = np.stack((lower_bounds, upper_bounds, fluxes), axis=-1)\n",
    "\n",
    "FluxOpenValue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61b5e6ee",
   "metadata": {},
   "source": [
    "### 3.4 Generation of the \"Mass Flow Graph (MFG) Matrix\"\n",
    "The MFG provides a versatile framework to create environment-specific metabolic graphs from FBA solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a64c8e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Calculation of the MFG\n",
    "PageRank = []\n",
    "#M_total = np.zeros((190, 190))\n",
    "for i in range(FluxOpenValue.shape[1]):\n",
    "    print(i)\n",
    "    v1 = FluxOpenValue[:, i].T\n",
    "\n",
    "    # unfolding the flux vector\n",
    "    # creation of vplus and vminus\n",
    "    vplus = (np.abs(v1) + v1) / 2\n",
    "    vminus = (np.abs(v1) - v1) / 2\n",
    "\n",
    "    # creation of v2m\n",
    "    v2m = np.concatenate((vplus, vminus))\n",
    "\n",
    "    # creation of J_v\n",
    "    J_v = S2mplus @ v2m.reshape(-1)\n",
    "\n",
    "    # calculation of the MFG\n",
    "    M = (S2mplus * v2m).T @ pinv(np.diag(J_v)) @ (S2mminus * v2m)\n",
    "    \n",
    "    #M_total = M_total + M\n",
    "\n",
    "    # Calculate and store PageRank\n",
    "    G = nx.from_numpy_array(M, create_using=nx.DiGraph)\n",
    "    pr = nx.pagerank(G)\n",
    "    PageRank.append(pr)\n",
    "    \n",
    "\n",
    "# Post-processing of PageRank\n",
    "df = pd.DataFrame(PageRank)\n",
    "PageRank = df.values\n",
    "PageRank = np.array(PageRank).T\n",
    "PageRankRxns = PageRank[:m, :]\n",
    "PageRankRxns_back = PageRank[m:, :]\n",
    "\n",
    "for i in range(m):\n",
    "    for j in range(PageRankRxns.shape[1]):\n",
    "        if PageRankRxns_back[i, j] > PageRankRxns[i, j]:\n",
    "            PageRankRxns[i, j] = PageRankRxns_back[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2563b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('PageRankRxns.txt', PageRankRxns, fmt='%.10f')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67f87a23",
   "metadata": {},
   "source": [
    "### 3.5 Plotting the \"MFG Matrix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6217b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graph\n",
    "G = nx.from_numpy_array(M_total, create_using=nx.DiGraph)\n",
    "weights = [G[u][v]['weight'] for u,v in G.edges()]\n",
    "normalized_weights = [(w - min(weights)) / (max(weights) - min(weights)) * (15 - 0.001) + 0.001 for w in weights]\n",
    "\n",
    "#Layout\n",
    "pos = nx.random_layout(G)\n",
    "\n",
    "# Calculate the degrees of each node\n",
    "degrees = [val for (node, val) in G.degree()]\n",
    "\n",
    "# Normalize the degrees for color mapping\n",
    "normalized_degrees = [(d - min(degrees)) / (max(degrees) - min(degrees)) for d in degrees]\n",
    "\n",
    "# Use a colormap to map normalized degrees to colors\n",
    "cmap = plt.get_cmap('OrRd')  # Choose a colormap here\n",
    "node_colors = [cmap(deg) for deg in normalized_degrees]\n",
    "\n",
    "\n",
    "labels = np.concatenate(([reaction.id for reaction in model.reactions],\n",
    "                         [reaction.id + '_r' for reaction in model.reactions]))\n",
    "node_labels = {i: reaction_name for i, reaction_name in enumerate(labels)}\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 20))  # Create a new figure and axes\n",
    "nx.draw(G, pos, node_color=node_colors, node_size=500, edge_color='lightgray',\n",
    "        edge_cmap=plt.cm.Blues, width=normalized_weights, ax=ax)\n",
    "label_pos = {node: (x + 0.01, y + 0.03) for node, (x, y) in pos.items()}\n",
    "nx.draw_networkx_labels(G, label_pos, labels=node_labels, font_size=12, ax=ax)\n",
    "\n",
    "plt.title('MFG')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc1aa9c0",
   "metadata": {},
   "source": [
    "### Identification of duplicates throught Chemical Formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca1953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemical Formula\n",
    "from cobra.io import read_sbml_model\n",
    "model = read_sbml_model(\"iCHOv3_CHO_23052023.xml\")\n",
    "\n",
    "import pandas as pd\n",
    "data = []\n",
    "\n",
    "for m in model.metabolites:\n",
    "    m.name = m.formula\n",
    "for r in model.reactions:\n",
    "    if r not in model.exchanges:\n",
    "        print(r)\n",
    "        reaction_id = r.id\n",
    "        reaction_name = r.name\n",
    "        reaction_formula = r.build_reaction_string(use_metabolite_names=True)\n",
    "        data.append([reaction_id, reaction_name, reaction_formula])\n",
    "df = pd.DataFrame(data, columns=['ID', 'Name', 'Reaction'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b85035",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.metabolites:\n",
    "    m.name = m.formula\n",
    "for r in model.reactions:\n",
    "    if r not in model.exchanges:\n",
    "        reaction_id = r.id\n",
    "        reaction_name = r.name\n",
    "        reaction_formula = r.build_reaction_string(use_metabolite_names=True)\n",
    "        data.append([reaction_id, reaction_name, reaction_formula])\n",
    "df = pd.DataFrame(data, columns=['ID', 'Name', 'Reaction'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a901faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_duplicates = df[df.duplicated(subset='Reaction', keep=False)].reset_index(drop=True)\n",
    "subset_duplicates = subset_duplicates.sort_values(by=['Reaction'])\n",
    "subset_duplicates.to_excel('Test.xlsx')\n",
    "\n",
    "for index, n in enumerate(subset_duplicates['Reaction']):\n",
    "    next_value = subset_duplicates['Reaction'][index + 1]\n",
    "    if n == next_value:\n",
    "        print(subset_duplicates['Name'][index])\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47ee0c57",
   "metadata": {},
   "source": [
    "### Duplicates identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C40H36N4O16 C40H36N4O16\n",
      "GapFill-R03166: hmbil_c <=> h2o_c + uppg1_c\n",
      "GapFill-R04972: uppg1_c <=> 4.0 co2_c + cpppg1_c\n",
      "------\n",
      "C40H36N4O16\n",
      "HMR_4772: HC01609_c + 4.0 h_c --> 4.0 co2_c + cpppg1_c\n"
     ]
    }
   ],
   "source": [
    "print(model.metabolites.get_by_id('uppg1_c').name, model.metabolites.get_by_id('HC01609_c').name)\n",
    "for r in model.metabolites.get_by_id('uppg1_c').reactions:\n",
    "    print(r)\n",
    "print('------')\n",
    "for r in model.metabolites.get_by_id('HC01609_c').reactions:\n",
    "    print(r)\n",
    "# Based on reations HMR_4772 and GapFill-R04972, HC01609_c and uppg1_c  are the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df438661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C15H12I3NO4 C15H12I3NO4\n",
      "HMR_6834: CE2866_c + i_c + nadp_c <=> HC02187_c + nadph_c\n",
      "r2196: HC02187_e + gthrd_c + hco3_c <=> HC02187_c + gthrd_e + hco3_e\n",
      "HMR_6839: h2o_c + triodthysuf_c --> HC02187_c + h_c + so4_c\n",
      "r2213: HC02187_e + HC02200_c + hco3_c <=> HC02187_c + HC02200_e + hco3_e\n",
      "HMR_6838: HC02187_c + paps_c --> h_c + pap_c + triodthysuf_c\n",
      "r2352: HC02187_e <=> HC02187_c\n",
      "r2214: HC02187_e + HC02201_c + hco3_c <=> HC02187_c + HC02201_e + hco3_e\n",
      "r2212: HC02187_e + HC02199_c + hco3_c <=> HC02187_c + HC02199_e + hco3_e\n",
      "------\n",
      "C15H12I3NO4\n",
      "r2210: HC02200_c + hco3_c + triodthy_e <=> HC02200_e + hco3_e + triodthy_c\n",
      "r2209: HC02199_c + hco3_c + triodthy_e <=> HC02199_e + hco3_e + triodthy_c\n",
      "TIDSSULF: h2o_c + triodthysuf_c --> h_c + so4_c + triodthy_c\n",
      "r2211: HC02201_c + hco3_c + triodthy_e <=> HC02201_e + hco3_e + triodthy_c\n",
      "RE0922C: triodthy_c + udpglcur_c --> CE2879_c + h_c + udp_c\n",
      "TRIODTHYSULT: paps_c + triodthy_c --> h_c + pap_c + triodthysuf_c\n",
      "HMR_6840: CE2872_c + i_c + nadp_c <=> nadph_c + triodthy_c\n",
      "HMR_6826: CE2866_c + i_c + nadp_c <=> nadph_c + triodthy_c\n",
      "TRIODTHYt: hco3_c + triodthy_e <=> hco3_e + triodthy_c\n",
      "HMR_6854: i_c + nadp_c + triodthy_c <=> nadph_c + thyox_L_c\n",
      "r2195: gthrd_c + hco3_c + triodthy_e <=> gthrd_e + hco3_e + triodthy_c\n",
      "TRIODTHYt2: triodthy_e <=> triodthy_c\n",
      "IDHPOXOX3: 35diotyr_c + 3ityr_L_c + h2o2_c --> 2amac_c + 2.0 h2o_c + triodthy_c\n"
     ]
    }
   ],
   "source": [
    "print(model.metabolites.get_by_id('HC02187_c').name, model.metabolites.get_by_id('triodthy_c').name)\n",
    "for r in model.metabolites.get_by_id('HC02187_c').reactions:\n",
    "    print(r)\n",
    "print('------')\n",
    "for r in model.metabolites.get_by_id('triodthy_c').reactions:\n",
    "    print(r)\n",
    "# Based on reations HMR_6834 and HMR_6826, triodthy_c and HC02187_c  are the same "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
