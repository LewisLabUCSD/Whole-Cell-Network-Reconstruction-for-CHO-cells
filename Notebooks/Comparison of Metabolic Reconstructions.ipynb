{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c0343d-7431-4db9-9bc8-e354a3a70b4e",
   "metadata": {},
   "source": [
    "# Comparison of Metabolic Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f793376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from cobra.io import read_sbml_model, load_json_model, load_matlab_model\n",
    "from google_sheet import GoogleSheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf02b59f-544d-4e3c-931d-bfd2378e0564",
   "metadata": {},
   "source": [
    "## 1. Conf. Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c063085",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- Generate datasets from Google Sheet ----- #####\n",
    "#Credential file\n",
    "KEY_FILE_PATH = 'credentials.json'\n",
    "#CHO Network Reconstruction + Recon3D_v3 Google Sheet ID\n",
    "SPREADSHEET_ID = '1MlBXeHIKw8k8fZyXm-sN__AHTRSunJxar_-bqvukZws'\n",
    "# Initialize the GoogleSheet object\n",
    "sheet = GoogleSheet(SPREADSHEET_ID, KEY_FILE_PATH)\n",
    "# Read data from the Google Sheet\n",
    "sheet_rxns = 'Rxns'\n",
    "rxns = sheet.read_google_sheet(sheet_rxns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ccb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### --- Conf. Score distribution throughout the dataset --- ####\n",
    "data_numeric = pd.to_numeric(rxns['Conf. Score'], errors='coerce')\n",
    "data_numeric = data_numeric.dropna()\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(data_numeric, bins='auto', color='steelblue', edgecolor='black')\n",
    "plt.grid(color='gray', linestyle='--', linewidth=0.5)\n",
    "plt.xticks(data_numeric.unique())\n",
    "plt.xlabel('Values', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "plt.title('Confidence Score Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.savefig('../Analyses/conf_score_distribution.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b218fa-7f54-4547-818d-bb9f1bf8a902",
   "metadata": {},
   "source": [
    "## 2. Subsystems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8b6c09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate models for comparison\n",
    "icho1766 = read_sbml_model('../Data/reconciliation/models/iCHOv1_final.xml')\n",
    "icho2291 = read_sbml_model('../Data/Reconciliation/models/iCHO2291.xml')\n",
    "icho2101 = load_json_model('../Data/Reconciliation/models/iCHO2101.json')\n",
    "iCHO3K = load_json_model('iCHO3595.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a59651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### --- Calculate the amount of reactions per Subsystem ---- ####\n",
    "\n",
    "#iCHO 1766\n",
    "subs = []\n",
    "for reaction in icho1766.reactions:\n",
    "    subs.append(reaction.subsystem.upper())\n",
    "    \n",
    "icho1766_subs = Counter(subs)\n",
    "\n",
    "#iCHO 2291\n",
    "subs = []\n",
    "for reaction in icho2291.reactions:\n",
    "    subs.append(reaction.subsystem.upper())\n",
    "    \n",
    "icho2291_subs = Counter(subs)\n",
    "\n",
    "# iCHO 2101\n",
    "subs = []\n",
    "for reaction in icho2101.reactions:\n",
    "    subs.append(reaction.subsystem.upper())\n",
    "    \n",
    "icho2101_subs = Counter(subs)\n",
    "\n",
    "#iCHO 3K\n",
    "subs = []\n",
    "for reaction in iCHO3K.reactions:\n",
    "    subs.append(reaction.subsystem.upper())\n",
    "    \n",
    "iCHO3K_subs = Counter(subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874ec2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of subsystems to categories (systems)\n",
    "\n",
    "# Updated Mapping of subsystems to categories\n",
    "category_mapping = {\n",
    "    'Amino Acid Metabolism': [\n",
    "        'AMINO ACID METABOLISM',\n",
    "        'ALANINE AND ASPARTATE METABOLISM',\n",
    "        'AMINO ACID DERIVATIVE',\n",
    "        'ARGININE AND PROLINE METABOLISM',\n",
    "        'BETA-ALANINE METABOLISM',\n",
    "        'CYSTEINE METABOLISM',\n",
    "        'D-ALANINE METABOLISM',\n",
    "        'GLUTAMATE METABOLISM',\n",
    "        'GLUTATHIONE METABOLISM',\n",
    "        'GLYCINE, SERINE, ALANINE AND THREONINE METABOLISM',\n",
    "        'GLYCINE, SERINE, AND THREONINE METABOLISM',\n",
    "        'HISTIDINE METABOLISM',\n",
    "        'LYSINE METABOLISM',\n",
    "        'METHIONINE AND CYSTEINE METABOLISM',\n",
    "        'METHIONINE METABOLISM',\n",
    "        'PEPTIDE METABOLISM',\n",
    "        'PHENYLALANINE METABOLISM',\n",
    "        'SELENOAMINO ACID METABOLISM',\n",
    "        'SPERMINE DEGRADATION',  # Added\n",
    "        'TAURINE AND HYPOTAURINE METABOLISM',\n",
    "        'TRYPTOPHAN METABOLISM',\n",
    "        'TYROSINE METABOLISM',\n",
    "        'UREA CYCLE',\n",
    "        'UREA CYCLE/AMINO GROUP METABOLISM',\n",
    "        'VALINE, LEUCINE, AND ISOLEUCINE METABOLISM'\n",
    "    ],\n",
    "    'Carbohydrates Metabolism': [\n",
    "        'ALKALOID SYNTHESIS',\n",
    "        'AMINOSUGAR METABOLISM',\n",
    "        'ASCORBATE AND ALDARATE METABOLISM',\n",
    "        'BUTANOATE METABOLISM',\n",
    "        'C5-BRANCHED DIBASIC ACID METABOLISM',\n",
    "        'FRUCTOSE AND MANNOSE METABOLISM',\n",
    "        'GALACTOSE METABOLISM',\n",
    "        'GLYOXYLATE AND DICARBOXYLATE METABOLISM',\n",
    "        'HEPARAN SULFATE DEGRADATION',\n",
    "        'HYALURONAN METABOLISM',\n",
    "        'LIMONENE AND PINENE DEGRADATION',\n",
    "        'LIPOATE METABOLISM',\n",
    "        'PENTOSE AND GLUCURONATE INTERCONVERSIONS',\n",
    "        'PROPANOATE METABOLISM',\n",
    "        'PYRUVATE METABOLISM',\n",
    "        'STARCH AND SUCROSE METABOLISM',\n",
    "        'STILBENE, COUMARINE AND LIGNIN SYNTHESIS',\n",
    "        'OTHER CARBON METABOLISM'\n",
    "    ],\n",
    "    'Energy Metabolism': [\n",
    "        'BIOMASS',\n",
    "        'BIOMASS SYNTHESIS',\n",
    "        'CITRIC ACID CYCLE',\n",
    "        'GLYCOLYSIS/GLUCONEOGENESIS',\n",
    "        'OXIDATIVE PHOSPHORYLATION',\n",
    "        'PENTOSE PHOSPHATE PATHWAY',\n",
    "        'ROS DETOXIFICATION',\n",
    "        'CENTRAL CARBON AND ENERGY METABOLISM'\n",
    "    ],\n",
    "    'Exchange/Transport': [\n",
    "        'EXCHANGE/DEMAND/SINK',\n",
    "        'EXCHANGE/DEMAND REACTION',\n",
    "        'EXCHANGE/DEMAND/SINK REACTION',\n",
    "        'EXCHANGE',\n",
    "        'DEMAND',\n",
    "        'SINK',\n",
    "        'TRANSPORT, ENDOPLASMIC RETICULAR',\n",
    "        'TRANSPORT, EXTRACELLULAR',\n",
    "        'TRANSPORT, GOLGI APPARATUS',\n",
    "        'TRANSPORT, LYSOSOMAL',\n",
    "        'TRANSPORT, MITOCHONDRIAL',\n",
    "        'TRANSPORT, NUCLEAR',\n",
    "        'TRANSPORT, PEROXISOMAL',\n",
    "        'TRANSPORT'\n",
    "    ],\n",
    "    'Lipid Metabolism': [\n",
    "        'ARACHIDONIC ACID METABOLISM',\n",
    "        'BILE, EICOSANOID AND STEROID METABOLISM',\n",
    "        'BILE ACID SYNTHESIS',\n",
    "        'CARNITINE SHUTTLE',\n",
    "        'CHOLESTEROL METABOLISM',\n",
    "        'EICOSANOID METABOLISM',\n",
    "        'FATTY ACID METABOLISM',\n",
    "        'FATTY ACID OXIDATION',\n",
    "        'FATTY ACID SYNTHESIS',\n",
    "        'FATTY ACID ELONGATION',\n",
    "        'GLYCAN AND GLYCOSAMINOGLYCAN METABOLISM',\n",
    "        'GLYCEROLIPID METABOLISM',\n",
    "        'GLYCEROPHOSPHOLIPID METABOLISM',\n",
    "        'GLYCOSPHINGOLIPID METABOLISM',\n",
    "        'GLYCOSYLPHOSPHATIDYLINOSITOL-ANCHOR BIOSYNTHESIS',\n",
    "        'GLYCOSYLPHOSPHATIDYLINOSITOL (GPI)-ANCHOR BIOSYNTHESIS',\n",
    "        'GLYCEROPHOSPHOLIPID, SPHINGOLIPID AND INOSITOL METABOLISM'\n",
    "        'INOSITOL PHOSPHATE METABOLISM',\n",
    "        'LINOLEATE METABOLISM',\n",
    "        'PHOSPHATIDYLINOSITOL PHOSPHATE METABOLISM',\n",
    "        'R GROUP SYNTHESIS',\n",
    "        'SPHINGOLIPID METABOLISM',\n",
    "        'SQUALENE AND CHOLESTEROL SYNTHESIS',\n",
    "        'TRIACYLGLYCEROL SYNTHESIS'\n",
    "    ],\n",
    "    'Nucleotide Metabolism': [\n",
    "        'NUCLEOTIDE SALVAGE PATHWAY',\n",
    "        'NUCLEOTIDE INTERCONVERSION',\n",
    "        'NUCLEOTIDES',\n",
    "        'PURINE METABOLISM',\n",
    "        'PURINE CATABOLISM',\n",
    "        'PURINE SYNTHESIS',\n",
    "        'PYRIMIDINE METABOLISM',\n",
    "        'PYRIMIDINE BIOSYNTHESIS',\n",
    "        'PYRIMIDINE CATABOLISM',\n",
    "        'PYRIMIDINE SYNTHESIS',\n",
    "        'NUCLEOTIDE SUGAR METABOLISM',\n",
    "        'NUCLEOTIDE METABOLISM',\n",
    "        'NUCELOTIDE METABOLISM',\n",
    "        'SALVAGE PATHWAY'\n",
    "    ],\n",
    "    'Protein Product Synthesis': [\n",
    "        'BLOOD GROUP SYNTHESIS',\n",
    "        'CHONDROITIN SULFATE DEGRADATION',\n",
    "        'CHONDROITIN SYNTHESIS',\n",
    "        'KERATAN SULFATE METABOLISM',\n",
    "        'KERATAN SULFATE SYNTHESIS',\n",
    "        'N-GLYCAN METABOLISM',\n",
    "        'N-GLYCAN BIOSYNTHESIS',\n",
    "        'N-GLYCAN SYNTHESIS',  # Added\n",
    "        'N-GLYCAN DEGRADATION',\n",
    "        'O-GLYCAN SYNTHESIS',\n",
    "        'PROTEIN ASSEMBLY',\n",
    "        'PROTEIN DEGRADATION',\n",
    "        'PROTEIN MODIFICATION',\n",
    "        'PROTEIN PRODUCTION',\n",
    "        'GLYCAN AND GLYCOSAMINOGLYCAN METABOLISM'\n",
    "    ],\n",
    "    'Unassigned': [\n",
    "        'UNASSIGNED',\n",
    "        'MISCELLANEOUS'\n",
    "    ],\n",
    "    'Vitamin & Cofactor Metabolism': [\n",
    "        'ANDROGEN AND ESTROGEN SYNTHESIS AND METABOLISM',\n",
    "        'BIOTIN METABOLISM',\n",
    "        'COA METABOLISM',\n",
    "        'COA SYNTHESIS',\n",
    "        'COA CATABOLISM',\n",
    "        'CYTOCHROME METABOLISM',\n",
    "        'FOLATE METABOLISM',\n",
    "        'NAD METABOLISM',\n",
    "        'PORPHYRIN METABOLISM',\n",
    "        'TETRAHYDROBIOPTERIN METABOLISM',\n",
    "        'THIAMINE METABOLISM',\n",
    "        'UBIQUINONE AND OTHER TERPENOID-QUINONE SYNTHESIS',\n",
    "        'UBIQUINONE SYNTHESIS',\n",
    "        'VITAMIN A METABOLISM',\n",
    "        'VITAMIN B2 METABOLISM',\n",
    "        'VITAMIN B6 METABOLISM',\n",
    "        'VITAMIN B12 METABOLISM',\n",
    "        'VITAMIN C METABOLISM',\n",
    "        'VITAMIN D METABOLISM',\n",
    "        'VITAMIN D',  # Adjusted to include both variants\n",
    "        'VITAMIN E METABOLISM',\n",
    "        'XENOBIOTICS METABOLISM',\n",
    "        'HEME SYNTHESIS',\n",
    "        'HEME DEGRADATION',\n",
    "        'CYP METABOLISM',\n",
    "        'VITAMIN AND COFACTOR METABOLISM'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7253ca-a307-497d-9b4d-acacf6ee6b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_counts(counts_dict, category_mapping):\n",
    "    from collections import defaultdict\n",
    "    # Create reverse mapping\n",
    "    subsystem_to_category = {}\n",
    "    for category, subsystems in category_mapping.items():\n",
    "        for subsystem in subsystems:\n",
    "            subsystem_to_category[subsystem.upper()] = category\n",
    "    \n",
    "    # Initialize category counts\n",
    "    category_counts = defaultdict(int)\n",
    "    \n",
    "    # Allocate counts\n",
    "    for subsystem, count in counts_dict.items():\n",
    "        subsystem_upper = subsystem.upper()\n",
    "        if subsystem_upper in subsystem_to_category:\n",
    "            category = subsystem_to_category[subsystem_upper]\n",
    "            category_counts[category] += count\n",
    "        else:\n",
    "            category_counts['Other'] += count\n",
    "    \n",
    "    return category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc981dd-6e8d-46e2-a731-b53f74cdd636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate counts for each dictionary\n",
    "icho1766_systems = allocate_counts(icho1766_subs, category_mapping)\n",
    "icho2101_systems = allocate_counts(icho2101_subs, category_mapping)\n",
    "icho2291_systems = allocate_counts(icho2291_subs, category_mapping)\n",
    "iCHO3K_systems = allocate_counts(iCHO3K_subs, category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2110215-283b-4014-9571-aee849cffd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of datasets\n",
    "datasets = {\n",
    "    'iCHO1766': icho1766_systems,\n",
    "    'iCHO2101': icho2101_systems,\n",
    "    'iCHO2291': icho2291_systems,\n",
    "    'iCHO3K': iCHO3K_systems\n",
    "}\n",
    "\n",
    "# Get the list of all categories\n",
    "all_categories = set()\n",
    "for counts in datasets.values():\n",
    "    all_categories.update(counts.keys())\n",
    "\n",
    "all_categories = sorted(all_categories)\n",
    "\n",
    "# Initialize DataFrame\n",
    "df = pd.DataFrame(index=all_categories)\n",
    "\n",
    "# Populate DataFrame\n",
    "for dataset_name, counts in datasets.items():\n",
    "    df[dataset_name] = [counts.get(category, 0) for category in all_categories]\n",
    "\n",
    "# Replace NaN with 0 (in case there are any)\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Compute total reactions per dataset\n",
    "total_reactions = df.sum(axis=0)\n",
    "\n",
    "# Add 'Total Reactions' as a new row to 'df'\n",
    "df.loc['Total Reactions'] = total_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8362f2df-2bde-469e-b42e-be805e3aeebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1db57b-06de-407e-adc8-623aba147e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude 'Total Reactions' for plotting\n",
    "df_plot = df.drop(['Total Reactions', 'Other'], axis=0)\n",
    "\n",
    "# Extract categories and datasets\n",
    "categories = df_plot.index.tolist()\n",
    "datasets = df_plot.columns.tolist()\n",
    "n_categories = len(categories)\n",
    "n_datasets = len(datasets)\n",
    "\n",
    "# Define bar heights and positions\n",
    "bar_height = 0.8 / n_datasets  # Adjust the bar height based on the number of datasets\n",
    "y_positions = np.arange(n_categories)\n",
    "\n",
    "# Set a professional color palette\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']  # Colors from your style\n",
    "model_names = datasets  # Assuming datasets are in the same order as colors\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "for i, (dataset, color) in enumerate(zip(datasets, colors)):\n",
    "    counts = df_plot[dataset].values\n",
    "    # Calculate positions for each dataset's bars\n",
    "    positions = y_positions - 0.4 + i * bar_height + bar_height / 2\n",
    "    bars = ax.barh(positions, counts, height=bar_height, label=dataset, color=color,\n",
    "                   edgecolor='black', linewidth=0.3)\n",
    "\n",
    "    # Annotate bars with their values\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        ax.annotate(f'{int(width)}',\n",
    "                    xy=(width, bar.get_y() + bar.get_height() / 2),\n",
    "                    xytext=(5, 0),\n",
    "                    textcoords='offset points',\n",
    "                    ha='left', va='center',\n",
    "                    fontweight='light', fontsize=8)\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_yticks(y_positions)\n",
    "ax.set_yticklabels(categories, fontsize=10)\n",
    "ax.set_title('Reaction Counts per System Across Models',\n",
    "             fontsize=15, fontweight='light', pad=15)\n",
    "\n",
    "# Invert the y-axis to reverse the order of the bars\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Add grid lines\n",
    "ax.grid(True, linestyle='-', linewidth=0.5, axis='x', color='gray', alpha=0.7)\n",
    "\n",
    "# Remove spines for a cleaner look\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "# Adjust x-axis ticks\n",
    "ax.tick_params(axis='x', labelsize=10)\n",
    "\n",
    "# Create custom handles for the legend\n",
    "custom_handles = [mpatches.Patch(color=color, label=model_name)\n",
    "                  for color, model_name in zip(colors, model_names)]\n",
    "\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot (adjust the path as needed)\n",
    "plt.savefig('../Analyses/recons_comparisons/metabolic_models_comparison_horizontal_inverted.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6009a3-7b1c-4a45-aa23-2a71c189a9d3",
   "metadata": {},
   "source": [
    "## 3. Reactions, Genes and Metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reaction counts for each recon\n",
    "icho1766_rxns = len(icho1766.reactions)\n",
    "icho2291_rxns = len(icho2291.reactions)\n",
    "icho2101_rxns = len(icho2101.reactions)\n",
    "icho3K_rxns = len(iCHO3K.reactions)\n",
    "\n",
    "#Metabolite counts for each recon\n",
    "icho1766_mets = len(icho1766.metabolites)\n",
    "icho2291_mets = len(icho2291.metabolites)\n",
    "icho2101_mets = len(icho2101.metabolites)\n",
    "icho3K_mets = len(iCHO3K.metabolites)\n",
    "\n",
    "# Gene counts for each recon\n",
    "icho1766_gens = len(icho1766.genes)\n",
    "icho2291_gens = len(icho2291.genes)\n",
    "icho2101_gens = len(icho2101.genes)\n",
    "icho3K_gens = len(iCHO3K.genes)\n",
    "\n",
    "\n",
    "# Creating a DataFrame from the counts\n",
    "data = {\n",
    "    'iCHO1766': [icho1766_rxns, icho1766_mets, icho1766_gens],\n",
    "    'iCHO2101': [icho2101_rxns, icho2101_mets, icho2101_gens],\n",
    "    'iCHO2291': [icho2291_rxns, icho2291_mets, icho2291_gens],\n",
    "    'iCHO3K': [icho3K_rxns, icho3K_mets, icho3K_gens]\n",
    "}\n",
    "\n",
    "counts_df = pd.DataFrame(data, index=['Reactions', 'Metabolites', 'Genes'])\n",
    "\n",
    "# Improved aesthetics for a research publication plot\n",
    "def create_research_plot(counts_df):\n",
    "    # Set a professional color palette\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "    model_names = ['iCHO1766', 'iCHO2101', 'iCHO2291', 'iCHO3K']\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(7, 6))\n",
    "    \n",
    "    # Turn off the first subplot\n",
    "    ax1, ax2, ax3, ax4 = axes.flatten()\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Define the axes for the categories\n",
    "    axes_mapping = {0: ax2, 1: ax3, 2: ax4}\n",
    "    categories = ['Reactions', 'Metabolites', 'Genes']\n",
    "\n",
    "    # A function to annotate the bars with their values\n",
    "    def annotate_bars(ax):\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                        ha='center', va='bottom', xytext=(0, 3), textcoords='offset points', fontweight='light', fontsize=12)\n",
    "\n",
    "    # Plotting and annotating each category\n",
    "    for index, category in enumerate(categories):\n",
    "        ax = axes_mapping[index]\n",
    "        counts_df.loc[category].plot(kind='bar', ax=ax, title=category, color=colors, edgecolor='black', linewidth=.3, width=0.9, legend=False)\n",
    "        annotate_bars(ax)\n",
    "        ax.set_title(category, fontsize=15, fontweight='light', pad=10)\n",
    "        ax.grid(True, linestyle='-', linewidth=0.5, axis='y')\n",
    "        ax.set_xticks([]) # Remove x-axis ticks\n",
    "        ax.set_xticklabels([])  # Remove x-axis labels\n",
    "        ax.tick_params(axis='y', labelsize=8)\n",
    "\n",
    "    # Remove border of the plots\n",
    "    for ax in [ax2, ax3, ax4]:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "\n",
    "    # Create custom handles for the legend\n",
    "    custom_handles = [mpatches.Patch(color=color, label=model_name) for color, model_name in zip(colors, model_names)]\n",
    "    fig.legend(handles=custom_handles, loc='upper left',bbox_to_anchor=(0.05, 0.9), fontsize=13, frameon=False, fancybox=False, shadow=False)\n",
    "    \n",
    "    # Adjust spacing between the subplots\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "    \n",
    "    plt.savefig('../Analyses/recons_comparisons/metabolic_models_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "create_research_plot(counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151676d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "list2 = [m.id[:-2] for m in icho1766.metabolites]\n",
    "set2 = set(list2)\n",
    "print(len(list2))\n",
    "print(len(set2))\n",
    "print('----------------------------------------')\n",
    "list3 = [m.id[:-2] for m in icho2101.metabolites]\n",
    "set3 = set(list3)\n",
    "print(len(list3))\n",
    "print(len(set3))\n",
    "print('----------------------------------------')\n",
    "list4 = [m.id[:-2] for m in icho2291.metabolites]\n",
    "set4 = set(list4)\n",
    "print(len(list4))\n",
    "print(len(set4))\n",
    "print('----------------------------------------')\n",
    "list5 = [m.id[:-2] for m in iCHO3K.metabolites]\n",
    "set5 = set(list5)\n",
    "print(len(list5))\n",
    "print(len(set5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a2404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the counts\n",
    "counts = {\n",
    "    'Model': [],\n",
    "    'Reactions with GPR': [],\n",
    "    'Reactions without GPR': [],\n",
    "    'Total Reactions': []\n",
    "}\n",
    "\n",
    "# Loop through the models and calculate counts\n",
    "models = [icho1766, icho2291, icho2101, iCHO3K]#, recon3d]\n",
    "model_names = ['iCHO1766', 'iCHO2291', 'iCHO2101', 'iCHO3K']#, 'Recon3D']\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    rxn_with_gpr = sum(1 for rxn in model.reactions if str(rxn.gpr) not in ['', 'nan'])\n",
    "    rxn_without_gpr = sum(1 for rxn in model.reactions if str(rxn.gpr) in ['', 'nan'])\n",
    "    total = len(model.reactions)\n",
    "\n",
    "    counts['Model'].append(name)\n",
    "    counts['Reactions with GPR'].append(rxn_with_gpr)\n",
    "    counts['Reactions without GPR'].append(rxn_without_gpr)\n",
    "    counts['Total Reactions'].append(total)\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "counts_df = pd.DataFrame(counts)\n",
    "counts_df['%'] = (counts_df['Reactions with GPR']/counts_df['Total Reactions'])*100\n",
    "\n",
    "# Setting the index to the model names\n",
    "counts_df.set_index('Model', inplace=True)\n",
    "\n",
    "def plot_gpr_coverage(counts_df):\n",
    "    # Create a plot with the right size and stacked bars directly\n",
    "    ax = counts_df[['Reactions with GPR', 'Reactions without GPR']].plot(\n",
    "        kind='bar', stacked=True, color=['#1f77b4', '#ff7f0e'], edgecolor='black', linewidth=.3, width=0.8, legend=False, figsize=(6, 6))\n",
    "    plt.title('GPR Coverage', fontsize=20, pad=10)\n",
    "\n",
    "\n",
    "    # Label configuration\n",
    "    ax.tick_params(axis='x', rotation=0)  # Set rotation for x ticks if needed\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45)  # Rotate labels if needed\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Grid and axis adjustments\n",
    "    ax.grid(True, linestyle='-', linewidth=0.5, axis='y')\n",
    "    ax.set_axisbelow(True)  # Ensure grid is behind the bars\n",
    "\n",
    "    # Hide x-axis ticks\n",
    "    ax.tick_params(axis='x', which='both', length=0)\n",
    "    ax.tick_params(axis='y', labelsize=8)\n",
    "\n",
    "    # Remove plot frame borders\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "        \n",
    "    # Legend configuration\n",
    "    ax.legend(loc='center left',bbox_to_anchor=(0.1, 1.4), fontsize=16, frameon=False, fancybox=False, shadow=False)\n",
    "\n",
    "\n",
    "    # Optimize layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig('../Analyses/recons_comparisons/gpr_coverage.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Call the function with the DataFrame\n",
    "plot_gpr_coverage(counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7291d20-7112-41e3-a462-78fde3114615",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c382b9",
   "metadata": {},
   "source": [
    "## 4. Gene Essentiality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae4b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from time import process_time\n",
    "import cobra\n",
    "from cobra.io import load_json_model, read_sbml_model, load_matlab_model\n",
    "from cobra.flux_analysis.variability import find_essential_genes, find_essential_reactions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6514ba9-3558-49f4-8236-f4e427a7cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Models\n",
    "\n",
    "iCHO3K = load_json_model('iCHO3K.json')\n",
    "iCHO1766 = read_sbml_model('../Data/Reconciliation/models/iCHOv1_final.xml')\n",
    "iCHO2291 = read_sbml_model('../Data/Reconciliation/models/iCHO2291.xml')\n",
    "iCHO2101 = load_json_model('../Data/Reconciliation/models/iCHO2101.json')\n",
    "WT_P4_Bio141 = load_matlab_model('../Data/Context_specific_models/AUG15_reduced_model_CF_WT_P4_Bio141.mat')\n",
    "WT_P4_Bio142 = load_matlab_model('../Data/Context_specific_models/AUG25_reduced_model_CF_WT_P4_Bio142.mat')\n",
    "WT_P4_Bio143 = load_matlab_model('../Data/Context_specific_models/AUG15_reduced_model_CF_WT_P4_Bio143.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7178d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset for the experimentally validated essential genes\n",
    "\n",
    "exp_essential_genes = pd.read_csv('../Data/Gene_Essentiality/cho_essential_genes.csv', sep='\\t')\n",
    "exp_essential_genes['gene'] = exp_essential_genes['gene'].str.replace('__1$', '', regex=True)\n",
    "# Extract all gene names\n",
    "all_gene_names = set()\n",
    "for names in exp_essential_genes['gene']:\n",
    "    for name in names.split('|'): #Extract the names of the genes with two aliases\n",
    "        all_gene_names.add(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fefc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' In case of retrieving the gene ID please activate this code\n",
    "# Generation gene ID of exp_essential_genes with biopython\n",
    "from Bio import Entrez\n",
    "import pandas as pd\n",
    "\n",
    "# Set your email (this is required by NCBI for accessing their services)\n",
    "Entrez.email = \"dh.choi@orcid\"\n",
    "\n",
    "# Your dataset with gene symbols (replace with actual dataframe)\n",
    "gene_symbols = exp_essential_genes.gene  # Example gene symbols\n",
    "\n",
    "# Function to fetch gene ID using Entrez API\n",
    "def get_gene_id(gene_symbol):\n",
    "    search_handle = Entrez.esearch(db=\"gene\", term=f\"{gene_symbol}[Gene] AND Cricetulus griseus[Organism]\")\n",
    "    record = Entrez.read(search_handle)\n",
    "    search_handle.close()\n",
    "    if record[\"IdList\"]:\n",
    "        return record[\"IdList\"][0]  # Return the first gene ID found\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create a DataFrame to store gene symbols and their corresponding gene IDs\n",
    "df = pd.DataFrame({'gene': gene_symbols})\n",
    "df['entrez_gene_id'] = df['gene'].apply(get_gene_id)\n",
    "\n",
    "# Display the result\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to a pickle file\n",
    "with open(\"gene_id_mapping.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "# Save the result to a CSV file as well, if needed\n",
    "df.to_csv(\"gene_id_mapping.csv\", index=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d02bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame from the pickle file\n",
    "with open(\"gene_id_mapping.pkl\", \"rb\") as f:\n",
    "    df_loaded = pickle.load(f)\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(df_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6385072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load uptake and secretion rate \"Intervals dict\n",
    "\n",
    "with open('../Data/Uptake_Secretion_Rates/uptake_secretion_intrvl_wt_dict.pkl', 'rb') as file:\n",
    "    uptsec_intrvl_wt = pickle.load(file)\n",
    "\n",
    "with open('../Data/Uptake_Secretion_Rates/uptake_secretion_raw_wt_dict.pkl', 'rb') as file:\n",
    "    uptsec_wt = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532b99c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constraint_model_feg(model, time, exp_dict, objective=None, solver=None, make_GM=None):\n",
    "    \"\"\"\n",
    "    Constrain the model with experimental data and calculate the objective function value using pFBA.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: COBRA model to be constrained.\n",
    "    - time: Time interval for applying the experimental constraints. Default is 'P2 to P4'.\n",
    "    - objective: The objective reaction. Default is 'biomass_cho_s'.\n",
    "    - solver: Solver to be used. Default is 'gurobi'.\n",
    "    \n",
    "    Returns:\n",
    "    - pfba_obj: The optimized objective function value (growth rate or other objective).\n",
    "    - pfba_solution: The full pFBA solution (flux distribution).\n",
    "    \"\"\"\n",
    "    \n",
    "    GM = model.copy()  # Copy the model to avoid modifying the original\n",
    "    temp_dict = exp_dict\n",
    "    \n",
    "    # Default values if no argument is provided\n",
    "    if objective is None:\n",
    "        objective = 'biomass_cho_s'\n",
    "    if solver is None:\n",
    "        solver = 'gurobi'\n",
    "\n",
    "    # Set the solver and the objective reaction\n",
    "    GM.solver = solver\n",
    "    GM.objective = objective\n",
    "\n",
    "    # Constraint the model with experimental data\n",
    "    #if objective is None:\n",
    "    #    GM.reactions.biomass_cho_s.bounds = temp_dict['exp_growth_rate'][time]\n",
    "    \n",
    "    for rxn in GM.boundary:\n",
    "        # Models that are forced to secrete ethanol are not feasible\n",
    "        if rxn.id == 'EX_etoh_e':\n",
    "            rxn.bounds = (-0.1,0.1)\n",
    "            continue\n",
    "\n",
    "        # Replace the lower and upper bound with experimental data\n",
    "        if rxn.id in temp_dict.keys():\n",
    "            rxn.bounds = temp_dict[rxn.id][time]\n",
    "            continue\n",
    "\n",
    "        # Keep boundaries open for essential metabolites\n",
    "        if rxn.id == 'EX_h2o_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "        if rxn.id == 'EX_h_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "        if rxn.id == 'EX_o2_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "        if rxn.id == 'EX_hco3_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "        if rxn.id == 'EX_so4_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "        if rxn.id == 'EX_pi_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "\n",
    "        # Boundaries from Sink reactions on iCHO_v1\n",
    "        if rxn.id == 'SK_Asn_X_Ser_Thr_r':\n",
    "            rxn.bounds = (-0.001,1000)\n",
    "            continue\n",
    "        if rxn.id == 'SK_Tyr_ggn_c':\n",
    "            rxn.bounds = (-0.001,1000)\n",
    "            continue\n",
    "        if rxn.id == 'SK_Ser_Thr_g':\n",
    "            rxn.bounds = (-0.001,1000)\n",
    "            continue\n",
    "        if rxn.id == 'SK_pre_prot_r':\n",
    "            rxn.bounds = (-0.001,1000)\n",
    "            continue\n",
    "\n",
    "        # Close uptake rates for the rest of the boundaries\n",
    "        if rxn.id.startswith(\"EX_\"):\n",
    "            rxn.bounds = (0,1000) \n",
    "        if rxn.id.startswith(\"SK_\"):\n",
    "            rxn.bounds = (-0.00001,1000)\n",
    "        if rxn.id.startswith(\"DM_\"):\n",
    "            rxn.bounds = (0,1000)\n",
    "    model_exp_constrained = GM \n",
    "    \n",
    "    if make_GM == True:\n",
    "        for rxn in GM.boundary:\n",
    "            if rxn.id in temp_dict.keys():\n",
    "                rxn.bounds = (-1000,1000)\n",
    "                print(rxn.bounds)\n",
    "                print(rxn)\n",
    "                continue\n",
    "        pfba_solution_GM = cobra.flux_analysis.pfba(GM)\n",
    "        pfba_obj_GM = pfba_solution_GM.fluxes[objective] \n",
    "        print(f\"Optimized objective w/ opened bounds (growth rate): {pfba_obj_GM}\")\n",
    "    else: \n",
    "        pfba_obj_GM =[]\n",
    "        GM = []\n",
    "            \n",
    "            \n",
    "    # Perform pFBA (parsimonious FBA) to minimize the total flux\n",
    "    pfba_solution = cobra.flux_analysis.pfba(model_exp_constrained)\n",
    "    pfba_obj = pfba_solution.fluxes[objective]\n",
    "\n",
    "    # Print and return the objective value and the full pFBA solution\n",
    "    print(f\"Optimized objective w/ exp constraints (growth rate): {pfba_obj}\")\n",
    "    \n",
    "    # Return the objective value and the full pFBA solution\n",
    "    return model_exp_constrained, pfba_obj, pfba_solution, pfba_obj_GM, GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef104b-8ee5-4d1e-a063-18092f6eff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constraint_model_feg_v2(model, exp_dict, exp_cond, exp_time, objective='biomass_cho_s', solver='gurobi'):\n",
    "    \"\"\"\n",
    "    Constrain the model with experimental data and calculate the objective function value using pFBA.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: COBRA model to be constrained.\n",
    "    - exp_dict: Dictionary containing experimental constraints for reactions.\n",
    "        - objective: The objective reaction. Default is 'biomass_cho_s'.\n",
    "    - exp_cond: Experimental condition identifier.\n",
    "    - exp_time: Experimental time point.\n",
    "    - solver: Solver to be used. Default is 'gurobi'.\n",
    "    \n",
    "    Returns:\n",
    "    - model_exp_constrained: The constrained COBRA model.\n",
    "    - pfba_obj: The optimized objective function value (growth rate or other objective).\n",
    "    - pfba_solution: The full pFBA solution (flux distribution).\n",
    "    \"\"\"\n",
    "    # Copy the model to avoid modifying the original\n",
    "    GM = model.copy()\n",
    "    temp_dict = exp_dict\n",
    "\n",
    "    # Set the solver and the objective reaction\n",
    "    GM.solver = solver\n",
    "    GM.objective = objective\n",
    "\n",
    "    \n",
    "    # Open the bounds for the biomass reaction\n",
    "    GM.reactions.get_by_id(objective).bounds = (0, 1000)\n",
    "    \n",
    "    for rxn in GM.boundary:\n",
    "        # Keep boundaries open for essential metabolites\n",
    "        if rxn.id in ['EX_h2o_e', 'EX_h_e', 'EX_o2_e', 'EX_hco3_e', 'EX_so4_e', 'EX_pi_e']:\n",
    "            rxn.bounds = (-1000, 1000)\n",
    "        elif rxn.id in ['SK_Asn_X_Ser_Thr_r', 'SK_Tyr_ggn_c', 'SK_Ser_Thr_g', 'SK_pre_prot_r']:\n",
    "            rxn.bounds = (-0.001, 1000)\n",
    "        elif rxn.id.startswith((\"EX_\", \"SK_\", \"DM_\")):\n",
    "            rxn.bounds = (0, 1000)  # Close uptake rates for others\n",
    "\n",
    "    print(f'Calculating Growth Rate...')\n",
    "    exp_gr = exp_dict['exp_growth_rate'][(exp_cond, exp_time)]\n",
    "    print(f'Experimental growth rate is: {exp_gr}')\n",
    "    \n",
    "    for reaction in GM.reactions:\n",
    "        if reaction.id == 'EX_etoh_e':  # Model creates infeasible solutions when secreting ethanol\n",
    "            continue\n",
    "        for r, v in exp_dict.items():\n",
    "            if reaction.id == r:\n",
    "                reaction.upper_bound = 1000\n",
    "                reaction.lower_bound = v[(exp_cond, exp_time)]\n",
    "\n",
    "    pfba_solution = cobra.flux_analysis.pfba(GM)\n",
    "    pfba_obj = pfba_solution.fluxes[objective]\n",
    "    print(f'Simulated growth rate is: {pfba_obj}')\n",
    "\n",
    "    return GM, pfba_obj, pfba_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d67e573-e174-4e5c-b57e-8e227a81f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pablo's modifification\n",
    "\n",
    "\n",
    "def find_and_match_essential_genes(model, df_exp_essential, save_csv=True, print_df=False, model_GM = None):\n",
    "    \"\"\"\n",
    "    This function finds and matches essential genes in the model with experimental Entrez gene data.\n",
    "    It returns the number of total matched genes (len_mat) and the number of essential matched genes (len_mat_ess).\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the necessary columns 'entrez_gene_id' and 'gene' exist in the dataframe\n",
    "    required_columns = ['entrez_gene_id', 'gene']\n",
    "    for col in required_columns:\n",
    "        if col not in df_exp_essential.columns:\n",
    "            raise KeyError(f\"Column '{col}' is missing from the dataframe.\")\n",
    "\n",
    "    # Create a reverse lookup dictionary where the key is the Entrez Gene ID and the value is the gene symbol\n",
    "    entrez_dict = df_exp_essential.set_index('entrez_gene_id')['gene'].to_dict()\n",
    "\n",
    "    # Matching metabolic genes\n",
    "    tmp_gene = []    \n",
    "    for gene in model.genes:\n",
    "        # Check if the gene.id matches any Entrez Gene ID in the reverse dictionary\n",
    "        if gene.id in entrez_dict:\n",
    "            entrez_gene_symbol = entrez_dict[gene.id]\n",
    "            tmp_gene.append((gene.id, gene.name, entrez_gene_symbol))\n",
    "    \n",
    "    # Number of total matched genes\n",
    "    len_mat = len(tmp_gene)\n",
    "\n",
    "    # Find the essential reactions for the given model\n",
    "    threshold = model.slim_optimize(error_value=None) * 0.9\n",
    "    essential_reactions = find_essential_reactions(model, threshold=threshold)\n",
    "\n",
    "    # Remove tRNA biosynthesis reactions (specifically from iCHO2291\n",
    "    essential_reactions = [r for r in essential_reactions if not (r.subsystem == 'Biomass synthesis' and r.id.endswith('TRS'))]\n",
    "\n",
    "\n",
    "    # Extract genes from the essential reactions list\n",
    "    essential_genes = set([g for r in essential_reactions for g in r.genes])\n",
    "        \n",
    "    # Create a list to store the matched essential genes\n",
    "    matched_genes = []\n",
    "\n",
    "    # Iterate over the essential genes and check if they match with the Entrez Gene IDs\n",
    "    for gene in essential_genes:\n",
    "        gene_exp_ess = model.genes.get_by_id(gene.id)  # Get the gene from the model\n",
    "\n",
    "        if gene_exp_ess.id in entrez_dict:\n",
    "            entrez_gene_symbol = entrez_dict[gene_exp_ess.id]\n",
    "            matched_genes.append((gene_exp_ess.id, gene_exp_ess.name, entrez_gene_symbol))\n",
    "\n",
    "    # Convert the matched essential genes into a DataFrame\n",
    "    matched_genes_essential_df = pd.DataFrame(matched_genes, columns=['gene_exp_ess.id', 'gene_exp_ess.name', 'entrez_gene_symbol'])\n",
    "\n",
    "    # Save the result to a CSV file if save_csv is True\n",
    "    if save_csv:\n",
    "        matched_genes_essential_df.to_csv(\"'../Data/Gene_Essentiality/matched_gene_entrez_ids_feg.csv\", index=False)\n",
    "\n",
    "    # Print the DataFrame if print_df is True\n",
    "    if print_df:\n",
    "        print(matched_genes_essential_df)\n",
    "\n",
    "    # Number of essential matched genes\n",
    "    len_mat_ess = len(matched_genes_essential_df)\n",
    "    \n",
    "    if model_GM is None:\n",
    "        # Print the summary information\n",
    "        print(f\"Total matched metabolic genes: {len_mat}\")\n",
    "        print(f\"Matched essential genes: {len_mat_ess}/{len_mat}\")\n",
    "        print(f\"Total simulated essential genes: {len(essential_genes)}\")\n",
    "        len_mat_GM_ess = []\n",
    "    else: \n",
    "        \n",
    "        essential_genes = find_essential_genes(model_GM)\n",
    "\n",
    "        # Create a list to store the matched essential genes\n",
    "        matched_genes_GM = []\n",
    "\n",
    "        # Iterate over the essential genes and check if they match with the Entrez Gene IDs\n",
    "        for gene in essential_genes:\n",
    "            gene_exp_ess_GM = model_GM.genes.get_by_id(gene.id)  # Get the gene from the model\n",
    "\n",
    "            if gene_exp_ess_GM.id in entrez_dict:\n",
    "                entrez_gene_symbol = entrez_dict[gene_exp_ess_GM.id]\n",
    "                matched_genes_GM.append((gene_exp_ess_GM.id, gene_exp_ess_GM.name, entrez_gene_symbol))\n",
    "\n",
    "        # Convert the matched essential genes into a DataFrame\n",
    "        matched_genes_essential_GM_df = pd.DataFrame(matched_genes_GM, columns=['gene_exp_ess_GM.id', 'gene_exp_ess_GM.name', 'entrez_gene_symbol'])\n",
    "        len_mat_GM_ess = len(matched_genes_essential_GM_df)\n",
    "        # Print the summary information\n",
    "        print(f\"Total matched metabolic genes_GM: {len_mat}\")\n",
    "        print(f\"Matched essential genes_GM: {len_mat_GM_ess}/{len_mat}\")\n",
    "        print(f\"Total simulated essential genes_GM: {len(essential_genes)}\")\n",
    "        \n",
    "\n",
    "\n",
    "    # Return the matched DataFrame and gene counts\n",
    "    return matched_genes_essential_df, len_mat, len_mat_ess, len_mat_GM_ess, essential_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_reaction_ids_specific(model):\n",
    "    # Iterate over each reaction in the model\n",
    "    for rxn in model.reactions:\n",
    "        # Check if the reaction ID contains \"(e)\"\n",
    "        if \"(e)\" in rxn.id:\n",
    "            # Replace \"(e)\" with \"_e\"\n",
    "            new_id = rxn.id.replace(\"(e)\", \"_e\")\n",
    "            print(f\"Updating reaction ID: {rxn.id} -> {new_id}\")\n",
    "            # Update the reaction ID with the new one\n",
    "            rxn.id = new_id\n",
    "            continue\n",
    "        \n",
    "        if \"(c)\" in rxn.id:\n",
    "            new_id = rxn.id.replace(\"(c)\", \"_c\")\n",
    "            print(f\"Updating reaction ID: {rxn.id} -> {new_id}\")\n",
    "            # Update the reaction ID with the new one\n",
    "            rxn.id = new_id\n",
    "            continue\n",
    "        \n",
    "        if \"(x)\" in rxn.id:\n",
    "            new_id = rxn.id.replace(\"(x)\", \"_x\")\n",
    "            print(f\"Updating reaction ID: {rxn.id} -> {new_id}\")\n",
    "            # Update the reaction ID with the new one\n",
    "            rxn.id = new_id\n",
    "            continue\n",
    "        \n",
    "        if \"(r)\" in rxn.id:\n",
    "            new_id = rxn.id.replace(\"(r)\", \"_r\")\n",
    "            print(f\"Updating reaction ID: {rxn.id} -> {new_id}\")\n",
    "            # Update the reaction ID with the new one\n",
    "            rxn.id = new_id\n",
    "            continue\n",
    "        \n",
    "        if \"(g)\" in rxn.id:\n",
    "            new_id = rxn.id.replace(\"(g)\", \"_g\")\n",
    "            print(f\"Updating reaction ID: {rxn.id} -> {new_id}\")\n",
    "            # Update the reaction ID with the new one\n",
    "            rxn.id = new_id\n",
    "            continue\n",
    "        \n",
    "        if \"_e_\" in rxn.id:\n",
    "            # Replace \"(e)\" with \"_e\"\n",
    "            new_id = rxn.id.replace(\"_e_\", \"_e\")\n",
    "            print(f\"Updating reaction ID: {rxn.id} -> {new_id}\")\n",
    "            # Update the reaction ID with the new one\n",
    "            rxn.id = new_id\n",
    "            continue\n",
    "        \n",
    "        if \"_c_\" in rxn.id:\n",
    "            # Replace \"_c_\" with \"_c\"\n",
    "            new_id = rxn.id.replace(\"_c_\", \"_c\")\n",
    "            print(f\"Updating reaction ID: {rxn.id} -> {new_id}\")\n",
    "            # Update the reaction ID with the new one\n",
    "            rxn.id = new_id\n",
    "            continue\n",
    "        \n",
    "        if \"_x_\" in rxn.id:\n",
    "            new_id = rxn.id.replace(\"_x_\", \"_x\")\n",
    "            print(f\"Updating reaction ID: {rxn.id} -> {new_id}\")\n",
    "            # Update the reaction ID with the new one\n",
    "            rxn.id = new_id\n",
    "            continue\n",
    "        \n",
    "        if \"_r_\" in rxn.id:\n",
    "            new_id = rxn.id.replace(\"_r_\", \"_r\")\n",
    "            print(f\"Updating reaction ID: {rxn.id} -> {new_id}\")\n",
    "            # Update the reaction ID with the new one\n",
    "            rxn.id = new_id\n",
    "            continue\n",
    "        \n",
    "        if \"_g_\" in rxn.id:\n",
    "            new_id = rxn.id.replace(\"_g_\", \"_g\")\n",
    "            print(f\"Updating reaction ID: {rxn.id} -> {new_id}\")\n",
    "            # Update the reaction ID with the new one\n",
    "            rxn.id = new_id\n",
    "            continue\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2d09a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iCHO2291_changed = update_reaction_ids_specific(iCHO2291)\n",
    "iCHO1766_changed = update_reaction_ids_specific(iCHO1766)\n",
    "iCHO2101_changed = update_reaction_ids_specific(iCHO2101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e13e3-e66f-44a4-8aa3-f6ddffd7b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_time = 'P2 to P4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593e1064-a181-439a-a70f-656a85f1a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "GM_constrained_WT_P4_Bio141, _, _, = constraint_model_feg_v2(iCHO3K, exp_dict=uptsec_wt, exp_cond='U1', exp_time=exp_time, objective='biomass_cho_s', solver='gurobi')\n",
    "matched_df_WT_P4_Bio141,len_WT_P4_Bio141,len_3WT_P4_Bio141_ess, len_WT_P4_Bio141_ess_GM, WT_P4_Bio141_essential_reactions = find_and_match_essential_genes(GM_constrained_WT_P4_Bio141, df_loaded, save_csv=False, print_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe66bf-5560-4fb8-9129-186a8f4f7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "GM_constrained_WT_P4_Bio142, _, _, = constraint_model_feg_v2(iCHO3K, exp_dict=uptsec_wt, exp_cond='U2', exp_time=exp_time, objective='biomass_cho_s', solver='gurobi')\n",
    "matched_df_WT_P4_Bio142,len_WT_P4_Bio142,len_3WT_P4_Bio142_ess, len_WT_P4_Bio142_ess_GM, WT_P4_Bio142_essential_reactions = find_and_match_essential_genes(GM_constrained_WT_P4_Bio142, df_loaded, save_csv=False, print_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dd60bb-b6a4-4bd8-b8d2-78ac832463fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GM_constrained_WT_P4_Bio143, _, _, = constraint_model_feg_v2(iCHO3K, exp_dict=uptsec_wt, exp_cond='U3', exp_time=exp_time, objective='biomass_cho_s', solver='gurobi')\n",
    "matched_df_WT_P4_Bio143,len_WT_P4_Bio143,len_3WT_P4_Bio143_ess, len_WT_P4_Bio143_ess_GM, WT_P4_Bio143_essential_reactions = find_and_match_essential_genes(GM_constrained_WT_P4_Bio143, df_loaded, save_csv=False, print_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f17cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "GM_constrained_1766, _, _, _, GM_unconstrained_1766 = constraint_model_feg(iCHO1766_changed, time=exp_time, exp_dict=uptsec_intrvl_wt, objective = \"biomass_cho\")\n",
    "matched_df_1766,len_1766,len_1766_ess,len_1766_ess_GM, icho1766_essential_reactions = find_and_match_essential_genes(GM_constrained_1766, df_loaded, save_csv=False, print_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca244db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GM_constrained_2101, _, _, _, GM_unconstrained_2101 = constraint_model_feg(iCHO2101_changed, time=exp_time, exp_dict=uptsec_intrvl_wt, objective = \"biomass_cho\")\n",
    "matched_df_2101,len_2101,len_2101_ess, len_2101_ess_GM, icho2101_essential_reactions = find_and_match_essential_genes(GM_constrained_2101, df_loaded, save_csv=False, print_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95984f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GM_constrained_2291, _, _, _, GM_unconstrained_2291 = constraint_model_feg(iCHO2291_changed, time=exp_time, exp_dict=uptsec_intrvl_wt, objective = \"biomass_cho\")\n",
    "matched_df_2291,len_2291,len_2291_ess, len_2291_ess_GM, icho2291_essential_reactions = find_and_match_essential_genes(GM_constrained_2291, df_loaded, save_csv=False, print_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804e2e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GM_constrained_3K, _, _, _, GM_unconstrained_3K = constraint_model_feg(iCHO3K, time=exp_time, exp_dict=uptsec_intrvl_wt, objective = \"biomass_cho\")\n",
    "matched_df_3K,len_3k,len_3k_ess, len_3k_ess_GM, icho3K_essential_reactions = find_and_match_essential_genes(GM_constrained_3K, df_loaded, save_csv=False, print_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01856159",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dong-Hyuk's modification -  To examine the differences before and after removing ATP and glucose loop reactions from the iCHO3K reconstruction\n",
    "\"\"\"\n",
    "\n",
    "with iCHO3K as model:\n",
    "    objective = 'biomass_cho_s'\n",
    "    model.objective = objective\n",
    "    \n",
    "    filtered_atp_loop_reactions = [\n",
    "    'SCP22x','TMNDNCCOAtx','OCCOAtx','r0391','BiGGRxn67','r2247','r2246','r2245','r2317','HMR_0293',\n",
    "    'HMR_7741','r1453','r1393','NICRNS','GapFill-R08726','RE2915M','HMR_3288','HMR_1325','RE2439C',\n",
    "     'r1450','RE3477C','AAPSAS','r0698','3HDH260p','HMR_3272','ACOAD183n3m','GapFill-R01463','r1468',\n",
    "     'r0655','r0603','r0541','HMR_1329','GapFill-R03599','AKGDm','r0556','OIVD1m','OIVD3m','2OXOADOXm',\n",
    "     'r0386','r0451','GLYCLm','MACACI'\n",
    "    ]\n",
    "    \n",
    "    glucloop_reactions = [\n",
    "    'GapFill-R01206', 'GAUGE-R00557', \n",
    "    'GAUGE-R00558', 'FNOR', 'GGH', 'r0741', 'r1479', 'XOLESTPOOL'\n",
    "    ]\n",
    "\n",
    "    model.remove_reactions(glucloop_reactions, remove_orphans=True)\n",
    "    model.remove_reactions(filtered_atp_loop_reactions, remove_orphans=True)\n",
    "\n",
    "\n",
    "    GM_constrained_3K, _, _, _, GM_unconstrained_3K = constraint_model_feg(model, time=exp_time, exp_dict=uptsec_intrvl_wt, objective = \"biomass_cho\")\n",
    "    matched_df_3K,len_3k,len_3k_ess, len_3k_ess_GM, icho3K_essential_reactions_2 = find_and_match_essential_genes(GM_constrained_3K, df_loaded, save_csv=False, print_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e562282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for the bar chart (len_ and len_ess for each model)\n",
    "data = {\n",
    "    'iCHO1766': [len_1766, len_1766_ess],\n",
    "    'iCHO2101': [len_2101, len_2101_ess],\n",
    "    'iCHO2291': [len_2291, len_2291_ess],\n",
    "    'iCHO3K': [len_3k, len_3k_ess]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "counts_df = pd.DataFrame(data, index=['Matched Genes', 'Matched Essential Genes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc2be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved aesthetics for a research publication plot\n",
    "def create_research_plot(counts_df):\n",
    "    # Set a professional color palette\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "    model_names = ['iCHO1766', 'iCHO2101', 'iCHO2291', 'iCHO3K']\n",
    "\n",
    "    # Create subplots with 1 row and 2 columns\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(7,2))  \n",
    "    \n",
    "    # Define the axes mapping for two categories\n",
    "    axes_mapping = {0: axes[0], 1: axes[1]}  # Mapping two axes\n",
    "    categories = ['Matched Genes', 'Matched Essential Genes']\n",
    "\n",
    "    # A function to annotate the bars with their values\n",
    "    def annotate_bars(ax):\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                        ha='center', va='bottom', xytext=(0, 3), textcoords='offset points', fontweight='light', fontsize=12)\n",
    "\n",
    "    # Plotting and annotating each category\n",
    "    for index, category in enumerate(categories):\n",
    "        ax = axes_mapping[index]\n",
    "        counts_df.loc[category].plot(kind='bar', ax=ax, title=category, color=colors, edgecolor='black', linewidth=.3, width=0.9, legend=False)\n",
    "        annotate_bars(ax)\n",
    "        ax.set_title(category, fontsize=15, fontweight='light', pad=16)\n",
    "        ax.grid(True, linestyle='-', linewidth=0.5, axis='y')\n",
    "        ax.set_xticks([])  # Remove x-axis ticks\n",
    "        ax.set_xticklabels([])  # Remove x-axis labels\n",
    "        ax.tick_params(axis='y', labelsize=8)\n",
    "\n",
    "    # Remove border of the plots\n",
    "    for ax in axes:  # Applies to both axes\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "\n",
    "#     # Create custom handles for the legend\n",
    "#     custom_handles = [mpatches.Patch(color=color, label=model_name) for color, model_name in zip(colors, model_names)]\n",
    "#     fig.legend(handles=custom_handles, loc='upper left', bbox_to_anchor=(0.15, 0.9), fontsize=10, frameon=False, fancybox=False, shadow=False)\n",
    "    \n",
    "    # Adjust spacing between the subplots\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig('../Analyses/recons_comparisons/Essential_genes_coverage_comparison.svg', format='svg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "create_research_plot(counts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9cd571",
   "metadata": {},
   "source": [
    "#### Comparisions of Essential genes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1973a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unique_genes(df1, df2, df3):\n",
    "    \"\"\"\n",
    "    Find unique genes in each DataFrame compared to others.\n",
    "    \"\"\"\n",
    "    # Convert gene columns to sets for comparison\n",
    "    genes_1 = set(df1['gene_exp_ess.id'])\n",
    "    genes_2 = set(df2['gene_exp_ess.id'])\n",
    "    genes_3 = set(df3['gene_exp_ess.id'])\n",
    "\n",
    "    # Find differences\n",
    "    unique_1 = genes_1 - genes_2 - genes_3\n",
    "    unique_2 = genes_2 - genes_1 - genes_3\n",
    "    unique_3 = genes_3 - genes_2 - genes_1\n",
    "\n",
    "    return unique_1, unique_2, unique_3\n",
    "\n",
    "def find_gene_reactions(model, unique_genes):\n",
    "    \"\"\"\n",
    "    For each gene, find associated reactions in the given model.\n",
    "    \"\"\"\n",
    "    for gene_id in unique_genes:\n",
    "        try:\n",
    "            # Get the gene object from the model\n",
    "            gene = model.genes.get_by_id(gene_id)\n",
    "            print(f\"Gene ID: {gene.id}, Name: {gene.name}\")\n",
    "            print(\"Associated Reactions:\")\n",
    "            \n",
    "            # Print associated reactions\n",
    "            for reaction in gene.reactions:\n",
    "                print(f\" - {reaction.id}: {reaction.reaction}\")\n",
    "        except KeyError:\n",
    "            print(f\"Gene {gene_id} not found in the model.\")\n",
    "            \n",
    "def find_gene_reactions_to_excel(model, unique_genes, model_name):\n",
    "    \"\"\"\n",
    "    For each gene, find associated reactions in the given model and store results in a DataFrame.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for gene_id in unique_genes:\n",
    "        try:\n",
    "            # Get the gene object from the model\n",
    "            gene = model.genes.get_by_id(gene_id)\n",
    "            \n",
    "            # Find associated reactions and append results\n",
    "            for reaction in gene.reactions:\n",
    "                results.append({\n",
    "                    'Gene ID': gene.id,\n",
    "                    'Gene Name': gene.name,\n",
    "                    'Reaction ID': reaction.id,\n",
    "                    'Reaction': reaction.reaction,\n",
    "                    'Model': model_name\n",
    "                })\n",
    "        except KeyError:\n",
    "            results.append({\n",
    "                'Gene ID': gene_id,\n",
    "                'Gene Name': 'Not Found',\n",
    "                'Reaction ID': 'N/A',\n",
    "                'Reaction': 'N/A',\n",
    "                'Model': model_name\n",
    "            })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Step 1: Find unique genes in each model\n",
    "unique_2101, unique_2291, unique_3K = find_unique_genes(matched_df_2101, matched_df_2291, matched_df_3K)\n",
    "\n",
    "# Step 2: Find reactions associated with the unique genes for each model\n",
    "print(\"\\nReactions for unique genes in iCHO2101:\")\n",
    "find_gene_reactions(iCHO2101_changed, unique_2101)\n",
    "\n",
    "print(\"\\nReactions for unique genes in iCHO2291:\")\n",
    "find_gene_reactions(iCHO2291_changed, unique_2291)\n",
    "\n",
    "print(\"\\nReactions for unique genes in iCHO3K:\")\n",
    "find_gene_reactions(iCHO3K, unique_3K)\n",
    "\n",
    "df_2101 = find_gene_reactions_to_excel(iCHO2101_changed, unique_2101, 'iCHO2101')\n",
    "df_2291 = find_gene_reactions_to_excel(iCHO2291_changed, unique_2291, 'iCHO2291')\n",
    "df_3K = find_gene_reactions_to_excel(iCHO3K, unique_3K, 'iCHO3K')\n",
    "\n",
    "\n",
    "combined_df = pd.concat([df_2101, df_2291, df_3K], ignore_index=True)\n",
    "\n",
    "combined_df.to_excel('unique_genes_reactions.xlsx', index=False)\n",
    "\n",
    "print(\"Results successfully saved to 'unique_genes_reactions.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca81d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "##### ----- Generate datasets from Google Sheet ----- #####\n",
    "#Credential file\n",
    "KEY_FILE_PATH = 'credentials.json'\n",
    "#CHO Network Reconstruction + Recon3D_v3 Google Sheet ID\n",
    "SPREADSHEET_ID = '1MlBXeHIKw8k8fZyXm-sN__AHTRSunJxar_-bqvukZws'\n",
    "# Initialize the GoogleSheet object\n",
    "sheet = GoogleSheet(SPREADSHEET_ID, KEY_FILE_PATH)\n",
    "# Read data from the Google Sheet\n",
    "sheet_rxns = 'Rxns'\n",
    "rxns = sheet.read_google_sheet(sheet_rxns)\n",
    "rxns_relevant_columns = rxns[['Reaction', 'GPR_yeo', 'GPR_final']]\n",
    "\n",
    "# Filter rows from rxns_relevant_columns that have Reaction IDs matching combined_df\n",
    "matching_rxns = rxns_relevant_columns[rxns_relevant_columns['Reaction'].isin(combined_df['Reaction ID'])]\n",
    "\n",
    "# Loop through the matching reactions and print 'GPR_yeo' and 'GPR_final' for each matching reaction\n",
    "for rxns_unique in combined_df['Reaction ID']:\n",
    "    # Find the row in rxns_relevant_columns that matches the rxns_unique\n",
    "    gpr_info = rxns_relevant_columns[rxns_relevant_columns['Reaction'] == rxns_unique]\n",
    "    \n",
    "    if not gpr_info.empty:\n",
    "        # Extract 'GPR_yeo' and 'GPR_final' for this reaction\n",
    "        gpr_yeo = gpr_info['GPR_yeo'].values[0]\n",
    "        gpr_final = gpr_info['GPR_final'].values[0]\n",
    "        \n",
    "        # Print or use the GPR information\n",
    "        print(f\"Reaction: {rxns_unique}\")\n",
    "        print(f\"GPR_yeo: {gpr_yeo}\")\n",
    "        print(f\"GPR_final: {gpr_final}\\n\")\n",
    "    else:\n",
    "        # If the reaction is not found, add it to the 'not_found_reactions' list\n",
    "        not_found_reactions.append(rxns_unique)\n",
    "\n",
    "# Print reactions not found in Google Sheet\n",
    "if not_found_reactions:\n",
    "    print(\"\\nReactions not found in the Google Sheet:\")\n",
    "    for reaction in not_found_reactions:\n",
    "        print(reaction)\n",
    "else:\n",
    "    print(\"\\nAll reactions found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120e6629",
   "metadata": {},
   "source": [
    "## MEMOTE for the different reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e42df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install memote\n",
    "# !pip install --upgrade typing_extensions\n",
    "# !pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # loading commands to control/navigate within the system architecture\n",
    "# Loading pandas, a library for data manipulation\n",
    "import os\n",
    "import xlrd\n",
    "import cobra\n",
    "from cobra.io import load_json_model\n",
    "# Loading numpy, a library fo manipulation of numbers\n",
    "import numpy as np\n",
    "\n",
    "# loading matplotlib, a library for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# loading Memote, quality assessment of GSMM\n",
    "from memote import test_model, snapshot_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ce20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iCHO3K = load_json_model('iCHO3595.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a46de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_return, mem_result = test_model(iCHO3K, results=True)\n",
    "with open('iOpol_MemoteReport.html', 'w') as f:\n",
    "    f.write(snapshot_report(mem_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87135296-4494-4d95-8b45-4db834938865",
   "metadata": {},
   "source": [
    "## Comparison of Secretory Pathway Recons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc952939",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/Sec_Recon_shared_genes/'\n",
    "\n",
    "with open(path+'common_jahirs_metrecon.txt', 'r') as file: common_jahirs_metrecon = [line.strip() for line in file]\n",
    "with open(path+'common_secrecon_jahirs.txt', 'r') as file: common_secrecon_jahirs = [line.strip() for line in file]\n",
    "with open(path+'common_secrecon_metrecon.txt', 'r') as file: common_secrecon_metrecon = [line.strip() for line in file]\n",
    "with open(path+'unique_secrecon_metrecon.txt', 'r') as file: unique_secrecon_metrecon = [line.strip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc79de3a-5336-48e7-8d87-8588a827e870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Subsystems of genes shared between Sec Recon and Met Recon (iCHO3000) minus Jahir's\n",
    "\n",
    "rxns_secrecon_metrecon = []\n",
    "subs_secrecon_metrecon = []\n",
    "for g in iCHO3000.genes:\n",
    "    if str(g) in unique_secrecon_metrecon:\n",
    "        for rxn in g.reactions:\n",
    "            if rxn.id not in rxns_secrecon_metrecon:\n",
    "                rxns_secrecon_metrecon.append(rxn.id)\n",
    "                subs_secrecon_metrecon.append(rxn.subsystem)\n",
    "\n",
    "\n",
    "# Subsystems of genes shared between Jahir's Recon and Met Recon (iCHO3000)\n",
    "\n",
    "rxns_jahirs_metrecon = []\n",
    "subs_jahirs_metrecon = []\n",
    "for g in iCHO3000.genes:\n",
    "    if str(g) in common_jahirs_metrecon:\n",
    "        for rxn in g.reactions:\n",
    "            if rxn.id not in rxns_jahirs_metrecon:\n",
    "                rxns_jahirs_metrecon.append(rxn.id)\n",
    "                subs_jahirs_metrecon.append(rxn.subsystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c934822c-d958-479c-82b9-70e94e199473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie Chart Subsystems of genes shared between Sec Recon and Met Recon (iCHO3000) minus Jahir's\n",
    "\n",
    "subsystem_counts = Counter(subs_secrecon_metrecon)\n",
    "labels = list(subsystem_counts.keys())\n",
    "sizes = list(subsystem_counts.values())\n",
    "\n",
    "# Plot the pie chart\n",
    "plt.figure(figsize=(10, 8)) \n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.title('Subsystem Distribution')\n",
    "plt.savefig('../Plots/pie_chart_subsystems_of_genes_shared_with_secrecon.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539c0a29-9f68-4f2e-a957-ba17827a9019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie Chart of subsystems of genes shared between Jahir's Recon and Met Recon (iCHO3000)\n",
    "\n",
    "subsystem_counts = Counter(subs_jahirs_metrecon)\n",
    "labels = list(subsystem_counts.keys())\n",
    "sizes = list(subsystem_counts.values())\n",
    "\n",
    "# Plot the pie chart\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal') \n",
    "plt.title('Subsystem Distribution')\n",
    "plt.savefig('../Plots/pie_chart_subsystems_of_genes_shared_with_jahirs.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483bd94f-d4f2-4da4-afae-f446e06df4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many reactions from the rxns_secrecon_metrecon come from Recon3D\n",
    "\n",
    "c=0\n",
    "for i, row in rxns.iterrows():\n",
    "    if (row['iCHO1766']=='-') and (row['iCH02101']=='-') and (row['iCHO2291']=='-'): #Check if the reactions has been added from Recon3D or other databases\n",
    "        r = str(row['Reaction'])\n",
    "        if r in rxns_secrecon_metrecon:\n",
    "            c+=1\n",
    "print(len(rxns_secrecon_metrecon))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258b19e-69c1-4a66-80b3-95b614ba0a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "from cobra.io import load_matlab_model\n",
    "\n",
    "# Load the .mat file using COBRApy\n",
    "model = load_matlab_model('../Data/Reconciliation/models/model_iCHO2291.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fcf1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
