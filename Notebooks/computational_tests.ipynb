{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Tests\n",
    "\n",
    "This notebook is intended for running different kinds of analyses that would validate our reconstruction.\n",
    "\n",
    "[1. Subsystem Overview and Analysis](#subsystems) <br>\n",
    "[2. Context-specific Model Generation](#context_specific) <br>\n",
    "[3. Biomass prediction using exp. data](#biomass) <br>\n",
    "[4. Flux Enrichment Analysis](#fea) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Subsystem Overview and Analysis <a id='subsystems'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from google_sheet import GoogleSheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- Generate Subsystems datasets from Google Sheet ----- #####\n",
    "\n",
    "#Credential file\n",
    "KEY_FILE_PATH = 'credentials.json'\n",
    "\n",
    "#CHO Network Reconstruction + Recon3D_v3 Google Sheet ID\n",
    "SPREADSHEET_ID = '1MlBXeHIKw8k8fZyXm-sN__AHTRSunJxar_-bqvukZws'\n",
    "\n",
    "# Initialize the GoogleSheet object\n",
    "sheet = GoogleSheet(SPREADSHEET_ID, KEY_FILE_PATH)\n",
    "\n",
    "# Read data from the Google Sheet\n",
    "sheet_subsystems = 'Summary Systems'\n",
    "subsystems = sheet.read_google_sheet(sheet_subsystems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### --- Pie Chart of the Amount of Reactions per System --- ####\n",
    "\n",
    "subsystems[\"Number of Reactions\"] = pd.to_numeric(subsystems[\"Number of Reactions\"])\n",
    "\n",
    "# Aggregate data by \"System\" and sum \"Number of Reactions\"\n",
    "system_reactions = subsystems.groupby(\"System\")[\"Number of Reactions\"].sum()\n",
    "\n",
    "# Set the figure and axes for more control\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Generate the pie chart again with the custom labels\n",
    "patches, texts, autotexts = ax.pie(system_reactions, labels=system_reactions.index, autopct=lambda p: '{:.1f}%'.format(p) if p > 0 else '', startangle=140, colors=plt.cm.tab20.colors)\n",
    "\n",
    "# Improve aesthetics\n",
    "for text in texts + autotexts:\n",
    "    text.set_color('black')\n",
    "ax.set_title(\"Pie Chart of Number of Reactions by System\", pad=30)  # Move the title upwards by increasing pad\n",
    "\n",
    "# Set equal aspect ratio\n",
    "ax.axis('equal')\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('../Plots/pie_chart_reactions_per_system.png')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Sunburst Plot\n",
    "fig = px.sunburst(subsystems, path=['System', 'Subsystems','Kegg Pathway'],\n",
    "                  color='System', title='System and Subsystems Relationship')\n",
    "\n",
    "fig.update_layout(width=1200, height=1000)\n",
    "\n",
    "fig.write_html(\"../Plots/sunburst_subsystems.html\") # Save as interactive HTML file\n",
    "fig.write_image(\"../Plots/sunburst_subsystems.png\", width=1200, height=1000)\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxotrophies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobra.io import load_json_model\n",
    "iCHO_path = \"iCHOv3_CHO_04032024.json\"\n",
    "iCHO = load_json_model(iCHO_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acids = {\n",
    "    \"arginine\": [\"EX_arg_L_e\", \"EX_arg_D_e\"],\n",
    "    \"asparagine\": [\"EX_asn_L_e\", \"EX_asn_D_e\"],\n",
    "    \"cysteine\": [\"EX_cys_L_e\", \"EX_cys_D_e\", \"EX_Lcystin_e\"],\n",
    "    \"histidine\": [\"EX_his_L_e\", \"EX_his_D_e\"],\n",
    "    \"isoleucine\": [\"EX_ile_L_e\", \"EX_ile_D_e\"],\n",
    "    \"leucine\": [\"EX_leu_L_e\", \"EX_leu_D_e\"],\n",
    "    \"lysine\": [\"EX_lys_L_e\", \"EX_lys_D_e\"],\n",
    "    \"methionine\": [\"EX_met_L_e\", \"EX_met_D_e\"],\n",
    "    \"phenylalanine\": [\"EX_phe_L_e\", \"EX_phe_D_e\"],\n",
    "    \"proline\": [\"EX_pro_L_e\", \"EX_pro_D_e\"],\n",
    "    \"threonine\": [\"EX_thr_L_e\", \"EX_thr_D_e\"],\n",
    "    \"tryptophan\": [\"EX_trp_L_e\", \"EX_trp_D_e\"],\n",
    "    \"valine\": [\"EX_val_L_e\", \"EX_val_D_e\"]\n",
    "}\n",
    "for amino_acid in amino_acids:\n",
    "    # ----- Setup initial bounds -----\n",
    "    for exchange_reaction in iCHO.exchanges:\n",
    "        exchange_reaction.bounds = -10, 10\n",
    "\n",
    "    # Arginine\n",
    "    iCHO.reactions.get_by_id('GAUGE-R00557').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('GAUGE-R10107').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('GAUGE-R00558').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('GLYAMDTRc').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('GAUGE-R10107').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('EX_valarggly_e').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('ARGSL').bounds = 0, 0\n",
    "\n",
    "    # Asparigine\n",
    "    iCHO.reactions.get_by_id('ASNS1').bounds = 0, 0\n",
    "\n",
    "    # Cysteine\n",
    "    iCHO.reactions.get_by_id('r0129').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('EX_cgly_e').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('AMPTASECG').bounds = -10, 0\n",
    "    iCHO.reactions.get_by_id('AMPTASECGe').bounds = -10, 0\n",
    "    iCHO.reactions.get_by_id('CYSTGL').bounds = -10, 0\n",
    "    iCHO.reactions.get_by_id('EX_HC00250_e').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('EX_sfcys_e').bounds = 0, 0\n",
    "\n",
    "    # Histidine\n",
    "    iCHO.reactions.get_by_id('VALTRPVALr').bounds = 0,0 \n",
    "\n",
    "    # Isoleucine - DONE\n",
    "    iCHO.reactions.get_by_id('EX_CE2916_e').bounds = 0,0 \n",
    "    iCHO.reactions.get_by_id('EX_CE2915_e').bounds = 0,0 \n",
    "    iCHO.reactions.get_by_id('ILETA').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('ILETAm').bounds = 0, 10\n",
    "\n",
    "    # Leucine\n",
    "    iCHO.reactions.get_by_id('LEULEULAPc').bounds = 0,0 \n",
    "    iCHO.reactions.get_by_id('EX_leugly_e').bounds = 0,0 \n",
    "    iCHO.reactions.get_by_id('EX_glyleu_e').bounds = 0,0 \n",
    "    iCHO.reactions.get_by_id('LEUTA').bounds = 0, 10 \n",
    "    iCHO.reactions.get_by_id('LEUTAm').bounds = 0, 10 \n",
    "    iCHO.reactions.get_by_id('EX_CE5797_e').bounds = 0, 0\n",
    "\n",
    "    # Lysine\n",
    "    iCHO.reactions.get_by_id('EX_biocyt_e').bounds = 0,0 \n",
    "\n",
    "    # Methionine\n",
    "    iCHO.reactions.get_by_id('METS').bounds = -10, 0 \n",
    "    iCHO.reactions.get_by_id('BHMT').bounds = -10, 0 \n",
    "    iCHO.reactions.get_by_id('GAUGE-R00648').bounds = 0, 10 \n",
    "    iCHO.reactions.get_by_id('UNK2').bounds = -10, 0 \n",
    "    iCHO.reactions.get_by_id('UNK3').bounds = -10, 0 \n",
    "    iCHO.reactions.get_by_id('TYRA').bounds = -10, 0 \n",
    "    #iCHO.reactions.get_by_id('GAUGE-R06895').bounds = 0, 0 # Curated by MR with 1 score / Erased from the reconstruction\n",
    "\n",
    "    # Phenylalanine\n",
    "    iCHO.reactions.get_by_id('EX_CE5786_e').bounds = 0, 0 \n",
    "    iCHO.reactions.get_by_id('EX_pheleu_e').bounds = 0, 0 \n",
    "    iCHO.reactions.get_by_id('EX_glyphe_e').bounds = 0, 0 \n",
    "    iCHO.reactions.get_by_id('EX_CE2917_e').bounds = 0, 0 \n",
    "    iCHO.reactions.get_by_id('EX_CE5786_e').bounds = 0, 0 \n",
    "    iCHO.reactions.get_by_id('EX_CE5789_e').bounds = 0, 0 \n",
    "    iCHO.reactions.get_by_id('EX_phpyr_e').bounds = 0, 0 \n",
    "\n",
    "    # Proline\n",
    "    iCHO.reactions.get_by_id('EX_glypro_e').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('EX_progly_e').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('P5CR').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('P5CRxm').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('P5CRx').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('P5CRm').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('r1453').bounds = 0, 10\n",
    "\n",
    "    # Threonine\n",
    "    #iCHO.reactions.get_by_id('THRS').bounds = 0,0  # Erased from the reconstruction\n",
    "\n",
    "\n",
    "    # Tryptophan\n",
    "    iCHO.reactions.get_by_id('NBAHH_ir').bounds = 0,0  \n",
    "\n",
    "    # Valine\n",
    "    iCHO.reactions.get_by_id('EX_valarggly_e').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('EX_vallystyr_e').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('VALTA').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('VALTAm').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('EX_valval_e').bounds = 0, 10\n",
    "    # -----------------------------------------\n",
    "\n",
    "    for exchange_reaction in iCHO.exchanges:\n",
    "        if exchange_reaction.id in amino_acids[amino_acid]:\n",
    "            exchange_reaction.bounds = 0, 10\n",
    "            # print(amino_acid, exchange_reaction.id, amino_acids[amino_acid])\n",
    "    sol = iCHO.optimize()\n",
    "    print(amino_acid, sol.objective_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acids = {\n",
    "    \"alanine\": [\"EX_ala_B_e\", \"EX_ala_L_e\", \"EX_ala_D_e\"],\n",
    "    \"arginine\": [\"EX_arg_L_e\", \"EX_arg_D_e\"],\n",
    "    \"asparagine\": [\"EX_asn_L_e\", \"EX_asn_D_e\"],\n",
    "    \"aspartic acid\": [\"EX_asp_L_e\", \"EX_asp_D_e\"],\n",
    "    \"cysteine\": [\"EX_cys_L_e\", \"EX_cys_D_e\"],\n",
    "    \"glutamine\": [\"EX_gln_L_e\", \"EX_gln_D_e\"],\n",
    "    \"glutamic acid\": [\"EX_glu_L_e\", \"EX_glu_D_e\"],\n",
    "    \"glycine\": [\"EX_gly_e\"],\n",
    "    \"histidine\": [\"EX_his_L_e\", \"EX_his_D_e\"],\n",
    "    \"isoleucine\": [\"EX_ile_L_e\", \"EX_ile_D_e\"],\n",
    "    \"leucine\": [\"EX_leu_L_e\", \"EX_leu_D_e\"],\n",
    "    \"lysine\": [\"EX_lys_L_e\", \"EX_lys_D_e\"],\n",
    "    \"methionine\": [\"EX_met_L_e\", \"EX_met_D_e\"],\n",
    "    \"phenylalanine\": [\"EX_phe_L_e\", \"EX_phe_D_e\"],\n",
    "    \"proline\": [\"EX_pro_L_e\", \"EX_pro_D_e\"],\n",
    "    \"serine\": [\"EX_ser_L_e\", \"EX_ser_D_e\"],\n",
    "    \"threonine\": [\"EX_thr_L_e\", \"EX_thr_D_e\"],\n",
    "    \"tryptophan\": [\"EX_trp_L_e\", \"EX_trp_D_e\"],\n",
    "    \"tyrosine\": [\"EX_tyr_L_e\", \"EX_tyr_D_e\"],\n",
    "    \"valine\": [\"EX_val_L_e\", \"EX_val_D_e\"]\n",
    "}\n",
    "\n",
    "def test_auxotrophy(model, amino_acids):\n",
    "    # Iterate through each amino acid and its corresponding exchange reactions\n",
    "    for amino_acid, reactions in amino_acids.items():\n",
    "        # Set the bounds for each exchange reaction\n",
    "        for exchange in model.exchanges:\n",
    "            if exchange.id in reactions:\n",
    "                exchange.bounds = (0, 10)  # Allow secretion but not uptake\n",
    "            else:\n",
    "                exchange.bounds = (-10, 10)  # Allow uptake and secretion\n",
    "\n",
    "        # Optimize the model for the current setup\n",
    "        solution = model.optimize()\n",
    "        if solution.status == \"optimal\":\n",
    "            print(f\"{amino_acid} biomass production: {solution.objective_value}\")\n",
    "        else:\n",
    "            print(f\"{amino_acid} optimization failed: {solution.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_auxotrophy(iCHO, amino_acids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iCHO.metabolites.leu_L_c.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gene Deletion test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Essential for growth genes and comparison to (An optimised genome-wide, virus free CRISPR screen for mammalian cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Commparsion to other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Context-specific Model Generation <a id='context_specific'></a>\n",
    "\n",
    "Here we use a matrix generated with rmf_CADRE to generate each context_specific model for each one of the conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "from cobra.io import load_json_model, save_json_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-03-04\n"
     ]
    }
   ],
   "source": [
    "# Load the matrix\n",
    "matrix = scipy.io.loadmat('../Data/Context_specific_models/CHO_retained_reactions.mat')['retR']\n",
    "\n",
    "# Load conditions\n",
    "conditions = open('../Data/Context_specific_models/uniqueConditions.txt', 'r').read().strip().split(',')\n",
    "\n",
    "# Load model\n",
    "model = load_json_model('iCHO3644_unblocked.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read LP format model from file /var/folders/_x/tfg8s2ks4n1ftkkwzp5sqjpc0000gn/T/tmp1nqe3e0z.lp\n",
      "Reading time = 0.05 seconds\n",
      ": 4728 rows, 17210 columns, 72834 nonzeros\n",
      "Model WT_P12 generated, 0\n",
      "Read LP format model from file /var/folders/_x/tfg8s2ks4n1ftkkwzp5sqjpc0000gn/T/tmpvu9ss9ng.lp\n",
      "Reading time = 0.05 seconds\n",
      ": 4728 rows, 17210 columns, 72834 nonzeros\n",
      "Model WT_P14 generated, 1\n",
      "Read LP format model from file /var/folders/_x/tfg8s2ks4n1ftkkwzp5sqjpc0000gn/T/tmpptazlufs.lp\n",
      "Reading time = 0.04 seconds\n",
      ": 4728 rows, 17210 columns, 72834 nonzeros\n",
      "Model WT_P2 generated, 2\n",
      "Read LP format model from file /var/folders/_x/tfg8s2ks4n1ftkkwzp5sqjpc0000gn/T/tmp20lcchp6.lp\n",
      "Reading time = 0.05 seconds\n",
      ": 4728 rows, 17210 columns, 72834 nonzeros\n",
      "Model WT_P4 generated, 3\n",
      "Read LP format model from file /var/folders/_x/tfg8s2ks4n1ftkkwzp5sqjpc0000gn/T/tmpcei3ahvb.lp\n",
      "Reading time = 0.05 seconds\n",
      ": 4728 rows, 17210 columns, 72834 nonzeros\n",
      "Model WT_P6 generated, 4\n",
      "Read LP format model from file /var/folders/_x/tfg8s2ks4n1ftkkwzp5sqjpc0000gn/T/tmpb2f44xv6.lp\n",
      "Reading time = 0.05 seconds\n",
      ": 4728 rows, 17210 columns, 72834 nonzeros\n",
      "Model WT_P8 generated, 5\n",
      "Read LP format model from file /var/folders/_x/tfg8s2ks4n1ftkkwzp5sqjpc0000gn/T/tmptxo28dde.lp\n",
      "Reading time = 0.05 seconds\n",
      ": 4728 rows, 17210 columns, 72834 nonzeros\n",
      "Model ZeLa_P12 generated, 6\n",
      "Read LP format model from file /var/folders/_x/tfg8s2ks4n1ftkkwzp5sqjpc0000gn/T/tmpc1l8tjss.lp\n",
      "Reading time = 0.05 seconds\n",
      ": 4728 rows, 17210 columns, 72834 nonzeros\n",
      "Model ZeLa_P14 generated, 7\n",
      "Read LP format model from file /var/folders/_x/tfg8s2ks4n1ftkkwzp5sqjpc0000gn/T/tmp2d5h1kal.lp\n",
      "Reading time = 0.05 seconds\n",
      ": 4728 rows, 17210 columns, 72834 nonzeros\n",
      "Model ZeLa_P2 generated, 8\n",
      "Read LP format model from file /var/folders/_x/tfg8s2ks4n1ftkkwzp5sqjpc0000gn/T/tmpmhwpytbs.lp\n",
      "Reading time = 0.05 seconds\n",
      ": 4728 rows, 17210 columns, 72834 nonzeros\n",
      "Model ZeLa_P4 generated, 9\n",
      "Read LP format model from file /var/folders/_x/tfg8s2ks4n1ftkkwzp5sqjpc0000gn/T/tmpmhbnm0l5.lp\n",
      "Reading time = 0.05 seconds\n",
      ": 4728 rows, 17210 columns, 72834 nonzeros\n",
      "Model ZeLa_P6 generated, 10\n",
      "Read LP format model from file /var/folders/_x/tfg8s2ks4n1ftkkwzp5sqjpc0000gn/T/tmpsaxku7ee.lp\n",
      "Reading time = 0.04 seconds\n",
      ": 4728 rows, 17210 columns, 72834 nonzeros\n",
      "Model ZeLa_P8 generated, 11\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each condition to generate a context-specific model for each one\n",
    "\n",
    "for i, condition in enumerate(conditions):\n",
    "    \n",
    "    # Create a copy of the model for each condition\n",
    "    submodel = model.copy()\n",
    "    \n",
    "    # Assign a unique name based on the condition index\n",
    "    submodel.id = condition\n",
    "    \n",
    "    # List to collect reactions to remove\n",
    "    reactions_to_remove = [submodel.reactions[j].id for j in range(matrix.shape[0]) if matrix[j, i] == 0]\n",
    "    \n",
    "    # Remove the collected reactions from the submodel\n",
    "    submodel.remove_reactions(reactions_to_remove, remove_orphans=False)\n",
    "\n",
    "    # Save each model as JSON with a unique name based on the condition\n",
    "    model_name_json = f'../Data/Context_specific_models/iCHO_{condition}.json'\n",
    "    save_json_model(submodel, model_name_json)\n",
    "    \n",
    "    print(f'Model {condition} generated, {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Biomass prediction using exp. data <a id='biomass'></a>\n",
    "\n",
    "Here we incorporate uptake and secretion rates from (https://www.sciencedirect.com/science/article/pii/S2405471216303635?via%3Dihub) data and calculate the growth rate (Figure 3). Reproduce Hooman's analsys with iCHO_v1 and incorporate iCHO2291 and iCHO2441 into the analysis.\n",
    "\n",
    "To do:\n",
    "- Try ecFBA with enzyme trunover numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cobra\n",
    "from cobra.io import load_json_model, read_sbml_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "\n",
    "iCHO1766 = read_sbml_model('../Data/Reconciliation/models/iCHOv1_final.xml')\n",
    "iCHO2291 = read_sbml_model('../Data/Reconciliation/models/iCHO2291.xml')\n",
    "iCHO2441 = read_sbml_model('../Data/Reconciliation/models/iCHO2441.xml')\n",
    "iCHO3000 = load_json_model('iCHO3644.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocess and standarization of iCHO1766\n",
    "iCHO1766.id = 'iCHO1766'\n",
    "iCHO1766.reactions.biomass_cho_producing.id = 'biomass_cho_prod'\n",
    "for r in iCHO1766.reactions:\n",
    "    if r.id.endswith(\"_\"):\n",
    "        r.id = r.id[:-1]\n",
    "\n",
    "# Preprocess and standarization of iCHO2101\n",
    "iCHO2441.id = 'iCHO2441'\n",
    "for r in iCHO2441.reactions:\n",
    "    if r.id.endswith(\"(e)\"):\n",
    "        r.id = r.id.replace(\"(e)\", \"_e\")\n",
    "    if r.id == \"SK_Asn_X_Ser/Thr[r]\":\n",
    "        r.id = \"SK_Asn_X_Ser_Thr_r\"\n",
    "    if r.id == \"SK_pre_prot[r]\":\n",
    "        r.id = \"SK_pre_prot_r\"\n",
    "    if r.id == \"SK_Ser/Thr[g]\":\n",
    "        r.id = \"SK_Ser_Thr_g\"\n",
    "    if r.id == \"SK_Tyr_ggn[c]\":\n",
    "        r.id = \"SK_Tyr_ggn_c\"\n",
    "    if r.id == \"DM_igg[g]\":\n",
    "        r.id = \"DM_igg_g\"\n",
    "\n",
    "# Preprocess and standarization of iCHO2291\n",
    "for r in iCHO2291.reactions:\n",
    "    if r.id.endswith(\"(e)\"):\n",
    "        r.id = r.id.replace(\"(e)\", \"_e\")\n",
    "    if r.id == \"SK_Asn_X_Ser/Thr[r]\":\n",
    "        r.id = \"SK_Asn_X_Ser_Thr_r\"\n",
    "    if r.id == \"SK_pre_prot[r]\":\n",
    "        r.id = \"SK_pre_prot_r\"\n",
    "    if r.id == \"SK_Ser/Thr[g]\":\n",
    "        r.id = \"SK_Ser_Thr_g\"\n",
    "    if r.id == \"SK_Tyr_ggn[c]\":\n",
    "        r.id = \"SK_Tyr_ggn_c\"\n",
    "    if r.id == \"DM_igg[g]\":\n",
    "        r.id = \"DM_igg_g\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models = [iCHO1766, iCHO2291, iCHO2441, iCHO3000]\n",
    "models = [iCHO3000]\n",
    "\n",
    "for model in models:\n",
    "    model.reactions.biomass_cho.bounds = (0.0,10)\n",
    "    model.reactions.biomass_cho_prod.bounds = (0.0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uptsec = pd.read_excel('../Data/Uptake_Secretion_Rates/mmc4.xlsx', header=2)\n",
    "\n",
    "biomass_bounds = uptsec[42:44]\n",
    "biomass_bounds = biomass_bounds.set_index(['Reaction'])\n",
    "\n",
    "uptsec = uptsec[:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hp = uptsec.set_index('Reaction')['HP'].to_dict()\n",
    "hp_nabu = uptsec.set_index('Reaction')['HP+NaBu'].to_dict()\n",
    "lp = uptsec.set_index('Reaction')['LP'].to_dict()\n",
    "lp_nabu = uptsec.set_index('Reaction')['LP+NaBu'].to_dict()\n",
    "early_exp = uptsec.set_index('Reaction')['Early Exp'].to_dict()\n",
    "late_exp = uptsec.set_index('Reaction')['Late Exp'].to_dict()\n",
    "cold_1 = uptsec.set_index('Reaction')['Cold 1'].to_dict()\n",
    "cold_2 = uptsec.set_index('Reaction')['Cold 2'].to_dict()\n",
    "\n",
    "conditions = ['HP', 'HP+NaBu', 'LP', 'LP+NaBu', 'Early Exp', 'Late Exp', 'Cold 1', 'Cold 2']\n",
    "dicts = [hp, hp_nabu, lp, lp_nabu, early_exp, late_exp, cold_1, cold_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    for rxn in model.boundary:\n",
    "    \n",
    "        # IMPORTANT, all ex should be 0 - 1000, except those that we know are being uptaken by the cell\n",
    "        \n",
    "        if rxn.id.startswith(\"EX_\"):\n",
    "            rxn.bounds = (0,1000) \n",
    "        if rxn.id.startswith(\"SK_\"):\n",
    "            rxn.bounds = (-1000,1000)\n",
    "        if rxn.id.startswith(\"DM_\"):\n",
    "            rxn.bounds = (0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pfba_solutions_fluxes = []\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Model\", \"Condition\", \"Biomass_CHO\", \"Biomass_CHO_Prod\"])\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    model_data = []\n",
    "    \n",
    "    for cond,dic in zip(conditions,dicts):\n",
    "        \n",
    "        # Set lower bounds of the reactions according to the experimental data\n",
    "        for reaction in model.reactions:\n",
    "            for r,v in dic.items():\n",
    "                if reaction.id == r:\n",
    "                    if not pd.isna(v):\n",
    "                        reaction.lower_bound = v\n",
    "    \n",
    "        # Calculate growth rate for each condition\n",
    "        print('----------------------')\n",
    "        print(f' Condtion: {cond} ')\n",
    "        print('----------------------')\n",
    "\n",
    "        # Print experimental growth rate\n",
    "        exp_gr = biomass_bounds[cond]['Experimental growth rate']\n",
    "        print(f'Experimental Growth Rate: {exp_gr}')\n",
    "\n",
    "        # Calculate growth for biomass_cho\n",
    "        model.objective = model.reactions.biomass_cho\n",
    "        model.reactions.biomass_cho_prod.upper_bound = 0\n",
    "        model.reactions.biomass_cho.upper_bound = 1000\n",
    "        pfba_solution = cobra.flux_analysis.pfba(model)\n",
    "        pfba_solution_biomass_cho = pfba_solution.fluxes['biomass_cho']\n",
    "        print(f'Model: {model.id}, Biomass: {pfba_solution_biomass_cho}')\n",
    "\n",
    "        # Calculate growth for biomass_cho_prod\n",
    "        model.objective = model.reactions.biomass_cho_prod\n",
    "        model.reactions.biomass_cho_prod.upper_bound = 1000\n",
    "        model.reactions.biomass_cho.upper_bound = 0\n",
    "        pfba_solution = cobra.flux_analysis.pfba(model)\n",
    "        pfba_solution_biomass_cho_prod = pfba_solution.fluxes['biomass_cho_prod']\n",
    "        print(f'Model: {model.id}, Biomass Prod: {pfba_solution_biomass_cho_prod}')\n",
    "        print(' ')\n",
    "\n",
    "        # Save the solution with metadata\n",
    "        pfba_solutions_fluxes.append({\n",
    "            \"model_id\": model.id,\n",
    "            \"condition\": cond,\n",
    "            \"type\": \"biomass_cho_prod\",\n",
    "            \"fluxes\": pfba_solution.fluxes\n",
    "        })\n",
    "\n",
    "        # Append the results to the model_data list\n",
    "        model_data.append({\n",
    "            'Model': model.id,\n",
    "            'Condition': cond,\n",
    "            'Biomass_CHO': pfba_solution_biomass_cho,\n",
    "            'Biomass_CHO_Prod': pfba_solution_biomass_cho_prod,\n",
    "        })\n",
    "\n",
    "\n",
    "    # Convert the model_data list to a DataFrame and concatenate it with the main DataFrame\n",
    "    model_df = pd.DataFrame(model_data)\n",
    "    df = pd.concat([df, model_df], ignore_index=True)\n",
    "\n",
    "\n",
    "# Add the experimental growth rate values to the dataset\n",
    "exp_data = []\n",
    "\n",
    "for cond,dic in zip(conditions,dicts):\n",
    "    exp_gr = biomass_bounds[cond]['Experimental growth rate']\n",
    "\n",
    "    exp_data.append({\n",
    "            'Model': \"Exp\",\n",
    "            'Condition': cond,\n",
    "            'Biomass_CHO': exp_gr,\n",
    "            'Biomass_CHO_Prod': exp_gr,\n",
    "        })\n",
    "exp_df = pd.DataFrame(exp_data)\n",
    "df = pd.concat([df, exp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\") \n",
    "\n",
    "# Plotting for Biomass_CHO\n",
    "plt.figure(figsize=(12, 7))\n",
    "barplot_cho = sns.barplot(data=df, x=\"Condition\", y=\"Biomass_CHO\", hue=\"Model\", palette=\"viridis\")\n",
    "plt.title(\"Growth Rate Calculated with the Biomass CHO Reaction\")\n",
    "plt.ylabel(\"Growth Rate (hr-1)\")\n",
    "plt.xlabel(\"Condition\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Condition', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../Plots/bar_plot_growth_rate_biomass_cho.png')\n",
    "plt.show()\n",
    "\n",
    "# Plotting for Biomass_CHO_Prod\n",
    "plt.figure(figsize=(12, 7))\n",
    "barplot_cho_prod = sns.barplot(data=df, x=\"Condition\", y=\"Biomass_CHO_Prod\", hue=\"Model\", palette=\"viridis\")\n",
    "plt.title(\"Growth Rate Calculated with the Biomass CHO Prod Reaction\")\n",
    "plt.ylabel(\"Growth Rate (hr-1)\")\n",
    "plt.xlabel(\"Condition\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Condition', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../Plots/bar_plot_growth_rate_biomass_cho_prod.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Flux Enrichment Analysis <a id='fea'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1\n",
    "# Use the fluxes from the growth rate calculations to filter reactions with fluxes\n",
    "# Define a cut off for the flux ??? # Plot to visualization of the flux distribution\n",
    "# Run Flux Enrichment Analysis on those reactions to see pathways enriched when optimized by biomass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2\n",
    "# Transcriptomic data from cell batches / biorreactiors\n",
    "# Overlay this into the recons and extract the reactions associated to the genes\n",
    "# Extract a reaction vector / \n",
    "# Run Flux Enrichment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R1 = g1 or (g2 and G3)\n",
    "# r1 = max(r1, (min(g2, g3))\n",
    "# r1 = sum(r1, min(g2, g3))\n",
    "# GIMME \n",
    "# Use mCADRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import hypergeom\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "def flux_enrichment_analysis(model, rxn_indices, attribute='subsystem'):\n",
    "    # Ensure rxn_indices is a list of integers\n",
    "    if not isinstance(rxn_indices, list) or not all(isinstance(i, int) for i in rxn_indices):\n",
    "        raise ValueError('rxn_indices must be a list of integers')\n",
    "    \n",
    "    # Check if the attribute exists in the first reaction as a proxy for all\n",
    "    if not hasattr(model.reactions[0], attribute):\n",
    "        raise ValueError(f'Attribute {attribute} not found in model reactions')\n",
    "\n",
    "    # Extract attribute information for all reactions\n",
    "    attribute_values = [getattr(rxn, attribute, 'None') for rxn in model.reactions]\n",
    "    unique_attributes = set(attribute_values)\n",
    "    \n",
    "    # Count occurrences in the model and in the reaction set\n",
    "    model_counts = {attr: attribute_values.count(attr) for attr in unique_attributes}\n",
    "    rxn_set_counts = {attr: 0 for attr in unique_attributes}\n",
    "    for idx in rxn_indices:\n",
    "        rxn_attr = getattr(model.reactions[idx], attribute, 'None')\n",
    "        rxn_set_counts[rxn_attr] += 1\n",
    "\n",
    "    # Calculate p-values using hypergeometric test\n",
    "    M = len(model.reactions)  # Total number of reactions\n",
    "    n = len(rxn_indices)  # Size of reaction set\n",
    "    p_values = []\n",
    "    for attr in unique_attributes:\n",
    "        N = model_counts[attr]  # Total reactions in group\n",
    "        x = rxn_set_counts[attr]  # Reactions in group and in set\n",
    "        p_value = hypergeom.sf(x-1, M, N, n)\n",
    "        p_values.append(p_value)\n",
    "\n",
    "    # Adjust p-values for multiple testing\n",
    "    _, adj_p_values, _, _ = multipletests(p_values, method='fdr_bh')\n",
    "\n",
    "    # Compile results\n",
    "    results = pd.DataFrame({\n",
    "        'Group': list(unique_attributes),\n",
    "        'P-value': p_values,\n",
    "        'Adjusted P-value': adj_p_values,\n",
    "        'Enriched set size': [rxn_set_counts[attr] for attr in unique_attributes],\n",
    "        'Total set size': [model_counts[attr] for attr in unique_attributes],\n",
    "    }).sort_values(by='Adjusted P-value')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobra.io import load_json_model\n",
    "iCHO3000 = load_json_model('iCHOv3_CHO_05032024.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: FEA on reactions active during growth rate optimization\n",
    "Use the fluxes from the growth rate calculations to filter reactions with fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate a vector of active reactions for each one of the conditions\n",
    "\n",
    "active_reactions = []\n",
    "\n",
    "for sol in pfba_solutions_fluxes:\n",
    "    if sol['model_id'] == 'iCHO3644':\n",
    "        rxns_fluxes = []\n",
    "        for i,(r,f) in enumerate(sol['fluxes'].items()):\n",
    "            if f != 0:\n",
    "                rxns_fluxes.append(i)\n",
    "        \n",
    "        active_reactions.append({\n",
    "            \"model_id\": sol['model_id'],\n",
    "            \"condition\": sol['condition'],\n",
    "            \"flux_vector\": rxns_fluxes\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate FEA results for each one of the vectors generated for each condition\n",
    "\n",
    "fea_results = []\n",
    "\n",
    "for fluxes in active_reactions:\n",
    "    results = flux_enrichment_analysis(iCHO3000, fluxes['flux_vector'], 'subsystem')\n",
    "    fea_results.append({\n",
    "        \"Condition\": fluxes['condition'],\n",
    "        \"Results\": results\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform p-values to -log10\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for result in fea_results:\n",
    "    condition = result['Condition']\n",
    "    temp_df = result['Results'][['Group', 'P-value']].copy()\n",
    "    temp_df.columns = ['Group', f'P-value_{condition}']\n",
    "    if all_data.empty:\n",
    "        all_data = temp_df\n",
    "    else:\n",
    "        all_data = pd.merge(all_data, temp_df, on='Group', how='outer')\n",
    "\n",
    "# Remove groups with a 0 value in all conditions (assuming a '0' value indicates non-significance)\n",
    "significant_filter = (all_data.drop(columns='Group') < 0.05).any(axis=1)\n",
    "filtered_data = all_data[significant_filter]\n",
    "filtered_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Transform the p-values\n",
    "for col in filtered_data.columns:\n",
    "    if col.startswith('P-value'):\n",
    "        filtered_data[f'-log10({col})'] = -np.log10(filtered_data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert the data for plotting the yticks correctly\n",
    "filtered_data = filtered_data.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "# Adjusting the bar width and spacing\n",
    "bar_width = 0.11  # Decrease the bar width for more distinct separation\n",
    "spacing = 0  # Increase the spacing between bars of different conditions\n",
    "\n",
    "# Assuming 'filtered_data' is structured with 'Group' and transformed p-value columns\n",
    "# Example conditions derived from your DataFrame's columns\n",
    "conditions = [col.replace('-log10(P-value_', '').replace(')', '') for col in filtered_data if col.startswith('-log10')]\n",
    "conditions = conditions[::-1]\n",
    "\n",
    "# Define colors for each condition using a colormap\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(conditions)))\n",
    "\n",
    "# Figure setup\n",
    "fig_height = len(filtered_data['Group']) * (bar_width + spacing) * len(conditions)\n",
    "plt.figure(figsize=(25, fig_height))\n",
    "\n",
    "# Initial y positions for each group's first condition bar\n",
    "initial_pos = np.arange(len(filtered_data['Group']))\n",
    "\n",
    "# Plotting\n",
    "for i, condition in enumerate(conditions):\n",
    "    position = [p + (bar_width + spacing) * i for p in initial_pos]\n",
    "    plt.barh(position, filtered_data[f'-log10(P-value_{condition})'], height=bar_width, color=colors[i], label=condition)\n",
    "\n",
    "plt.tick_params(axis='y', labelsize=25)\n",
    "plt.tick_params(axis='x', labelsize=15)\n",
    "plt.yticks(initial_pos + (bar_width + spacing) * (len(conditions) - 1) / 2, filtered_data['Group'])\n",
    "plt.xlabel('-log10(P-value)', fontsize=30)\n",
    "plt.legend(title='Condition', bbox_to_anchor=(1.05, 1), fontsize=20, loc='upper left', reverse=True)\n",
    "\n",
    "# Manually adjust the y-axis limits if necessary\n",
    "plt.ylim(-0.5, len(filtered_data['Group']) - 0.5 + (bar_width + spacing) * len(conditions))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../Plots/FEA_biomass_prod_iCHO3000.png', format='png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
