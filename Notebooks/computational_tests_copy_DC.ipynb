{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Tests\n",
    "\n",
    "This notebook is intended for running different kinds of analyses that would validate our reconstruction.\n",
    "\n",
    "[1. Subsystem Overview and Analysis](#subsystems) <br>\n",
    "[2. Context-specific Model Generation](#context_specific) <br>\n",
    "[3. Biomass prediction using exp. data](#biomass) <br>\n",
    "[4. Flux Enrichment Analysis](#fea) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Subsystem Overview and Analysis <a id='subsystems'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from google_sheet import GoogleSheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- Generate Subsystems datasets from Google Sheet ----- #####\n",
    "\n",
    "#Credential file\n",
    "KEY_FILE_PATH = 'credentials.json'\n",
    "\n",
    "#CHO Network Reconstruction + Recon3D_v3 Google Sheet ID\n",
    "SPREADSHEET_ID = '1MlBXeHIKw8k8fZyXm-sN__AHTRSunJxar_-bqvukZws'\n",
    "\n",
    "# Initialize the GoogleSheet object\n",
    "sheet = GoogleSheet(SPREADSHEET_ID, KEY_FILE_PATH)\n",
    "\n",
    "# Read data from the Google Sheet\n",
    "sheet_subsystems = 'Summary Systems'\n",
    "sheet_reactions = 'Rxns'\n",
    "subsystems = sheet.read_google_sheet(sheet_subsystems)\n",
    "reactions_rec = sheet.read_google_sheet(sheet_reactions)\n",
    "\n",
    "# Remove the total count\n",
    "subsystems = subsystems.iloc[:-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### --- Pie Chart of the Amount of Reactions per System --- ####\n",
    "\n",
    "subsystems[\"Number of Reactions\"] = pd.to_numeric(subsystems[\"Number of Reactions\"])\n",
    "\n",
    "# Aggregate data by \"System\" and sum \"Number of Reactions\"\n",
    "system_reactions = subsystems.groupby(\"System\")[\"Number of Reactions\"].sum()\n",
    "\n",
    "# Set the figure and axes for more control\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Generate the pie chart again with the custom labels\n",
    "patches, texts, autotexts = ax.pie(system_reactions, labels=system_reactions.index, autopct=lambda p: '{:.1f}%'.format(p) if p > 0 else '', startangle=140, colors=plt.cm.tab20.colors)\n",
    "\n",
    "# Improve aesthetics\n",
    "for text in texts + autotexts:\n",
    "    text.set_color('black')\n",
    "ax.set_title(\"Pie Chart of Number of Reactions by System\", pad=30)  # Move the title upwards by increasing pad\n",
    "\n",
    "# Set equal aspect ratio\n",
    "ax.axis('equal')\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('../Plots/pie_chart_reactions_per_system.png')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Sunburst Plot\n",
    "\n",
    "fig = px.sunburst(subsystems, path=['System', 'Subsystems', 'Kegg Pathway'],\n",
    "                  color='System')\n",
    "\n",
    "# Convert to a Graph Objects figure\n",
    "fig_go = go.Figure(fig)\n",
    "\n",
    "# Update layout\n",
    "fig_go.update_layout(width=1200, height=1000)\n",
    "\n",
    "# Define font sizes\n",
    "font_size_last_layer = 10\n",
    "font_size_previous_layer = 15\n",
    "default_font_size = 12\n",
    "\n",
    "# Create a list to store font sizes\n",
    "font_sizes = []\n",
    "\n",
    "# Update font size for each level\n",
    "for trace in fig_go.data:\n",
    "    if isinstance(trace, go.Sunburst):\n",
    "        for id in trace.ids:\n",
    "            level = id.count(\"/\")  # Determine level by the number of slashes in the id\n",
    "            if level == 2:  # Last layer (Kegg Pathway)\n",
    "                font_sizes.append(font_size_last_layer)\n",
    "            elif level == 1:  # Previous layer (Subsystems)\n",
    "                font_sizes.append(font_size_previous_layer)\n",
    "            else:\n",
    "                font_sizes.append(default_font_size)  # Default size for other layers\n",
    "\n",
    "# Apply the font sizes to the figure\n",
    "fig_go.update_traces(insidetextfont=dict(size=font_sizes))\n",
    "\n",
    "# Save the figure\n",
    "fig_go.write_html(\"../Plots/sunburst_subsystems.html\")  # Save as interactive HTML file\n",
    "fig_go.write_image(\"../Plots/sunburst_subsystems.png\", width=1200, height=1000, scale=2)  # Increase resolution by setting scale parameter\n",
    "\n",
    "# Show the plot\n",
    "fig_go.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxotrophies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobra.io import load_json_model\n",
    "\n",
    "iCHO_path = \"iCHO3595.json\"\n",
    "iCHO = load_json_model(iCHO_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acids = {\n",
    "    \"arginine\": [\"EX_arg_L_e\", \"EX_arg_D_e\"],\n",
    "    \"asparagine\": [\"EX_asn_L_e\", \"EX_asn_D_e\"],\n",
    "    \"cysteine\": [\"EX_cys_L_e\", \"EX_cys_D_e\", \"EX_Lcystin_e\"],\n",
    "    \"histidine\": [\"EX_his_L_e\", \"EX_his_D_e\"],\n",
    "    \"isoleucine\": [\"EX_ile_L_e\", \"EX_ile_D_e\"],\n",
    "    \"leucine\": [\"EX_leu_L_e\", \"EX_leu_D_e\"],\n",
    "    \"lysine\": [\"EX_lys_L_e\", \"EX_lys_D_e\"],\n",
    "    \"methionine\": [\"EX_met_L_e\", \"EX_met_D_e\"],\n",
    "    \"phenylalanine\": [\"EX_phe_L_e\", \"EX_phe_D_e\"],\n",
    "    \"proline\": [\"EX_pro_L_e\", \"EX_pro_D_e\"],\n",
    "    \"threonine\": [\"EX_thr_L_e\", \"EX_thr_D_e\"],\n",
    "    \"tryptophan\": [\"EX_trp_L_e\", \"EX_trp_D_e\"],\n",
    "    \"valine\": [\"EX_val_L_e\", \"EX_val_D_e\"]\n",
    "}\n",
    "for amino_acid in amino_acids:\n",
    "    # ----- Setup initial bounds -----\n",
    "    for exchange_reaction in iCHO.exchanges:\n",
    "        exchange_reaction.bounds = -10, 10\n",
    "\n",
    "    # Arginine\n",
    "    iCHO.reactions.get_by_id('GAUGE-R00557').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('GAUGE-R10107').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('GAUGE-R00558').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('GLYAMDTRc').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('GAUGE-R10107').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('EX_valarggly_e').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('ARGSL').bounds = 0, 0\n",
    "\n",
    "    # Asparigine\n",
    "    iCHO.reactions.get_by_id('ASNS1').bounds = 0, 0\n",
    "\n",
    "    # Cysteine\n",
    "    iCHO.reactions.get_by_id('r0129').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('EX_cgly_e').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('AMPTASECG').bounds = -10, 0\n",
    "    iCHO.reactions.get_by_id('AMPTASECGe').bounds = -10, 0\n",
    "    iCHO.reactions.get_by_id('CYSTGL').bounds = -10, 0\n",
    "    iCHO.reactions.get_by_id('EX_HC00250_e').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('EX_sfcys_e').bounds = 0, 0\n",
    "\n",
    "    # Histidine\n",
    "    iCHO.reactions.get_by_id('VALTRPVALr').bounds = 0,0 \n",
    "\n",
    "    # Isoleucine - DONE\n",
    "    iCHO.reactions.get_by_id('EX_CE2916_e').bounds = 0,0 \n",
    "    iCHO.reactions.get_by_id('EX_CE2915_e').bounds = 0,0 \n",
    "    iCHO.reactions.get_by_id('ILETA').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('ILETAm').bounds = 0, 10\n",
    "\n",
    "    # Leucine\n",
    "    iCHO.reactions.get_by_id('LEULEULAPc').bounds = 0,0 \n",
    "    iCHO.reactions.get_by_id('EX_leugly_e').bounds = 0,0 \n",
    "    iCHO.reactions.get_by_id('EX_glyleu_e').bounds = 0,0 \n",
    "    iCHO.reactions.get_by_id('LEUTA').bounds = 0, 10 \n",
    "    iCHO.reactions.get_by_id('LEUTAm').bounds = 0, 10 \n",
    "    iCHO.reactions.get_by_id('EX_CE5797_e').bounds = 0, 0\n",
    "\n",
    "    # Lysine\n",
    "    iCHO.reactions.get_by_id('EX_biocyt_e').bounds = 0,0 \n",
    "\n",
    "    # Methionine\n",
    "    iCHO.reactions.get_by_id('METS').bounds = -10, 0 \n",
    "    iCHO.reactions.get_by_id('BHMT').bounds = -10, 0 \n",
    "    iCHO.reactions.get_by_id('GAUGE-R00648').bounds = 0, 10 \n",
    "    iCHO.reactions.get_by_id('UNK2').bounds = -10, 0 \n",
    "    iCHO.reactions.get_by_id('UNK3').bounds = -10, 0 \n",
    "    iCHO.reactions.get_by_id('TYRA').bounds = -10, 0 \n",
    "    #iCHO.reactions.get_by_id('GAUGE-R06895').bounds = 0, 0 # Curated by MR with 1 score / Erased from the reconstruction\n",
    "\n",
    "    # Phenylalanine\n",
    "    iCHO.reactions.get_by_id('EX_CE5786_e').bounds = 0, 0 \n",
    "    iCHO.reactions.get_by_id('EX_pheleu_e').bounds = 0, 0 \n",
    "    iCHO.reactions.get_by_id('EX_glyphe_e').bounds = 0, 0 \n",
    "    iCHO.reactions.get_by_id('EX_CE2917_e').bounds = 0, 0 \n",
    "    iCHO.reactions.get_by_id('EX_CE5786_e').bounds = 0, 0 \n",
    "    iCHO.reactions.get_by_id('EX_CE5789_e').bounds = 0, 0 \n",
    "    iCHO.reactions.get_by_id('EX_phpyr_e').bounds = 0, 0 \n",
    "\n",
    "    # Proline\n",
    "    iCHO.reactions.get_by_id('EX_glypro_e').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('EX_progly_e').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('P5CR').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('P5CRxm').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('P5CRx').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('P5CRm').bounds = 0, 0\n",
    "    iCHO.reactions.get_by_id('r1453').bounds = 0, 10\n",
    "\n",
    "    # Threonine\n",
    "    #iCHO.reactions.get_by_id('THRS').bounds = 0,0  # Erased from the reconstruction\n",
    "\n",
    "\n",
    "    # Tryptophan\n",
    "    iCHO.reactions.get_by_id('NBAHH_ir').bounds = 0,0  # Histidine hydrolase\n",
    "\n",
    "    # Valine\n",
    "    iCHO.reactions.get_by_id('EX_valarggly_e').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('EX_vallystyr_e').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('VALTA').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('VALTAm').bounds = 0, 10\n",
    "    iCHO.reactions.get_by_id('EX_valval_e').bounds = 0, 10\n",
    "    # -----------------------------------------\n",
    "\n",
    "    for exchange_reaction in iCHO.exchanges:\n",
    "        if exchange_reaction.id in amino_acids[amino_acid]:\n",
    "            exchange_reaction.bounds = 0, 10\n",
    "            # print(amino_acid, exchange_reaction.id, amino_acids[amino_acid])\n",
    "    sol = iCHO.optimize()\n",
    "    print(amino_acid, sol.objective_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iCHO.metabolites.leu_L_c.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gene Deletion test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from time import process_time\n",
    "import cobra\n",
    "from cobra.io import load_json_model, read_sbml_model\n",
    "\n",
    "\n",
    "model = load_json_model('iCHO3595_unblocked.json')\n",
    "#iCHO1766 = read_sbml_model('../Data/Reconciliation/models/iCHOv1_final.xml')\n",
    "# model = read_sbml_model('../Data/Reconciliation/models/iCHO2291.xml')\n",
    "#iCHO2441 = read_sbml_model('../Data/Reconciliation/models/iCHO2441.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset for the experimentally validated essential genes\n",
    "\n",
    "exp_essential_genes = pd.read_csv('../Data/Gene_Essentiality/cho_essential_genes.csv', sep='\\t')\n",
    "exp_essential_genes['gene'] = exp_essential_genes['gene'].str.replace('__1$', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all gene names\n",
    "all_gene_names = set()\n",
    "for names in exp_essential_genes['gene']:\n",
    "    for name in names.split('|'): #Extract the names of the genes with two aliases\n",
    "        all_gene_names.add(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          gene entrez_gene_id\n",
      "0          Ubc      100689267\n",
      "1       Ncaph2      100756862\n",
      "2        Huwe1      100757403\n",
      "3      Isg20l2      100752909\n",
      "4        Coq8b      100770066\n",
      "...        ...            ...\n",
      "1975     Sprtn      100764217\n",
      "1976     Perm1      100773289\n",
      "1977   Tmem147      100751744\n",
      "1978    Rnf216      100758416\n",
      "1979  Rnaseh2b      100751948\n",
      "\n",
      "[1980 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Generation gene ID of exp_essential_genes with biopython\n",
    "from Bio import Entrez\n",
    "import pandas as pd\n",
    "\n",
    "# Set your email (this is required by NCBI for accessing their services)\n",
    "Entrez.email = \"dh.choi@orcid\"\n",
    "\n",
    "# Your dataset with gene symbols (replace with actual dataframe)\n",
    "gene_symbols = exp_essential_genes.gene  # Example gene symbols\n",
    "\n",
    "# Function to fetch gene ID using Entrez API\n",
    "def get_gene_id(gene_symbol):\n",
    "    search_handle = Entrez.esearch(db=\"gene\", term=f\"{gene_symbol}[Gene] AND Cricetulus griseus[Organism]\")\n",
    "    record = Entrez.read(search_handle)\n",
    "    search_handle.close()\n",
    "    if record[\"IdList\"]:\n",
    "        return record[\"IdList\"][0]  # Return the first gene ID found\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create a DataFrame to store gene symbols and their corresponding gene IDs\n",
    "df = pd.DataFrame({'gene': gene_symbols})\n",
    "df['entrez_gene_id'] = df['gene'].apply(get_gene_id)\n",
    "\n",
    "# Display the result\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to a pickle file\n",
    "with open(\"gene_id_mapping.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "# Save the result to a CSV file as well, if needed\n",
    "df.to_csv(\"gene_id_mapping.csv\", index=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          gene entrez_gene_id\n",
      "0          Ubc      100689267\n",
      "1       Ncaph2      100756862\n",
      "2        Huwe1      100757403\n",
      "3      Isg20l2      100752909\n",
      "4        Coq8b      100770066\n",
      "...        ...            ...\n",
      "1975     Sprtn      100764217\n",
      "1976     Perm1      100773289\n",
      "1977   Tmem147      100751744\n",
      "1978    Rnf216      100758416\n",
      "1979  Rnaseh2b      100751948\n",
      "\n",
      "[1980 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the DataFrame from the pickle file\n",
    "with open(\"gene_id_mapping.pkl\", \"rb\") as f:\n",
    "    df_loaded = pickle.load(f)\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(df_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load uptake and secretion rate \"Intervals dict\n",
    "\n",
    "with open('../Data/Uptake_Secretion_Rates/uptake_secretion_intrvl_wt_dict.pkl', 'rb') as file:\n",
    "    uptsec_intrvl_wt = pickle.load(file)\n",
    "\n",
    "with open('../Data/Uptake_Secretion_Rates/uptake_secretion_intrvl_zela_dict.pkl', 'rb') as file:\n",
    "    uptsec_intrvl_zela = pickle.load(file)\n",
    "    \n",
    "temp_dict_zela = uptsec_intrvl_zela\n",
    "temp_dict_wt = uptsec_intrvl_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GM = model\n",
    "# Constraint the model with exp data\n",
    "\n",
    "time = 'P2 to P4'\n",
    "\n",
    "GM.solver = 'gurobi'\n",
    "objective = 'biomass_cho_s' # 'biomass_cho'\n",
    "GM.objective = objective\n",
    "\n",
    "GM.reactions.biomass_cho_s.bounds = temp_dict['exp_growth_rate'][time]\n",
    "for rxn in GM.boundary:\n",
    "    \n",
    "    # Models that are forced to secrete ethanol are not feasible\n",
    "    if rxn.id == 'EX_etoh_e':\n",
    "        rxn.bounds = (-0.1,0.1)\n",
    "        continue\n",
    "\n",
    "    # Replace the lower and upper bound with experimental data\n",
    "    if rxn.id in temp_dict.keys():\n",
    "        rxn.bounds = temp_dict[rxn.id][time]\n",
    "        continue\n",
    "    \n",
    "    # Keep boundaries open for essential metabolites\n",
    "    if rxn.id == 'EX_h2o_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "    if rxn.id == 'EX_h_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "    if rxn.id == 'EX_o2_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "    if rxn.id == 'EX_hco3_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "    if rxn.id == 'EX_so4_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "    if rxn.id == 'EX_pi_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "\n",
    "    # Boundaries from Sink reactions on iCHO_v1 (100 times lower)\n",
    "    if rxn.id == 'SK_Asn_X_Ser_Thr_r':\n",
    "        rxn.bounds = (-0.001,1000)\n",
    "        continue\n",
    "    if rxn.id == 'SK_Tyr_ggn_c':\n",
    "        rxn.bounds = (-0.001,1000)\n",
    "        continue\n",
    "    if rxn.id == 'SK_Ser_Thr_g':\n",
    "        rxn.bounds = (-0.001,1000)\n",
    "        continue\n",
    "    if rxn.id == 'SK_pre_prot_r':\n",
    "        rxn.bounds = (-0.0006,1000)\n",
    "        continue\n",
    "\n",
    "    # Close uptake rates for the rest of the boundaries\n",
    "    if rxn.id.startswith(\"EX_\"):\n",
    "        rxn.bounds = (0,1000) \n",
    "    if rxn.id.startswith(\"SK_\"):\n",
    "        rxn.bounds = (0,1000)\n",
    "    if rxn.id.startswith(\"DM_\"):\n",
    "        rxn.bounds = (0,1000)\n",
    "    \n",
    "pfba_solution = cobra.flux_analysis.pfba(GM)\n",
    "pfba_obj = pfba_solution.fluxes[objective]\n",
    "print(pfba_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpa99zyb14.lp\n",
      "Reading time = 0.09 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp_155ozdx.lp\n",
      "Reading time = 0.06 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpzhgt__no.lp\n",
      "Reading time = 0.18 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpoicxbk69.lp\n",
      "Reading time = 0.11 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp1uhd22s0.lp\n",
      "Reading time = 0.12 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpt1w0lora.lp\n",
      "Reading time = 0.08 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpnwwm9x6y.lp\n",
      "Reading time = 0.10 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Number of essential genes for biomass: 0\n",
      "Essential genes for biomass production:\n",
      "Essential genes for biomass production with matching Entrez Gene IDs:\n"
     ]
    }
   ],
   "source": [
    "from cobra.flux_analysis.variability import find_essential_genes\n",
    "\n",
    "# Find the essential genes for the given model\n",
    "essential_genes = find_essential_genes(model)\n",
    "\n",
    "# Print the number of essential genes for biomass\n",
    "print(f\"Number of essential genes for biomass: {len(essential_genes)}\")\n",
    "print(\"Essential genes for biomass production:\")\n",
    "\n",
    "# Iterate over the essential genes and print them (essential_genes is a set)\n",
    "for gene in essential_genes:\n",
    "    print(f\"{gene.id}: {gene.name}\")\n",
    "\n",
    "# Create a reverse lookup dictionary where the key is the Entrez Gene ID and the value is the gene symbol\n",
    "entrez_dict = df.set_index('entrez_gene_id')['gene'].to_dict()\n",
    "\n",
    "# Now, match essential genes with Entrez Gene IDs and print the results\n",
    "print(\"Essential genes for biomass production with matching Entrez Gene IDs:\")\n",
    "\n",
    "# Iterate over the essential genes and match them with Entrez Gene IDs\n",
    "for gene in essential_genes:\n",
    "    # Check if the gene.name matches any Entrez Gene ID in the dictionary\n",
    "    entrez_id = entrez_dict.get(gene.name, \"No Match\")  # You can also try gene.id if it's closer to Entrez IDs\n",
    "    \n",
    "    # Print the gene along with its corresponding Entrez Gene ID (if matched)\n",
    "    print(f\"{gene.id}: {gene.name}, Entrez Gene ID: {entrez_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the results\n",
    "matched_genes = []\n",
    "\n",
    "# Iterate over the essential genes\n",
    "for gene in essential_genes:\n",
    "    gene_exp_ess = model.genes.get_by_id(gene.id)  # Get the gene from the model\n",
    "\n",
    "    # Check if the gene.id matches any Entrez Gene ID in the reverse dictionary\n",
    "    if gene_exp_ess.id in entrez_dict:\n",
    "        # If it matches, retrieve the corresponding gene symbol\n",
    "        entrez_gene_symbol = entrez_dict[gene_exp_ess.id]\n",
    "        print(f\"{gene_exp_ess.id}: {gene_exp_ess.name}, Entrez Gene Symbol: {entrez_gene_symbol}\")\n",
    "\n",
    "        # Append the matched result to the list\n",
    "        matched_genes.append((gene_exp_ess.id, gene_exp_ess.name, entrez_gene_symbol))\n",
    "    else:\n",
    "        print(f\"{gene_exp_ess.id}: {gene_exp_ess.name}, No Entrez Gene Match\")\n",
    "\n",
    "# Convert the matched list into a DataFrame if needed\n",
    "matched_genes_essential_df = pd.DataFrame(matched_genes, columns=['gene_exp_ess.id', 'gene_exp_ess.name', 'entrez_gene_symbol'])\n",
    "\n",
    "# Save the result to a CSV file\n",
    "matched_genes_essential_df.to_csv(\"matched_gene_entrez_ids_feg.csv\", index=False)\n",
    "\n",
    "# Optional: Print the DataFrame\n",
    "print(matched_genes_essential_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows where entrez_gene_id is None (indicating no match was found)\n",
    "no_match_df = df_loaded[df_loaded['entrez_gene_id'].isnull()]\n",
    "len(no_match_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matched_genes_essential_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterating Condition-Specific Constraints and Identifyng Matched Essential Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from time import process_time\n",
    "import cobra\n",
    "from cobra.io import load_json_model, read_sbml_model\n",
    "from cobra.flux_analysis.variability import find_essential_genes\n",
    "\n",
    "model = load_json_model('iCHO3595_unblocked.json')\n",
    "#iCHO1766 = read_sbml_model('../Data/Reconciliation/models/iCHOv1_final.xml')\n",
    "#iCHO2291 = read_sbml_model('../Data/Reconciliation/models/iCHO2291.xml')\n",
    "#iCHO2441 = read_sbml_model('../Data/Reconciliation/models/iCHO2441.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset for the experimentally validated essential genes\n",
    "\n",
    "exp_essential_genes = pd.read_csv('../Data/Gene_Essentiality/cho_essential_genes.csv', sep='\\t')\n",
    "exp_essential_genes['gene'] = exp_essential_genes['gene'].str.replace('__1$', '', regex=True)\n",
    "# Extract all gene names\n",
    "all_gene_names = set()\n",
    "for names in exp_essential_genes['gene']:\n",
    "    for name in names.split('|'): #Extract the names of the genes with two aliases\n",
    "        all_gene_names.add(name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame from the pickle file\n",
    "with open(\"gene_id_mapping.pkl\", \"rb\") as f:\n",
    "    df_loaded = pickle.load(f)\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(df_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load uptake and secretion rate \"Intervals dict\n",
    "\n",
    "with open('../Data/Uptake_Secretion_Rates/uptake_secretion_intrvl_wt_dict.pkl', 'rb') as file:\n",
    "    uptsec_intrvl_wt = pickle.load(file)\n",
    "\n",
    "with open('../Data/Uptake_Secretion_Rates/uptake_secretion_intrvl_zela_dict.pkl', 'rb') as file:\n",
    "    uptsec_intrvl_zela = pickle.load(file)\n",
    "    \n",
    "temp_dict_zela = uptsec_intrvl_zela\n",
    "temp_dict_wt = uptsec_intrvl_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constraint_model_feg(model, time, exp_dict, objective=None, solver=None):\n",
    "    \"\"\"\n",
    "    Constrain the model with experimental data and calculate the objective function value using pFBA.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: COBRA model to be constrained.\n",
    "    - time: Time interval for applying the experimental constraints. Default is 'P2 to P4'.\n",
    "    - objective: The objective reaction. Default is 'biomass_cho_s'.\n",
    "    - solver: Solver to be used. Default is 'gurobi'.\n",
    "    \n",
    "    Returns:\n",
    "    - pfba_obj: The optimized objective function value (growth rate or other objective).\n",
    "    - pfba_solution: The full pFBA solution (flux distribution).\n",
    "    \"\"\"\n",
    "    \n",
    "    GM = model.copy()  # Copy the model to avoid modifying the original\n",
    "    temp_dict = exp_dict\n",
    "    \n",
    "    # Default values if no argument is provided\n",
    "    if objective is None:\n",
    "        objective = 'biomass_cho_s'\n",
    "    if solver is None:\n",
    "        solver = 'gurobi'\n",
    "\n",
    "    # Set the solver and the objective reaction\n",
    "    GM.solver = solver\n",
    "    GM.objective = objective\n",
    "\n",
    "    # Constraint the model with experimental data\n",
    "    GM.reactions.biomass_cho_s.bounds = temp_dict['exp_growth_rate'][time]\n",
    "    \n",
    "    for rxn in GM.boundary:\n",
    "        # Models that are forced to secrete ethanol are not feasible\n",
    "        if rxn.id == 'EX_etoh_e':\n",
    "            rxn.bounds = (-0.1,0.1)\n",
    "            continue\n",
    "\n",
    "        # Replace the lower and upper bound with experimental data\n",
    "        if rxn.id in temp_dict.keys():\n",
    "            rxn.bounds = temp_dict[rxn.id][time]\n",
    "            continue\n",
    "\n",
    "        # Keep boundaries open for essential metabolites\n",
    "        if rxn.id == 'EX_h2o_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "        if rxn.id == 'EX_h_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "        if rxn.id == 'EX_o2_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "        if rxn.id == 'EX_hco3_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "        if rxn.id == 'EX_so4_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "        if rxn.id == 'EX_pi_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "\n",
    "        # Boundaries from Sink reactions on iCHO_v1\n",
    "        if rxn.id == 'SK_Asn_X_Ser_Thr_r':\n",
    "            rxn.bounds = (-0.1,1000)\n",
    "            continue\n",
    "        if rxn.id == 'SK_Tyr_ggn_c':\n",
    "            rxn.bounds = (-0.1,1000)\n",
    "            continue\n",
    "        if rxn.id == 'SK_Ser_Thr_g':\n",
    "            rxn.bounds = (-0.1,1000)\n",
    "            continue\n",
    "        if rxn.id == 'SK_pre_prot_r':\n",
    "            rxn.bounds = (-0.1,1000)\n",
    "            continue\n",
    "\n",
    "        # Close uptake rates for the rest of the boundaries\n",
    "        if rxn.id.startswith(\"EX_\"):\n",
    "            rxn.bounds = (0,1000) \n",
    "        if rxn.id.startswith(\"SK_\"):\n",
    "            rxn.bounds = (0,1000)\n",
    "        if rxn.id.startswith(\"DM_\"):\n",
    "            rxn.bounds = (0,1000)\n",
    "\n",
    "    # Perform pFBA (parsimonious FBA) to minimize the total flux\n",
    "    pfba_solution = cobra.flux_analysis.pfba(GM)\n",
    "    pfba_obj = pfba_solution.fluxes[objective]\n",
    "\n",
    "    # Print and return the objective value and the full pFBA solution\n",
    "    print(f\"Optimized objective (growth rate): {pfba_obj}\")\n",
    "    \n",
    "    # Return the objective value and the full pFBA solution\n",
    "    return GM, pfba_obj, pfba_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_match_essential_genes(model, df_exp_essential, save_csv=True, print_df=False):\n",
    "\n",
    "    # Check if the necessary columns 'entrez_gene_id' and 'gene' exist in the dataframe\n",
    "    required_columns = ['entrez_gene_id', 'gene']\n",
    "    for col in required_columns:\n",
    "        if col not in df_exp_essential.columns:\n",
    "            raise KeyError(f\"Column '{col}' is missing from the dataframe.\")\n",
    "\n",
    "    # Create a reverse lookup dictionary where the key is the Entrez Gene ID and the value is the gene symbol\n",
    "    entrez_dict = df_exp_essential.set_index('entrez_gene_id')['gene'].to_dict()\n",
    "\n",
    "    # Find the essential genes for the given model\n",
    "    essential_genes = find_essential_genes(model)\n",
    "    \n",
    "    # Create an empty list to store the results\n",
    "    matched_genes = []\n",
    "\n",
    "    # Iterate over the essential genes\n",
    "    for gene in essential_genes:\n",
    "        gene_exp_ess = model.genes.get_by_id(gene.id)  # Get the gene from the model\n",
    "\n",
    "        # Check if the gene.id matches any Entrez Gene ID in the reverse dictionary\n",
    "        if gene_exp_ess.id in entrez_dict:\n",
    "            # If it matches, retrieve the corresponding gene symbol\n",
    "            entrez_gene_symbol = entrez_dict[gene_exp_ess.id]\n",
    "#             print(f\"{gene_exp_ess.id}: {gene_exp_ess.name}, Entrez Gene Symbol: {entrez_gene_symbol}\")\n",
    "\n",
    "            # Append the matched result to the list\n",
    "            matched_genes.append((gene_exp_ess.id, gene_exp_ess.name, entrez_gene_symbol))\n",
    "#         else:\n",
    "#             print(f\"{gene_exp_ess.id}: {gene_exp_ess.name}, No Entrez Gene Match\")\n",
    "\n",
    "    # Convert the matched list into a DataFrame\n",
    "    matched_genes_essential_df = pd.DataFrame(matched_genes, columns=['gene_exp_ess.id', 'gene_exp_ess.name', 'entrez_gene_symbol'])\n",
    "\n",
    "    # Save the result to a CSV file if save_csv is True\n",
    "    if save_csv:\n",
    "        matched_genes_essential_df.to_csv(\"matched_gene_entrez_ids_feg.csv\", index=False)\n",
    "\n",
    "    # Print the DataFrame if print_df is True\n",
    "    if print_df:\n",
    "        print(matched_genes_essential_df)\n",
    "\n",
    "    # Return the matched DataFrame\n",
    "    return matched_genes_essential_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpj37tgtz4.lp\n",
      "Reading time = 0.06 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Optimized objective (growth rate): 0.03725896271642408\n"
     ]
    }
   ],
   "source": [
    "GM_constrained, _, _ = constraint_model_feg(model, time='P2 to P4', exp_dict=temp_dict_zela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp52yx3t_z.lp\n",
      "Reading time = 0.06 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpoeg9nwpz.lp\n",
      "Reading time = 0.06 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpprb_uy5g.lp\n",
      "Reading time = 0.07 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpo4eyvrdv.lp\n",
      "Reading time = 0.12 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpgd4mie_m.lp\n",
      "Reading time = 0.16 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpf3z8je4x.lp\n",
      "Reading time = 0.16 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpydx3fa_g.lp\n",
      "Reading time = 0.15 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "100757066: Poli, No Entrez Gene Match\n",
      "100769107: Poln, No Entrez Gene Match\n",
      "100758378: Mybbp1a, No Entrez Gene Match\n",
      "100758493: Pola1, Entrez Gene Symbol: Pola1\n",
      "103163165: LOC103163165, No Entrez Gene Match\n",
      "100762233: Polm, No Entrez Gene Match\n",
      "100762815: Pold2, Entrez Gene Symbol: Pold2\n",
      "100761682: Pold4, No Entrez Gene Match\n",
      "100760867: Tent4a, No Entrez Gene Match\n",
      "100754280: Pole2, No Entrez Gene Match\n",
      "100774890: Rev3l, Entrez Gene Symbol: Rev3l\n",
      "100751096: Poll, Entrez Gene Symbol: Poll\n",
      "100774930: Mthfr, No Entrez Gene Match\n",
      "100774291: Polg2, No Entrez Gene Match\n",
      "100773935: Pold1, Entrez Gene Symbol: Pold1\n",
      "100755501: Polg, No Entrez Gene Match\n",
      "100753174: Rfc5, Entrez Gene Symbol: Rfc5\n",
      "100756090: Pold3, Entrez Gene Symbol: Pold3\n",
      "100774671: Pole, Entrez Gene Symbol: Pole\n",
      "100768307: Pola2, Entrez Gene Symbol: Pola2\n",
      "100764158: Polq, No Entrez Gene Match\n",
      "100752018: Pole3, No Entrez Gene Match\n",
      "100758244: Polh, No Entrez Gene Match\n",
      "100758099: Polk, No Entrez Gene Match\n",
      "100774965: Polb, No Entrez Gene Match\n",
      "100763640: Ptpmt1, Entrez Gene Symbol: Ptpmt1\n",
      "100763004: Eif3g, Entrez Gene Symbol: Eif3g\n",
      "100689060: Adsl, Entrez Gene Symbol: Adsl\n",
      "100769654: Eif4ebp1, No Entrez Gene Match\n",
      "100770352: Eif4h, No Entrez Gene Match\n",
      "100758911: Eif4b, No Entrez Gene Match\n",
      "100753359: Eif3l, Entrez Gene Symbol: Eif3l\n",
      "100769028: Eif3f, Entrez Gene Symbol: Eif3f\n",
      "100689446: Gart, Entrez Gene Symbol: Gart\n",
      "100689310: Eef1e1, Entrez Gene Symbol: Eef1e1\n",
      "100755894: Eef1d, No Entrez Gene Match\n",
      "100689051: Eef2, Entrez Gene Symbol: Eef2\n",
      "100766778: Eif4e1b, No Entrez Gene Match\n",
      "100753925: Eef1b2, No Entrez Gene Match\n",
      "100752954: Eif4ebp3, No Entrez Gene Match\n",
      "100753124: Acacb, No Entrez Gene Match\n",
      "100762904: Acaca, Entrez Gene Symbol: Acaca\n",
      "100771190: Eif3e, Entrez Gene Symbol: Eif3e\n",
      "100753545: Eef1g, Entrez Gene Symbol: Eef1g\n",
      "100766600: Eif3k, Entrez Gene Symbol: Eif3k\n",
      "100762979: Eif3b, Entrez Gene Symbol: Eif3b\n",
      "100759947: Eif4e3, No Entrez Gene Match\n",
      "100768213: Eif3m, Entrez Gene Symbol: Eif3m\n",
      "100764716: Eif4e2, No Entrez Gene Match\n",
      "100773768: Eif4e, No Entrez Gene Match\n",
      "100753319: Eif3i, Entrez Gene Symbol: Eif3i\n",
      "100774340: Bdh1, No Entrez Gene Match\n",
      "100768613: Eif4ebp2, No Entrez Gene Match\n",
      "100752118: Eif3a, Entrez Gene Symbol: Eif3a\n",
      "100751998: Eif3h, Entrez Gene Symbol: Eif3h\n",
      "100756126: Gmps, Entrez Gene Symbol: Gmps\n",
      "100767580: Hsd17b7, Entrez Gene Symbol: Hsd17b7\n",
      "100756809: Agps, Entrez Gene Symbol: Agps\n",
      "100766541: Mvd, Entrez Gene Symbol: Mvd\n",
      "100765639: Ebp, Entrez Gene Symbol: Ebp\n",
      "100773070: Cept1, Entrez Gene Symbol: Cept1\n",
      "100774679: Ggct, No Entrez Gene Match\n",
      "100756363: Hmgcr, Entrez Gene Symbol: Hmgcr\n",
      "100689449: Pgs1, Entrez Gene Symbol: Pgs1\n",
      "100754434: Asrgl1, No Entrez Gene Match\n",
      "100753498: Lss, Entrez Gene Symbol: Lss\n",
      "100762838: Got2, No Entrez Gene Match\n",
      "100751653: Mvk, Entrez Gene Symbol: Mvk\n",
      "100759992: Pmvk, Entrez Gene Symbol: Pmvk\n",
      "100689192: Fdft1, Entrez Gene Symbol: Fdft1\n",
      "100764994: Aldh4a1, No Entrez Gene Match\n",
      "100764834: Sqle, Entrez Gene Symbol: Sqle\n",
      "100765024: Gnpat, Entrez Gene Symbol: Gnpat\n",
      "100767831: Isyna1, No Entrez Gene Match\n",
      "100759109: Hoga1, No Entrez Gene Match\n",
      "100774578: Kdsr, Entrez Gene Symbol: Kdsr\n",
      "100750895: Atic, Entrez Gene Symbol: Atic\n",
      "100689093: Pisd, Entrez Gene Symbol: Pisd\n",
      "100758991: Paics, Entrez Gene Symbol: Paics\n",
      "100760149: Ppat, Entrez Gene Symbol: Ppat\n",
      "100760956: Pfas, Entrez Gene Symbol: Pfas\n",
      "100689232: Cad, Entrez Gene Symbol: Cad\n",
      "100689326: Sptlc1, Entrez Gene Symbol: Sptlc1\n",
      "100756632: Dhodh, Entrez Gene Symbol: Dhodh\n",
      "100751671: Gyg1, No Entrez Gene Match\n",
      "100772279: Gbe1, No Entrez Gene Match\n",
      "100763416: Mtr, Entrez Gene Symbol: Mtr\n",
      "100758206: Agpat1, No Entrez Gene Match\n",
      "100756786: Umps, Entrez Gene Symbol: Umps\n",
      "100761591: Rrm1, Entrez Gene Symbol: Rrm1\n",
      "   gene_exp_ess.id gene_exp_ess.name entrez_gene_symbol\n",
      "0        100758493             Pola1              Pola1\n",
      "1        100762815             Pold2              Pold2\n",
      "2        100774890             Rev3l              Rev3l\n",
      "3        100751096              Poll               Poll\n",
      "4        100773935             Pold1              Pold1\n",
      "5        100753174              Rfc5               Rfc5\n",
      "6        100756090             Pold3              Pold3\n",
      "7        100774671              Pole               Pole\n",
      "8        100768307             Pola2              Pola2\n",
      "9        100763640            Ptpmt1             Ptpmt1\n",
      "10       100763004             Eif3g              Eif3g\n",
      "11       100689060              Adsl               Adsl\n",
      "12       100753359             Eif3l              Eif3l\n",
      "13       100769028             Eif3f              Eif3f\n",
      "14       100689446              Gart               Gart\n",
      "15       100689310            Eef1e1             Eef1e1\n",
      "16       100689051              Eef2               Eef2\n",
      "17       100762904             Acaca              Acaca\n",
      "18       100771190             Eif3e              Eif3e\n",
      "19       100753545             Eef1g              Eef1g\n",
      "20       100766600             Eif3k              Eif3k\n",
      "21       100762979             Eif3b              Eif3b\n",
      "22       100768213             Eif3m              Eif3m\n",
      "23       100753319             Eif3i              Eif3i\n",
      "24       100752118             Eif3a              Eif3a\n",
      "25       100751998             Eif3h              Eif3h\n",
      "26       100756126              Gmps               Gmps\n",
      "27       100767580           Hsd17b7            Hsd17b7\n",
      "28       100756809              Agps               Agps\n",
      "29       100766541               Mvd                Mvd\n",
      "30       100765639               Ebp                Ebp\n",
      "31       100773070             Cept1              Cept1\n",
      "32       100756363             Hmgcr              Hmgcr\n",
      "33       100689449              Pgs1               Pgs1\n",
      "34       100753498               Lss                Lss\n",
      "35       100751653               Mvk                Mvk\n",
      "36       100759992              Pmvk               Pmvk\n",
      "37       100689192             Fdft1              Fdft1\n",
      "38       100764834              Sqle               Sqle\n",
      "39       100765024             Gnpat              Gnpat\n",
      "40       100774578              Kdsr               Kdsr\n",
      "41       100750895              Atic               Atic\n",
      "42       100689093              Pisd               Pisd\n",
      "43       100758991             Paics              Paics\n",
      "44       100760149              Ppat               Ppat\n",
      "45       100760956              Pfas               Pfas\n",
      "46       100689232               Cad                Cad\n",
      "47       100689326            Sptlc1             Sptlc1\n",
      "48       100756632             Dhodh              Dhodh\n",
      "49       100763416               Mtr                Mtr\n",
      "50       100756786              Umps               Umps\n",
      "51       100761591              Rrm1               Rrm1\n"
     ]
    }
   ],
   "source": [
    "matched_df = find_and_match_essential_genes(GM_constrained, df_loaded, save_csv=False, print_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time point: Zela P0 to P2\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp5km55rlx.lp\n",
      "Reading time = 0.08 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Optimized objective (growth rate): 0.03774957566811849\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp5suq2_o6.lp\n",
      "Reading time = 0.07 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpvhyr1n7w.lp\n",
      "Reading time = 0.06 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpi5ab3640.lp\n",
      "Reading time = 0.06 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpiwtvzo2w.lp\n",
      "Reading time = 0.07 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp0fgr_j5o.lp\n",
      "Reading time = 0.08 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpp0iqft8e.lp\n",
      "Reading time = 0.08 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp3k6k8dpz.lp\n",
      "Reading time = 0.10 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "   gene_exp_ess.id gene_exp_ess.name entrez_gene_symbol\n",
      "0        100689446              Gart               Gart\n",
      "1        100762904             Acaca              Acaca\n",
      "2        100689093              Pisd               Pisd\n",
      "3        100756126              Gmps               Gmps\n",
      "4        100767580           Hsd17b7            Hsd17b7\n",
      "5        100756809              Agps               Agps\n",
      "6        100766541               Mvd                Mvd\n",
      "7        100773070             Cept1              Cept1\n",
      "8        100765639               Ebp                Ebp\n",
      "9        100756363             Hmgcr              Hmgcr\n",
      "10       100689449              Pgs1               Pgs1\n",
      "11       100753498               Lss                Lss\n",
      "12       100762189      LOC100762189       LOC100762189\n",
      "13       100759992              Pmvk               Pmvk\n",
      "14       100689192             Fdft1              Fdft1\n",
      "15       100764834              Sqle               Sqle\n",
      "16       100765024             Gnpat              Gnpat\n",
      "17       100689310            Eef1e1             Eef1e1\n",
      "18       100689051              Eef2               Eef2\n",
      "19       100771190             Eif3e              Eif3e\n",
      "20       100753545             Eef1g              Eef1g\n",
      "21       100766600             Eif3k              Eif3k\n",
      "22       100762979             Eif3b              Eif3b\n",
      "23       100750895              Atic               Atic\n",
      "24       100768213             Eif3m              Eif3m\n",
      "25       100758991             Paics              Paics\n",
      "26       100760149              Ppat               Ppat\n",
      "27       100753319             Eif3i              Eif3i\n",
      "28       100760956              Pfas               Pfas\n",
      "29       100752118             Eif3a              Eif3a\n",
      "30       100689232               Cad                Cad\n",
      "31       100689326            Sptlc1             Sptlc1\n",
      "32       100751998             Eif3h              Eif3h\n",
      "33       100756632             Dhodh              Dhodh\n",
      "34       100756786              Umps               Umps\n",
      "35       100761591              Rrm1               Rrm1\n",
      "36       100758493             Pola1              Pola1\n",
      "37       100762815             Pold2              Pold2\n",
      "38       100774890             Rev3l              Rev3l\n",
      "39       100751096              Poll               Poll\n",
      "40       100773935             Pold1              Pold1\n",
      "41       100753174              Rfc5               Rfc5\n",
      "42       100756090             Pold3              Pold3\n",
      "43       100774671              Pole               Pole\n",
      "44       100768307             Pola2              Pola2\n",
      "45       100763640            Ptpmt1             Ptpmt1\n",
      "46       100763004             Eif3g              Eif3g\n",
      "47       100689060              Adsl               Adsl\n",
      "48       100774578              Kdsr               Kdsr\n",
      "49       100753359             Eif3l              Eif3l\n",
      "50       100769028             Eif3f              Eif3f\n",
      "Processing time point: Zela P2 to P4\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpnmxit26k.lp\n",
      "Reading time = 0.06 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Optimized objective (growth rate): 0.03725896271642408\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmphpkoskqe.lp\n",
      "Reading time = 0.05 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpodph57ql.lp\n",
      "Reading time = 0.06 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpu70mvpcs.lp\n",
      "Reading time = 0.13 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp57_emvn9.lp\n",
      "Reading time = 0.11 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmphypctl43.lp\n",
      "Reading time = 0.13 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp76w1buy0.lp\n",
      "Reading time = 0.10 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmptaksoz0n.lp\n",
      "Reading time = 0.09 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "   gene_exp_ess.id gene_exp_ess.name entrez_gene_symbol\n",
      "0        100753545             Eef1g              Eef1g\n",
      "1        100766600             Eif3k              Eif3k\n",
      "2        100762979             Eif3b              Eif3b\n",
      "3        100768213             Eif3m              Eif3m\n",
      "4        100753319             Eif3i              Eif3i\n",
      "5        100689093              Pisd               Pisd\n",
      "6        100752118             Eif3a              Eif3a\n",
      "7        100751998             Eif3h              Eif3h\n",
      "8        100761591              Rrm1               Rrm1\n",
      "9        100689060              Adsl               Adsl\n",
      "10       100762904             Acaca              Acaca\n",
      "11       100750895              Atic               Atic\n",
      "12       100758991             Paics              Paics\n",
      "13       100760149              Ppat               Ppat\n",
      "14       100756126              Gmps               Gmps\n",
      "15       100760956              Pfas               Pfas\n",
      "16       100689232               Cad                Cad\n",
      "17       100689326            Sptlc1             Sptlc1\n",
      "18       100756632             Dhodh              Dhodh\n",
      "19       100767580           Hsd17b7            Hsd17b7\n",
      "20       100763416               Mtr                Mtr\n",
      "21       100756809              Agps               Agps\n",
      "22       100756786              Umps               Umps\n",
      "23       100766541               Mvd                Mvd\n",
      "24       100765639               Ebp                Ebp\n",
      "25       100773070             Cept1              Cept1\n",
      "26       100756363             Hmgcr              Hmgcr\n",
      "27       100689449              Pgs1               Pgs1\n",
      "28       100753498               Lss                Lss\n",
      "29       100758493             Pola1              Pola1\n",
      "30       100762815             Pold2              Pold2\n",
      "31       100751653               Mvk                Mvk\n",
      "32       100759992              Pmvk               Pmvk\n",
      "33       100689192             Fdft1              Fdft1\n",
      "34       100764834              Sqle               Sqle\n",
      "35       100774890             Rev3l              Rev3l\n",
      "36       100751096              Poll               Poll\n",
      "37       100773935             Pold1              Pold1\n",
      "38       100765024             Gnpat              Gnpat\n",
      "39       100753174              Rfc5               Rfc5\n",
      "40       100756090             Pold3              Pold3\n",
      "41       100774671              Pole               Pole\n",
      "42       100768307             Pola2              Pola2\n",
      "43       100763640            Ptpmt1             Ptpmt1\n",
      "44       100763004             Eif3g              Eif3g\n",
      "45       100753359             Eif3l              Eif3l\n",
      "46       100769028             Eif3f              Eif3f\n",
      "47       100774578              Kdsr               Kdsr\n",
      "48       100689446              Gart               Gart\n",
      "49       100689310            Eef1e1             Eef1e1\n",
      "50       100689051              Eef2               Eef2\n",
      "51       100771190             Eif3e              Eif3e\n",
      "Processing time point: Zela P4 to P6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpun3lo3iz.lp\n",
      "Reading time = 0.05 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Optimized objective (growth rate): 0.018563977057166503\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpha4_jpks.lp\n",
      "Reading time = 0.07 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpayeoy53m.lp\n",
      "Reading time = 0.06 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpp1mbbvyv.lp\n",
      "Reading time = 0.06 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpfqsbyfx5.lp\n",
      "Reading time = 0.08 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpj8_40hnf.lp\n",
      "Reading time = 0.08 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp99czuc2y.lp\n",
      "Reading time = 0.10 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpxyf68iph.lp\n",
      "Reading time = 0.08 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "   gene_exp_ess.id gene_exp_ess.name entrez_gene_symbol\n",
      "0        100763416               Mtr                Mtr\n",
      "1        100758493             Pola1              Pola1\n",
      "2        100762815             Pold2              Pold2\n",
      "3        100774890             Rev3l              Rev3l\n",
      "4        100751096              Poll               Poll\n",
      "5        100773935             Pold1              Pold1\n",
      "6        100753174              Rfc5               Rfc5\n",
      "7        100756090             Pold3              Pold3\n",
      "8        100774671              Pole               Pole\n",
      "9        100768307             Pola2              Pola2\n",
      "10       100763640            Ptpmt1             Ptpmt1\n",
      "11       100763004             Eif3g              Eif3g\n",
      "12       100753359             Eif3l              Eif3l\n",
      "13       100769028             Eif3f              Eif3f\n",
      "14       100689446              Gart               Gart\n",
      "15       100689310            Eef1e1             Eef1e1\n",
      "16       100689051              Eef2               Eef2\n",
      "17       100762904             Acaca              Acaca\n",
      "18       100771190             Eif3e              Eif3e\n",
      "19       100753545             Eef1g              Eef1g\n",
      "20       100766600             Eif3k              Eif3k\n",
      "21       100762979             Eif3b              Eif3b\n",
      "22       100768213             Eif3m              Eif3m\n",
      "23       100753319             Eif3i              Eif3i\n",
      "24       100752118             Eif3a              Eif3a\n",
      "25       100751998             Eif3h              Eif3h\n",
      "26       100689232               Cad                Cad\n",
      "27       100756632             Dhodh              Dhodh\n",
      "28       100767580           Hsd17b7            Hsd17b7\n",
      "29       100756809              Agps               Agps\n",
      "30       100756786              Umps               Umps\n",
      "31       100766541               Mvd                Mvd\n",
      "32       100765639               Ebp                Ebp\n",
      "33       100773070             Cept1              Cept1\n",
      "34       100756363             Hmgcr              Hmgcr\n",
      "35       100689449              Pgs1               Pgs1\n",
      "36       100753498               Lss                Lss\n",
      "37       100761591              Rrm1               Rrm1\n",
      "38       100751653               Mvk                Mvk\n",
      "39       100759992              Pmvk               Pmvk\n",
      "40       100689192             Fdft1              Fdft1\n",
      "41       100764834              Sqle               Sqle\n",
      "42       100765024             Gnpat              Gnpat\n",
      "43       100689060              Adsl               Adsl\n",
      "44       100774578              Kdsr               Kdsr\n",
      "45       100689093              Pisd               Pisd\n",
      "46       100750895              Atic               Atic\n",
      "47       100758991             Paics              Paics\n",
      "48       100760149              Ppat               Ppat\n",
      "49       100756126              Gmps               Gmps\n",
      "50       100760956              Pfas               Pfas\n",
      "51       100689326            Sptlc1             Sptlc1\n",
      "Processing time point: Zela P6 to P8\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp0ue55ne6.lp\n",
      "Reading time = 0.05 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Optimized objective (growth rate): 0.007324063298029265\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp5ie_edx8.lp\n",
      "Reading time = 0.07 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp8_ptd2r8.lp\n",
      "Reading time = 0.06 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp5u4sinji.lp\n",
      "Reading time = 0.08 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpvx9jpdku.lp\n",
      "Reading time = 0.10 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpx1bd_1t7.lp\n",
      "Reading time = 0.09 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpzir4u5h7.lp\n",
      "Reading time = 0.16 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpkd07r1tv.lp\n",
      "Reading time = 0.15 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "   gene_exp_ess.id gene_exp_ess.name entrez_gene_symbol\n",
      "0        100756126              Gmps               Gmps\n",
      "1        100689326            Sptlc1             Sptlc1\n",
      "2        100767580           Hsd17b7            Hsd17b7\n",
      "3        100756809              Agps               Agps\n",
      "4        100766541               Mvd                Mvd\n",
      "5        100765639               Ebp                Ebp\n",
      "6        100773070             Cept1              Cept1\n",
      "7        100756363             Hmgcr              Hmgcr\n",
      "8        100689449              Pgs1               Pgs1\n",
      "9        100753498               Lss                Lss\n",
      "10       100762189      LOC100762189       LOC100762189\n",
      "11       100761591              Rrm1               Rrm1\n",
      "12       100759992              Pmvk               Pmvk\n",
      "13       100689192             Fdft1              Fdft1\n",
      "14       100764834              Sqle               Sqle\n",
      "15       100765024             Gnpat              Gnpat\n",
      "16       100689060              Adsl               Adsl\n",
      "17       100689446              Gart               Gart\n",
      "18       100689093              Pisd               Pisd\n",
      "19       100750895              Atic               Atic\n",
      "20       100758991             Paics              Paics\n",
      "21       100752118             Eif3a              Eif3a\n",
      "22       100751998             Eif3h              Eif3h\n",
      "23       100760149              Ppat               Ppat\n",
      "24       100760956              Pfas               Pfas\n",
      "25       100689232               Cad                Cad\n",
      "26       100756632             Dhodh              Dhodh\n",
      "27       100756786              Umps               Umps\n",
      "28       100758493             Pola1              Pola1\n",
      "29       100762815             Pold2              Pold2\n",
      "30       100774890             Rev3l              Rev3l\n",
      "31       100751096              Poll               Poll\n",
      "32       100773935             Pold1              Pold1\n",
      "33       100753174              Rfc5               Rfc5\n",
      "34       100756090             Pold3              Pold3\n",
      "35       100774671              Pole               Pole\n",
      "36       100768307             Pola2              Pola2\n",
      "37       100750580                Cs                 Cs\n",
      "38       100763640            Ptpmt1             Ptpmt1\n",
      "39       100763004             Eif3g              Eif3g\n",
      "40       100753359             Eif3l              Eif3l\n",
      "41       100769028             Eif3f              Eif3f\n",
      "42       100774578              Kdsr               Kdsr\n",
      "43       100689310            Eef1e1             Eef1e1\n",
      "44       100689051              Eef2               Eef2\n",
      "45       100762904             Acaca              Acaca\n",
      "46       100771190             Eif3e              Eif3e\n",
      "47       100753545             Eef1g              Eef1g\n",
      "48       100766600             Eif3k              Eif3k\n",
      "49       100762979             Eif3b              Eif3b\n",
      "50       100768213             Eif3m              Eif3m\n",
      "51       100753319             Eif3i              Eif3i\n",
      "Processing time point: WT P2 to P4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpnswpiwas.lp\n",
      "Reading time = 0.06 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Optimized objective (growth rate): 0.035864607666101986\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp_qtpt0jy.lp\n",
      "Reading time = 0.07 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpr0nywvkv.lp\n",
      "Reading time = 0.08 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp3wib2pei.lp\n",
      "Reading time = 0.08 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp7f8719a4.lp\n",
      "Reading time = 0.09 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpva55c30l.lp\n",
      "Reading time = 0.08 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmps8d6aj3o.lp\n",
      "Reading time = 0.11 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpoov3fjvm.lp\n",
      "Reading time = 0.13 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "   gene_exp_ess.id gene_exp_ess.name entrez_gene_symbol\n",
      "0        100689449              Pgs1               Pgs1\n",
      "1        100756809              Agps               Agps\n",
      "2        100756126              Gmps               Gmps\n",
      "3        100756632             Dhodh              Dhodh\n",
      "4        100773070             Cept1              Cept1\n",
      "5        100689060              Adsl               Adsl\n",
      "6        100756786              Umps               Umps\n",
      "7        100774578              Kdsr               Kdsr\n",
      "8        100689093              Pisd               Pisd\n",
      "9        100760149              Ppat               Ppat\n",
      "10       100764834              Sqle               Sqle\n",
      "11       100689326            Sptlc1             Sptlc1\n",
      "12       100760956              Pfas               Pfas\n",
      "13       100762904             Acaca              Acaca\n",
      "14       100689232               Cad                Cad\n",
      "15       100763640            Ptpmt1             Ptpmt1\n",
      "16       100689446              Gart               Gart\n",
      "17       100750895              Atic               Atic\n",
      "18       100758991             Paics              Paics\n",
      "19       100765024             Gnpat              Gnpat\n",
      "20       100751653               Mvk                Mvk\n",
      "21       100761591              Rrm1               Rrm1\n",
      "22       100759992              Pmvk               Pmvk\n",
      "23       100751998             Eif3h              Eif3h\n",
      "24       100752118             Eif3a              Eif3a\n",
      "25       100762189      LOC100762189       LOC100762189\n",
      "26       100774890             Rev3l              Rev3l\n",
      "27       100689192             Fdft1              Fdft1\n",
      "28       100689310            Eef1e1             Eef1e1\n",
      "29       100762979             Eif3b              Eif3b\n",
      "30       100766600             Eif3k              Eif3k\n",
      "31       100771190             Eif3e              Eif3e\n",
      "32       100753545             Eef1g              Eef1g\n",
      "33       100768213             Eif3m              Eif3m\n",
      "34       100753319             Eif3i              Eif3i\n",
      "35       100753174              Rfc5               Rfc5\n",
      "36       100763416               Mtr                Mtr\n",
      "37       100689051              Eef2               Eef2\n",
      "38       100762815             Pold2              Pold2\n",
      "39       100756090             Pold3              Pold3\n",
      "40       100753359             Eif3l              Eif3l\n",
      "41       100769028             Eif3f              Eif3f\n",
      "42       100774671              Pole               Pole\n",
      "43       100768307             Pola2              Pola2\n",
      "44       100758493             Pola1              Pola1\n",
      "45       100763004             Eif3g              Eif3g\n",
      "46       100766541               Mvd                Mvd\n",
      "47       100751096              Poll               Poll\n",
      "48       100765639               Ebp                Ebp\n",
      "49       100756363             Hmgcr              Hmgcr\n",
      "50       100753498               Lss                Lss\n",
      "51       100773935             Pold1              Pold1\n",
      "Processing time point: WT P4 to P6\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpln2dfi3k.lp\n",
      "Reading time = 0.06 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Optimized objective (growth rate): 0.018010251694238397\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp6ditu2vt.lp\n",
      "Reading time = 0.06 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmplpy6j4jw.lp\n",
      "Reading time = 0.06 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpl4k2e4c2.lp\n",
      "Reading time = 0.06 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp87rkxk2n.lp\n",
      "Reading time = 0.08 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmpfmd0kzpr.lp\n",
      "Reading time = 0.09 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmphk030vka.lp\n",
      "Reading time = 0.13 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-16\n",
      "Read LP format model from file /var/folders/8_/lxtrgg8n30b2czkwbgcxncmh0000gp/T/tmp11xf4kkz.lp\n",
      "Reading time = 0.09 seconds\n",
      ": 4764 rows, 17114 columns, 72396 nonzeros\n",
      "   gene_exp_ess.id gene_exp_ess.name entrez_gene_symbol\n",
      "0        100756809              Agps               Agps\n",
      "1        100773070             Cept1              Cept1\n",
      "2        100689449              Pgs1               Pgs1\n",
      "3        100765024             Gnpat              Gnpat\n",
      "4        100763640            Ptpmt1             Ptpmt1\n",
      "5        100689446              Gart               Gart\n",
      "6        100762904             Acaca              Acaca\n",
      "7        100689093              Pisd               Pisd\n",
      "8        100750895              Atic               Atic\n",
      "9        100758991             Paics              Paics\n",
      "10       100760149              Ppat               Ppat\n",
      "11       100760956              Pfas               Pfas\n",
      "12       100689232               Cad                Cad\n",
      "13       100756632             Dhodh              Dhodh\n",
      "14       100767580           Hsd17b7            Hsd17b7\n",
      "15       100763416               Mtr                Mtr\n",
      "16       100756786              Umps               Umps\n",
      "17       100766541               Mvd                Mvd\n",
      "18       100765639               Ebp                Ebp\n",
      "19       100756363             Hmgcr              Hmgcr\n",
      "20       100753498               Lss                Lss\n",
      "21       100761591              Rrm1               Rrm1\n",
      "22       100758493             Pola1              Pola1\n",
      "23       100762815             Pold2              Pold2\n",
      "24       100751653               Mvk                Mvk\n",
      "25       100759992              Pmvk               Pmvk\n",
      "26       100764834              Sqle               Sqle\n",
      "27       100774890             Rev3l              Rev3l\n",
      "28       100751096              Poll               Poll\n",
      "29       100773935             Pold1              Pold1\n",
      "30       100753174              Rfc5               Rfc5\n",
      "31       100756090             Pold3              Pold3\n",
      "32       100774671              Pole               Pole\n",
      "33       100768307             Pola2              Pola2\n",
      "34       100763004             Eif3g              Eif3g\n",
      "35       100689060              Adsl               Adsl\n",
      "36       100753359             Eif3l              Eif3l\n",
      "37       100769028             Eif3f              Eif3f\n",
      "38       100774578              Kdsr               Kdsr\n",
      "39       100689310            Eef1e1             Eef1e1\n",
      "40       100689051              Eef2               Eef2\n",
      "41       100771190             Eif3e              Eif3e\n",
      "42       100753545             Eef1g              Eef1g\n",
      "43       100766600             Eif3k              Eif3k\n",
      "44       100762979             Eif3b              Eif3b\n",
      "45       100768213             Eif3m              Eif3m\n",
      "46       100753319             Eif3i              Eif3i\n",
      "47       100752118             Eif3a              Eif3a\n",
      "48       100751998             Eif3h              Eif3h\n",
      "49       100756126              Gmps               Gmps\n",
      "50       100689326            Sptlc1             Sptlc1\n",
      "Combined Matched Zela DataFrame:\n",
      "    gene_exp_ess.id gene_exp_ess.name entrez_gene_symbol\n",
      "0         100689446              Gart               Gart\n",
      "1         100762904             Acaca              Acaca\n",
      "2         100689093              Pisd               Pisd\n",
      "3         100756126              Gmps               Gmps\n",
      "4         100767580           Hsd17b7            Hsd17b7\n",
      "5         100756809              Agps               Agps\n",
      "6         100766541               Mvd                Mvd\n",
      "7         100773070             Cept1              Cept1\n",
      "8         100765639               Ebp                Ebp\n",
      "9         100756363             Hmgcr              Hmgcr\n",
      "10        100689449              Pgs1               Pgs1\n",
      "11        100753498               Lss                Lss\n",
      "12        100762189      LOC100762189       LOC100762189\n",
      "13        100759992              Pmvk               Pmvk\n",
      "14        100689192             Fdft1              Fdft1\n",
      "15        100764834              Sqle               Sqle\n",
      "16        100765024             Gnpat              Gnpat\n",
      "17        100689310            Eef1e1             Eef1e1\n",
      "18        100689051              Eef2               Eef2\n",
      "19        100771190             Eif3e              Eif3e\n",
      "20        100753545             Eef1g              Eef1g\n",
      "21        100766600             Eif3k              Eif3k\n",
      "22        100762979             Eif3b              Eif3b\n",
      "23        100750895              Atic               Atic\n",
      "24        100768213             Eif3m              Eif3m\n",
      "25        100758991             Paics              Paics\n",
      "26        100760149              Ppat               Ppat\n",
      "27        100753319             Eif3i              Eif3i\n",
      "28        100760956              Pfas               Pfas\n",
      "29        100752118             Eif3a              Eif3a\n",
      "30        100689232               Cad                Cad\n",
      "31        100689326            Sptlc1             Sptlc1\n",
      "32        100751998             Eif3h              Eif3h\n",
      "33        100756632             Dhodh              Dhodh\n",
      "34        100756786              Umps               Umps\n",
      "35        100761591              Rrm1               Rrm1\n",
      "36        100758493             Pola1              Pola1\n",
      "37        100762815             Pold2              Pold2\n",
      "38        100774890             Rev3l              Rev3l\n",
      "39        100751096              Poll               Poll\n",
      "40        100773935             Pold1              Pold1\n",
      "41        100753174              Rfc5               Rfc5\n",
      "42        100756090             Pold3              Pold3\n",
      "43        100774671              Pole               Pole\n",
      "44        100768307             Pola2              Pola2\n",
      "45        100763640            Ptpmt1             Ptpmt1\n",
      "46        100763004             Eif3g              Eif3g\n",
      "47        100689060              Adsl               Adsl\n",
      "48        100774578              Kdsr               Kdsr\n",
      "49        100753359             Eif3l              Eif3l\n",
      "50        100769028             Eif3f              Eif3f\n",
      "71        100763416               Mtr                Mtr\n",
      "82        100751653               Mvk                Mvk\n",
      "192       100750580                Cs                 Cs\n",
      "Combined Matched WT DataFrame:\n",
      "   gene_exp_ess.id gene_exp_ess.name entrez_gene_symbol\n",
      "0        100689449              Pgs1               Pgs1\n",
      "1        100756809              Agps               Agps\n",
      "2        100756126              Gmps               Gmps\n",
      "3        100756632             Dhodh              Dhodh\n",
      "4        100773070             Cept1              Cept1\n",
      "5        100689060              Adsl               Adsl\n",
      "6        100756786              Umps               Umps\n",
      "7        100774578              Kdsr               Kdsr\n",
      "8        100689093              Pisd               Pisd\n",
      "9        100760149              Ppat               Ppat\n",
      "10       100764834              Sqle               Sqle\n",
      "11       100689326            Sptlc1             Sptlc1\n",
      "12       100760956              Pfas               Pfas\n",
      "13       100762904             Acaca              Acaca\n",
      "14       100689232               Cad                Cad\n",
      "15       100763640            Ptpmt1             Ptpmt1\n",
      "16       100689446              Gart               Gart\n",
      "17       100750895              Atic               Atic\n",
      "18       100758991             Paics              Paics\n",
      "19       100765024             Gnpat              Gnpat\n",
      "20       100751653               Mvk                Mvk\n",
      "21       100761591              Rrm1               Rrm1\n",
      "22       100759992              Pmvk               Pmvk\n",
      "23       100751998             Eif3h              Eif3h\n",
      "24       100752118             Eif3a              Eif3a\n",
      "25       100762189      LOC100762189       LOC100762189\n",
      "26       100774890             Rev3l              Rev3l\n",
      "27       100689192             Fdft1              Fdft1\n",
      "28       100689310            Eef1e1             Eef1e1\n",
      "29       100762979             Eif3b              Eif3b\n",
      "30       100766600             Eif3k              Eif3k\n",
      "31       100771190             Eif3e              Eif3e\n",
      "32       100753545             Eef1g              Eef1g\n",
      "33       100768213             Eif3m              Eif3m\n",
      "34       100753319             Eif3i              Eif3i\n",
      "35       100753174              Rfc5               Rfc5\n",
      "36       100763416               Mtr                Mtr\n",
      "37       100689051              Eef2               Eef2\n",
      "38       100762815             Pold2              Pold2\n",
      "39       100756090             Pold3              Pold3\n",
      "40       100753359             Eif3l              Eif3l\n",
      "41       100769028             Eif3f              Eif3f\n",
      "42       100774671              Pole               Pole\n",
      "43       100768307             Pola2              Pola2\n",
      "44       100758493             Pola1              Pola1\n",
      "45       100763004             Eif3g              Eif3g\n",
      "46       100766541               Mvd                Mvd\n",
      "47       100751096              Poll               Poll\n",
      "48       100765639               Ebp                Ebp\n",
      "49       100756363             Hmgcr              Hmgcr\n",
      "50       100753498               Lss                Lss\n",
      "51       100773935             Pold1              Pold1\n",
      "66       100767580           Hsd17b7            Hsd17b7\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "matched_zela = []\n",
    "matched_wt = []\n",
    "\n",
    "objective = 'biomass_cho_s'\n",
    "\n",
    "# Adjust the lower bound values according to the experimental growth rates in order to indetify bottlenecks\n",
    "time_points_dict = {'P0 to P2':'P2', 'P2 to P4':'P4', 'P4 to P6':'P6', 'P6 to P8':'P8', 'P8 to P12':'P12', 'P12 to P14':'P14'}\n",
    "time_points_zela = {'P0 to P2':'P2', 'P2 to P4':'P4', 'P4 to P6':'P6', 'P6 to P8':'P8'}\n",
    "time_points_wt = {'P2 to P4':'P4', 'P4 to P6':'P6'}\n",
    "\n",
    "for time_key in time_points_zela.keys():\n",
    "    print(f\"Processing time point: Zela {time_key}\")\n",
    "    #Zela\n",
    "    GM_constrained, pfba_obj, pfba_solution = constraint_model_feg(\n",
    "        model, \n",
    "        time=time_key, \n",
    "        exp_dict=temp_dict_zela\n",
    "    )\n",
    "    # Find and match essential genes\n",
    "    matched_df_zela = find_and_match_essential_genes(GM_constrained, df_loaded, save_csv=False, print_df=True)\n",
    "    \n",
    "    # Append the matched DataFrame for Zela to the list\n",
    "    matched_zela.append(matched_df_zela)\n",
    "    \n",
    "for time_key in time_points_wt.keys():\n",
    "    print(f\"Processing time point: WT {time_key}\")\n",
    "    # WT\n",
    "    GM_constrained, pfba_obj, pfba_solution = constraint_model_feg(\n",
    "        model, \n",
    "        time=time_key, \n",
    "        exp_dict=temp_dict_wt\n",
    "    )\n",
    "    # Find and match essential genes\n",
    "    matched_df_wt = find_and_match_essential_genes(GM_constrained, df_loaded, save_csv=False, print_df=True)\n",
    "    \n",
    "    # Append the matched DataFrame for WT to the list\n",
    "    matched_wt.append(matched_df_wt)\n",
    "\n",
    "# Concatenate matched DataFrames into one and remove duplicates\n",
    "if matched_zela:\n",
    "    combined_matched_zela = pd.concat(matched_zela, ignore_index=True).drop_duplicates()\n",
    "    print(\"Combined Matched Zela DataFrame:\")\n",
    "    print(combined_matched_zela)\n",
    "\n",
    "if matched_wt:\n",
    "    combined_matched_wt = pd.concat(matched_wt, ignore_index=True).drop_duplicates()\n",
    "    print(\"Combined Matched WT DataFrame:\")\n",
    "    print(combined_matched_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined All (WT + Zela) DataFrame without duplicates:\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "# Combine the two combined DataFrames and remove duplicates\n",
    "if matched_zela and matched_wt:\n",
    "    combined_all = pd.concat([combined_matched_zela, combined_matched_wt], ignore_index=True).drop_duplicates()\n",
    "    print(\"Combined All (WT + Zela) DataFrame without duplicates:\")\n",
    "    print(len(combined_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_matched_zela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_matched_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.solver = 'gurobi'\n",
    "for rxn in model.boundary:\n",
    "\n",
    "    # Models that are forced to secrete ethanol are not feasible\n",
    "    if rxn.id == 'EX_etoh_e':\n",
    "        rxn.bounds = (-0.1,0.1)\n",
    "        continue\n",
    "\n",
    "    # Replace the lower and upper bound with experimental data\n",
    "    if rxn.id in temp_dict.keys():\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "\n",
    "    # Keep boundaries open for essential metabolites\n",
    "    if rxn.id == 'EX_h2o_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "    if rxn.id == 'EX_h_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "    if rxn.id == 'EX_o2_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "    if rxn.id == 'EX_hco3_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "    if rxn.id == 'EX_so4_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "    if rxn.id == 'EX_pi_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "\n",
    "    # Boundaries from Sink reactions on iCHO_v1 (100 times lower)\n",
    "    if rxn.id == 'SK_Asn_X_Ser_Thr_r':\n",
    "        rxn.bounds = (-0.1,1000)\n",
    "        continue\n",
    "    if rxn.id == 'SK_Tyr_ggn_c':\n",
    "        rxn.bounds = (-0.1,1000)\n",
    "        continue\n",
    "    if rxn.id == 'SK_Ser_Thr_g':\n",
    "        rxn.bounds = (-0.1,1000)\n",
    "        continue\n",
    "    if rxn.id == 'SK_pre_prot_r':\n",
    "        rxn.bounds = (-0.1,1000)\n",
    "        continue\n",
    "\n",
    "    # Close uptake rates for the rest of the boundaries\n",
    "    if rxn.id.startswith(\"EX_\"):\n",
    "        rxn.bounds = (0,1000) \n",
    "    if rxn.id.startswith(\"SK_\"):\n",
    "        rxn.bounds = (0,1000)\n",
    "    if rxn.id.startswith(\"DM_\"):\n",
    "        rxn.bounds = (0,1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the essential genes\n",
    "print(f\"Number of essential genes for biomass: {len(essential_genes)}\")\n",
    "print(\"Essential genes for biomass production:\")\n",
    "for gene_idx in essential_genes.index:\n",
    "    gene = model.genes[gene_idx]\n",
    "    print(f\"{gene.id}: {gene.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobra.flux_analysis.variability import find_essential_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_essential_genes = find_essential_genes(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_deletion_results = single_gene_deletion(model)\n",
    "essentiality_threshold = 0.01\n",
    "essential_genes = gene_deletion_results[gene_deletion_results['growth'] < essentiality_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' contains 'gene' and 'entrez_gene_id'\n",
    "# Create a reverse lookup dictionary where the key is the Entrez Gene ID and the value is the gene symbol\n",
    "entrez_dict = df.set_index('entrez_gene_id')['gene'].to_dict()\n",
    "\n",
    "# Print the essential genes and match them with Entrez Gene IDs\n",
    "print(f\"Number of essential genes for biomass: {len(essential_genes)}\")\n",
    "print(\"Essential genes for biomass production with matching Entrez IDs:\")\n",
    "\n",
    "# Create an empty list to store the results\n",
    "matched_genes = []\n",
    "\n",
    "for gene_idx in essential_genes.index:\n",
    "    gene_exp_ess = model.genes[gene_idx]\n",
    "    \n",
    "    # Check if the gene.id matches any Entrez Gene ID (value) in the reverse dictionary\n",
    "    if gene_exp_ess.id in entrez_dict:\n",
    "        # If it matches, retrieve the corresponding gene symbol\n",
    "        entrez_gene_symbol = entrez_dict[gene_exp_ess.id]\n",
    "        print(f\"{gene_exp_ess.id}: {gene_exp_ess.name}, Entrez Gene Symbol: {entrez_gene_symbol}\")\n",
    "        \n",
    "        # Append the matched result to the list\n",
    "        matched_genes.append((gene_exp_ess.id, gene_exp_ess.name, entrez_gene_symbol))\n",
    "    else:\n",
    "        print(f\"{gene_exp_ess.id}: {gene_exp_ess.name}, No Entrez Gene Match\")\n",
    "\n",
    "# Convert the matched list into a DataFrame if needed\n",
    "matched_genes_essential_df = pd.DataFrame(matched_genes, columns=['gene_exp_ess.id', 'gene_exp_ess.name', 'entrez_gene_symbol'])\n",
    "\n",
    "# Save the result to a CSV file if desired\n",
    "matched_genes_essential_df.to_csv(\"matched_gene_entrez_ids.csv\", index=False)\n",
    "\n",
    "# Print or return the DataFrame for further use\n",
    "print(matched_genes_df)\n",
    "\n",
    "# Create an empty list to store the results\n",
    "matched_genes_model = []\n",
    "\n",
    "# Iterate through all genes in the model\n",
    "for gene in model.genes:\n",
    "    # Check if the gene.id (or gene.name) matches any Entrez Gene ID in the dictionary\n",
    "    if gene.id in entrez_dict:  # Here we're assuming gene.id matches the entrez_gene_id\n",
    "        entrez_gene_symbol = entrez_dict[gene.id]  # Get the corresponding gene symbol\n",
    "        print(f\"Model gene.id: {gene.id}, Gene name: {gene.name}, Matched Entrez Gene Symbol: {entrez_gene_symbol}\")\n",
    "        \n",
    "        # Append the matched gene information to the list\n",
    "        matched_genes_model.append((gene.id, gene.name, entrez_gene_symbol))\n",
    "    else:\n",
    "        print(f\"Model gene.id: {gene.id}, Gene name: {gene.name}, No match found.\")\n",
    "\n",
    "# Convert the matched genes list to a DataFrame\n",
    "matched_genes_df = pd.DataFrame(matched_genes_model, columns=['gene.id', 'gene.name', 'entrez_gene_symbol'])\n",
    "\n",
    "# Save the result to a CSV file if needed\n",
    "matched_genes_df.to_csv(\"matched_model_genes.csv\", index=False)\n",
    "\n",
    "# Print or return the matched genes DataFrame\n",
    "print(matched_genes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(entrez_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "essential_genes_model = []\n",
    "for g in model.genes:\n",
    "    if g.name in all_gene_names:\n",
    "        essential_genes_model.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = set(sim_essential_genes)\n",
    "set2 = set(essential_genes_model)\n",
    "\n",
    "# Find shared elements\n",
    "shared_elements = set1.intersection(set2)\n",
    "\n",
    "# Find unique elements\n",
    "unique_in_list1 = set1.difference(set2)\n",
    "unique_in_list2 = set2.difference(set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shared genes between Exp Validated Essential Genes and Simulated Essential Genes:\", len(shared_elements))\n",
    "print(\"Unique genes in Simulated Essential Genes:\", len(unique_in_list1))\n",
    "print(\"Unique genes in Exp Validated Essentail Genes:\", len(unique_in_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Essential for growth genes and comparison to (An optimised genome-wide, virus free CRISPR screen for mammalian cells)\n",
    "https://pubmed.ncbi.nlm.nih.gov/34935002/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Context-specific Model Generation <a id='context_specific'></a>\n",
    "\n",
    "Here we use a matrix generated with rmf_CADRE to generate each context_specific model for each one of the conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from time import process_time\n",
    "\n",
    "import pymCADRE\n",
    "from pymCADRE.rank import rank_reactions\n",
    "from pymCADRE.check import check_model_function\n",
    "from pymCADRE.prune import prune_model\n",
    "\n",
    "import cobra\n",
    "from cobra.io import load_json_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Intervals for Context-specific model generation\n",
    "Here we define the set of constraints in the uptake and secretion rates that we want to incorporate to our context specific models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Loading and Constraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load generic model\n",
    "model = load_json_model('iCHO3595_unblocked.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load uptake and secretion rate \"Intervals dict\n",
    "\n",
    "with open('../Data/Uptake_Secretion_Rates/uptake_secretion_intrvl_wt_dict.pkl', 'rb') as file:\n",
    "    uptsec_intrvl_wt = pickle.load(file)\n",
    "\n",
    "with open('../Data/Uptake_Secretion_Rates/uptake_secretion_intrvl_zela_dict.pkl', 'rb') as file:\n",
    "    uptsec_intrvl_zela = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = uptsec_intrvl_zela\n",
    "time = 'P2 to P4'\n",
    "\n",
    "with model as model:\n",
    "    model.reactions.biomass_cho_s.bounds = temp_dict['exp_growth_rate'][time]\n",
    "    for rxn in model.boundary:\n",
    "        \n",
    "        # Models that are forced to secrete ethanol are not feasible\n",
    "        if rxn.id == 'EX_etoh_e':\n",
    "            rxn.bounds = (-0.1,0.1)\n",
    "            continue\n",
    "\n",
    "        # Replace the lower and upper bound with experimental data\n",
    "        if rxn.id in temp_dict.keys():\n",
    "            rxn.bounds = temp_dict[rxn.id][time]\n",
    "            continue\n",
    "        \n",
    "        # Keep boundaries open for essential metabolites\n",
    "        if rxn.id == 'EX_h2o_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "        if rxn.id == 'EX_h_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "        if rxn.id == 'EX_o2_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "        if rxn.id == 'EX_hco3_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "        if rxn.id == 'EX_so4_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "        if rxn.id == 'EX_pi_e':\n",
    "            rxn.bounds = (-1000,1000)\n",
    "            continue\n",
    "\n",
    "        # Boundaries from Sink reactions on iCHO_v1 (100 times lower)\n",
    "        if rxn.id == 'SK_Asn_X_Ser_Thr_r':\n",
    "            rxn.bounds = (-0.001,1000)\n",
    "            continue\n",
    "        if rxn.id == 'SK_Tyr_ggn_c':\n",
    "            rxn.bounds = (-0.001,1000)\n",
    "            continue\n",
    "        if rxn.id == 'SK_Ser_Thr_g':\n",
    "            rxn.bounds = (-0.001,1000)\n",
    "            continue\n",
    "        if rxn.id == 'SK_pre_prot_r':\n",
    "            rxn.bounds = (-0.0006,1000)\n",
    "            continue\n",
    "\n",
    "        # Close uptake rates for the rest of the boundaries\n",
    "        if rxn.id.startswith(\"EX_\"):\n",
    "            rxn.bounds = (0,1000) \n",
    "        if rxn.id.startswith(\"SK_\"):\n",
    "            rxn.bounds = (0,1000)\n",
    "        if rxn.id.startswith(\"DM_\"):\n",
    "            rxn.bounds = (0,1000)\n",
    "        \n",
    "    pfba_solution = cobra.flux_analysis.pfba(model)\n",
    "    pfba_obj = pfba_solution.fluxes[objective]\n",
    "    print(pfba_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Ubiquity and Confidence Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .mat file\n",
    "mat_data = loadmat('../Data/Context_specific_models/ubiData.mat')\n",
    "\n",
    "# Access the ubiData structure\n",
    "ubiData = mat_data['ubiData']\n",
    "\n",
    "# Accessing individual fields within ubiData\n",
    "ubiScores = ubiData['ubiScores'][0, 0]\n",
    "uScore = ubiData['uScore'][0, 0]\n",
    "rxns = ubiData['rxns'][0, 0]\n",
    "Condition = ubiData['Condition'][0, 0]\n",
    "\n",
    "# Print or process the data as needed\n",
    "print(ubiScores.shape)\n",
    "print(uScore.shape)\n",
    "print(rxns.shape)\n",
    "print(Condition.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,cond in enumerate(Condition[0]):\n",
    "    if \"WT_P4\" in cond[0]:\n",
    "        print(cond[0], i)\n",
    "    elif \"ZeLa_P4\" in cond[0]:\n",
    "        print(cond[0], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Condition[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ubiquity score list\n",
    "U = list(ubiScores[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conf Score List\n",
    "conf_scores = pd.read_csv('../Data/Context_specific_models/confidence_scores.csv', header=None).iloc[:, 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protected Reations\n",
    "high_confidence_reactions = ['biomass_cho_s', 'DNAsyn', 'LipidSyn_cho_s', 'PROTsyn_cho_s', 'RNAsyn_cho_s', 'EX_bhb_e', 'EX_nh4_e', 'EX_ac_e', 'EX_ala_L_e',\n",
    "    'EX_arg_L_e', 'EX_asn_L_e', 'EX_asp_L_e', 'EX_2hb_e', 'EX_cit_e', 'EX_cys_L_e', 'EX_etoh_e', 'EX_for_e', 'EX_fum_e', 'EX_glc_e', 'EX_glu_L_e',\n",
    "    'EX_gln_L_e', 'EX_gly_e', 'EX_his_L_e', 'EX_4hpro_e', 'EX_ile_L_e', 'EX_lac_L_e', 'EX_leu_L_e', 'EX_lys_L_e', 'EX_mal_L_e', 'EX_met_L_e',\n",
    "    'EX_phe_L_e', 'EX_pro_L_e', 'EX_5oxpro_e', 'EX_pyr_e', 'EX_ser_L_e', 'EX_thr_L_e', 'EX_trp_L_e', 'EX_tyr_L_e', 'EX_val_L_e', 'EX_h2o_e',\n",
    "    'EX_h_e', 'EX_o2_e', 'EX_hco3_e', 'EX_so4_e', 'EX_pi_e', 'SK_Asn_X_Ser_Thr_r', 'SK_Tyr_ggn_c', 'SK_Ser_Thr_g', 'SK_pre_prot_r'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Rank reactions\n",
    "##############################################\n",
    "\n",
    "print('Processing inputs and ranking reactions...')\n",
    "GM, C, NC, P, Z, model_C = rank_reactions(model, U, conf_scores, high_confidence_reactions, method=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the results\n",
    "print(\"Generic Model:\", GM)\n",
    "print(\"Core Reactions:\", len(C))\n",
    "print(\"Non-Core Reactions:\", len(NC))\n",
    "print(\"Ranked Non-Core Reactions:\", len(P))\n",
    "print(\"Zero-Expression Reactions:\", len(Z))\n",
    "print(\"Core Reactions in Original Model:\", len(model_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobra.util import create_stoichiometric_matrix\n",
    "\n",
    "def retrieve_precursor_metabolites(model, protected_rxns):\n",
    "    \"\"\"\n",
    "    Retrieve precursor metabolites from a specified list of reactions in a metabolic model.\n",
    "\n",
    "    Args:\n",
    "        model: cobra.Model - The metabolic model.\n",
    "        protected_rxns: list - A list of reaction IDs for which precursor metabolites need to be retrieved.\n",
    "\n",
    "    Returns:\n",
    "        precursor_mets: list - A list of precursor metabolites.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a list of all the reactions in the model\n",
    "    model_reactions = [r.id for r in model.reactions]\n",
    "    \n",
    "    # Ensure that the protected reactions list is not empty\n",
    "    if protected_rxns:\n",
    "        \n",
    "        #Define a list to store the indices of the protected reactions\n",
    "        rxn_indices = []\n",
    "        \n",
    "        for rxn in protected_rxns:\n",
    "            # Ensure that the protected reaction is included in the model\n",
    "            if rxn in model_reactions:\n",
    "                # Get the indices of the protected reactions in the model, only if the reaction exists\n",
    "                rxn_indices.append(model.reactions.index(model.reactions.get_by_id(rxn)))\n",
    "\n",
    "        # Create stoichiometric matrix S\n",
    "        S = create_stoichiometric_matrix(model)\n",
    "        \n",
    "        # Retrieve precursor metabolites: metabolites with a negative coefficient in the stoichiometric matrix\n",
    "        precursor_mets = [\n",
    "            model.metabolites[i] \n",
    "            for i in range(len(model.metabolites)) \n",
    "            if any(S[i, idx] < 0 for idx in rxn_indices)\n",
    "        ]\n",
    "\n",
    "        return precursor_mets\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precursor_mets = retrieve_precursor_metabolites(model, high_confidence_reactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Define inputs to the model pruning step\n",
    "##################################################\n",
    "\n",
    "# Define core vs. non-core ratio threshold for removing reactions\n",
    "eta = 1 / 3\n",
    "\n",
    "# Check functionality of generic model\n",
    "genericStatus = check_model_function(GM, 'required_mets', precursor_mets)[0]\n",
    "print(genericStatus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint the model with exp data\n",
    "\n",
    "time = 'P2 to P4'\n",
    "\n",
    "GM.solver = 'gurobi'\n",
    "objective = 'biomass_cho_s' # 'biomass_cho'\n",
    "GM.objective = objective\n",
    "\n",
    "GM.reactions.biomass_cho_s.bounds = temp_dict['exp_growth_rate'][time]\n",
    "for rxn in GM.boundary:\n",
    "    \n",
    "    # Models that are forced to secrete ethanol are not feasible\n",
    "    if rxn.id == 'EX_etoh_e':\n",
    "        rxn.bounds = (-0.1,0.1)\n",
    "        continue\n",
    "\n",
    "    # Replace the lower and upper bound with experimental data\n",
    "    if rxn.id in temp_dict.keys():\n",
    "        rxn.bounds = temp_dict[rxn.id][time]\n",
    "        continue\n",
    "    \n",
    "    # Keep boundaries open for essential metabolites\n",
    "    if rxn.id == 'EX_h2o_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "    if rxn.id == 'EX_h_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "    if rxn.id == 'EX_o2_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "    if rxn.id == 'EX_hco3_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "    if rxn.id == 'EX_so4_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "    if rxn.id == 'EX_pi_e':\n",
    "        rxn.bounds = (-1000,1000)\n",
    "        continue\n",
    "\n",
    "    # Boundaries from Sink reactions on iCHO_v1 (100 times lower)\n",
    "    if rxn.id == 'SK_Asn_X_Ser_Thr_r':\n",
    "        rxn.bounds = (-0.001,1000)\n",
    "        continue\n",
    "    if rxn.id == 'SK_Tyr_ggn_c':\n",
    "        rxn.bounds = (-0.001,1000)\n",
    "        continue\n",
    "    if rxn.id == 'SK_Ser_Thr_g':\n",
    "        rxn.bounds = (-0.001,1000)\n",
    "        continue\n",
    "    if rxn.id == 'SK_pre_prot_r':\n",
    "        rxn.bounds = (-0.0006,1000)\n",
    "        continue\n",
    "\n",
    "    # Close uptake rates for the rest of the boundaries\n",
    "    if rxn.id.startswith(\"EX_\"):\n",
    "        rxn.bounds = (0,1000) \n",
    "    if rxn.id.startswith(\"SK_\"):\n",
    "        rxn.bounds = (0,1000)\n",
    "    if rxn.id.startswith(\"DM_\"):\n",
    "        rxn.bounds = (0,1000)\n",
    "    \n",
    "pfba_solution = cobra.flux_analysis.pfba(GM)\n",
    "pfba_obj = pfba_solution.fluxes[objective]\n",
    "print(pfba_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if genericStatus:\n",
    "    print('Generic model passed precursor metabolites test')\n",
    "\n",
    "    ##############################################################\n",
    "    # If generic functionality test is passed, prune reactions\n",
    "    ###############################################################\n",
    "    print('Pruning reactions...')\n",
    "    t0 = process_time()\n",
    "    PM, cRes = prune_model(GM, P, C, Z, eta, precursor_mets, salvage_check=0, method=1)\n",
    "    # Stop the stopwatch / counter\n",
    "    t_stop = process_time()\n",
    "    # compute elapsed time\n",
    "    pruneTime = t_stop - t0\n",
    "\n",
    "else:\n",
    "    print('Generic model failed precursor metabolites test!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATP Generation loops removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import pickle\n",
    "import numpy as np\n",
    "from optlang.symbolics import Zero\n",
    "\n",
    "import cobra\n",
    "from cobra.util import create_stoichiometric_matrix\n",
    "from cobra.io import load_json_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Constraining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_json_model('iCHO3595_unblocked.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/Uptake_Secretion_Rates/uptake_secretion_raw_zela_dict.pkl', 'rb') as file:\n",
    "    uptsec_zela = pickle.load(file)\n",
    "\n",
    "for rxn in model.boundary:\n",
    "    if rxn.id in ['EX_h2o_e', 'EX_h_e', 'EX_o2_e', 'EX_hco3_e', 'EX_so4_e', 'EX_pi_e']:\n",
    "        rxn.bounds = (-1000, 1000)\n",
    "    elif rxn.id in ['SK_Asn_X_Ser_Thr_r', 'SK_Tyr_ggn_c', 'SK_Ser_Thr_g', 'SK_pre_prot_r']:\n",
    "        rxn.bounds = (-0.001, 1000)\n",
    "    elif rxn.id.startswith((\"EX_\", \"SK_\", \"DM_\")):\n",
    "        rxn.bounds = (0, 1000)  # Close uptake rates for others\n",
    "\n",
    "for reaction in model.reactions:\n",
    "    if reaction.id == 'EX_etoh_e': #Model creates infeasible solutions when secreting etoh\n",
    "        continue\n",
    "    elif reaction.id == 'ATPM': # Add ATP Maintenance Cost\n",
    "        reaction.lower_bound = 0\n",
    "    for r,v in uptsec_zela.items():\n",
    "        if reaction.id == r:\n",
    "            reaction.upper_bound = 1000\n",
    "            reaction.lower_bound = v[('U6','P2 to P4')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ATP loops removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Thanasis' original version\n",
    "#########################################\n",
    "\n",
    "\n",
    "# Get the maximum flux through the oxidatitve phosphoryaltion pathway. Get the maximum flux of the objectives, biomass and IgG. \n",
    "# If a reaction that consumes ATP (negative stoichiometric coefficient), has a flux value below a cutoff in both maximisation of biomass\n",
    "# IgG and ox. pho. pathway, then the reaction doesn't provide any useable ATP (cyclic)\n",
    "\n",
    "step6_safe_rxn_rmv = []\n",
    "\n",
    "protected_subsystems = [ # Why protecting these subsystems\n",
    "    'BIOMASS', 'Product Formation', 'OXIDATIVE PHOSPHORYLATION', 'CITRIC ACID CYCLE', 'GLYCOLYSIS/GLUCONEOGENESIS',\n",
    "    'PYRUVATE METABOLISM', 'PENTOSE PHOSPHATE PATHWAY', 'GLUTAMATE METABOLISM', 'NAD METABOLISM',\n",
    "    'TRANSPORT, MITOCHONDRIAL', 'TRANSPORT, ENDOPLASMIC RETICULAR', 'ARGININE AND PROLINE METABOLISM',\n",
    "    'UBIQUINONE SYNTHESIS', 'VALINE, LEUCINE, AND ISOLEUCINE METABOLISM', 'TRYPTOPHAN METABOLISM',\n",
    "    'METHIONINE AND CYSTEINE METABOLISM', 'TYROSINE METABOLISM', 'GLYCINE, SERINE, AND THREONINE METABOLISM',\n",
    "    'HISTIDINE METABOLISM', 'ALANINE AND ASPARTATE METABOLISM', 'PHENYLALANINE METABOLISM',\n",
    "    'LYSINE METABOLISM', 'TYROSINE METABOLISM', 'N-GLYCAN BIOSYNTHESIS', 'PROTEIN PRODUCTION', 'SECRETORY PATHWAY'\n",
    "]\n",
    "\n",
    "\n",
    "# biomass and igg reactions of the model; we want to ensure their production after removals of any ATP cycles\n",
    "biomass_rxn = 'biomass_cho_s'\n",
    "igg_rxn = 'igg_formation'\n",
    "\n",
    "model.objective = biomass_rxn\n",
    "biomass_control = model.optimize('maximise')\n",
    "model.objective = igg_rxn\n",
    "igg_control = model.optimize('maximise')\n",
    "print(\"Original: Biomass: \", round(biomass_control.objective_value, 5), \"IgG: \", round(igg_control.objective_value, 5))\n",
    "\n",
    "model_temp = model.copy()\n",
    "atp_related_mets = ['atp_c', 'atp_n', 'atp_m', 'atp_x'] # What about atp_l, atp_g, atp_r, atp_e\n",
    "atp_met_indices = [model_temp.metabolites.get_by_id(met) for met in atp_related_mets]\n",
    "\n",
    "# Find the reactions associated with these metabolites\n",
    "atp_rxns_indices = []\n",
    "for met in atp_met_indices:\n",
    "    for reac in met.reactions:\n",
    "        atp_rxns_indices.append(reac.id)\n",
    "atp_rxns_indices = list(set(atp_rxns_indices))\n",
    "\n",
    "# Determine which reactions are consuming ATP (negative stoichiometry for ATP)\n",
    "atp_consumption_idx = []\n",
    "stoich_matrix = create_stoichiometric_matrix(model_temp)\n",
    "for atp_rxn in atp_rxns_indices:\n",
    "    reaction = model_temp.reactions.get_by_id(atp_rxn)\n",
    "    if not reaction.reversibility:  # Only irreversible reactions\n",
    "        for met in atp_met_indices:\n",
    "            if stoich_matrix[model_temp.metabolites.index(met), model_temp.reactions.index(reaction)] < 0:\n",
    "                atp_consumption_idx.append(atp_rxn)\n",
    "                break\n",
    "\n",
    "# Perform FBA to get maximum ATP production\n",
    "model_temp.objective = 0\n",
    "oxpho_rxns = [r for r in model_temp.reactions if 'OXIDATIVE PHOSPHORYLATION' in r.subsystem]\n",
    "reaction_variables = ((rxn.forward_variable, rxn.reverse_variable) for rxn in oxpho_rxns)\n",
    "variables = chain(*reaction_variables)\n",
    "model_temp.objective = model_temp.problem.Objective( Zero, direction=\"max\", sloppy=True, name=\"maxATP\" )\n",
    "model_temp.objective.set_linear_coefficients({v: 1.0 for v in variables})\n",
    "print(\"objective function\", model_temp.objective.expression)\n",
    "solution_maxATP = model_temp.optimize()\n",
    "\n",
    "for obj in [biomass_rxn, igg_rxn]:\n",
    "    model_temp.objective = obj\n",
    "    sol = model_temp.optimize('maximize')\n",
    "    atp_rate = np.vstack([sol[atp_consumption_idx], solution_maxATP[atp_consumption_idx]])\n",
    "\n",
    "    # Find ATP consuming reactions with low rates\n",
    "    atp_rxn_lowFlux = [id for id, rate in zip(atp_consumption_idx, np.sum(atp_rate, axis=0)) if rate <= 2e-12]\n",
    "\n",
    "    atp_loop_rxn_rmv = []\n",
    "    for rxn in atp_rxn_lowFlux:\n",
    "        if model_temp.reactions.get_by_id(rxn).subsystem not in protected_subsystems:\n",
    "            atp_loop_rxn_rmv.append(rxn)\n",
    "\n",
    "    # Filter out exchange reactions\n",
    "    exchange_reactions = [r.id for r in model_temp.exchanges]\n",
    "    atp_loop_rxn_rmv = [r_id for r_id in atp_loop_rxn_rmv if r_id not in exchange_reactions]\n",
    "\n",
    "    # Ensure ATP maintenance reaction is not deleted\n",
    "    id_atp_maint = model_temp.reactions.get_by_id('ATPM').id\n",
    "    atp_loop_rxn_rmv = [r_id for r_id in atp_loop_rxn_rmv if r_id != id_atp_maint]\n",
    "\n",
    "    if obj == biomass_rxn:\n",
    "        atp_loop_rxns_bio = atp_loop_rxn_rmv\n",
    "    elif obj == igg_rxn:\n",
    "        atp_loop_rxns_igg = atp_loop_rxn_rmv\n",
    "\n",
    "# Print the reactions to be deleted\n",
    "atp_loop_rxns = list(set(atp_loop_rxns_igg).intersection(atp_loop_rxns_bio))\n",
    "print(\"Reactions to be deleted:\", len(atp_loop_rxns))\n",
    "\n",
    "# Remove reactions from the model and check that Biomass and IgG are produced\n",
    "model_temp.objective = biomass_rxn\n",
    "sol_bio_control = model_temp.optimize('maximize')\n",
    "model_temp.objective = igg_rxn\n",
    "sol_igg_control = model_temp.optimize('maximize')\n",
    "model_temp_temp = model_temp.copy()\n",
    "\n",
    "for rxn_to_rmv in atp_loop_rxns:\n",
    "    model_temp_temp.remove_reactions(rxn_to_rmv)\n",
    "    model_temp_temp.objective = biomass_rxn\n",
    "    sol_bio = model_temp_temp.optimize('maximize')\n",
    "    model_temp_temp.objective = igg_rxn\n",
    "    sol_igg = model_temp_temp.optimize('maximize')\n",
    "    if round(sol_bio.objective_value, 5) == round(sol_bio_control.objective_value, 5) and round(sol_igg.objective_value, 5) == round(sol_igg_control.objective_value, 5):\n",
    "        step6_safe_rxn_rmv.append(rxn_to_rmv)\n",
    "\n",
    "model_temp.remove_reactions(step6_safe_rxn_rmv)\n",
    "print(\"Reactions consuming ATP in a cyclic fashion AND are safe to remove: \", len(step6_safe_rxn_rmv))\n",
    "print(\"Model size after the removal of ATP cyclic reactions: Reactions: \", len(model_temp.reactions), \"Metabolites: \", len(model_temp.metabolites))\n",
    "model_temp.objective = biomass_rxn\n",
    "sol_bio = model_temp.optimize('maximize')\n",
    "model_temp.objective = igg_rxn\n",
    "sol_igg = model_temp.optimize('maximize')\n",
    "print(\"Old Bio: \", round(sol_bio_control.objective_value, 3), \"New Bio: \", round(sol_bio.objective_value, 3), \"Old IgG: \", round(sol_igg_control.objective_value, 5), \"New IgG: \", round(sol_igg.objective_value, 5))\n",
    "model = model_temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Pablo's modification\n",
    "#########################################\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_atp_related_reactions(model, atp_mets):\n",
    "    \"\"\" Get reactions associated with ATP and related metabolites like GTP, GDP, etc. \"\"\"\n",
    "    atp_rxns_indices = set()  # Use set to avoid duplicates\n",
    "    for met in atp_mets:\n",
    "        for reac in met.reactions:\n",
    "            if any(x in reac.reactants + reac.products for x in atp_mets):\n",
    "                atp_rxns_indices.add(reac.id)\n",
    "    return list(atp_rxns_indices)\n",
    "\n",
    "def find_low_flux_reactions(model, atp_rxns_indices, atp_met_indices, stoich_matrix, consumption_cutoff=2e-12):\n",
    "    \"\"\" Identify reactions with low ATP or related metabolite consumption flux. \"\"\"\n",
    "    atp_consumption_idx = []\n",
    "    for atp_rxn in atp_rxns_indices:\n",
    "        reaction = model.reactions.get_by_id(atp_rxn)\n",
    "        for met in atp_met_indices:\n",
    "            # Check for both ATP and GTP-related consumption (stoichiometric coefficient < 0)\n",
    "            if stoich_matrix[model.metabolites.index(met), model.reactions.index(reaction)] < 0:\n",
    "                atp_consumption_idx.append(atp_rxn)\n",
    "                break\n",
    "    return atp_consumption_idx\n",
    "\n",
    "def perform_fba_for_max_atp(model, oxpho_rxns):\n",
    "    \"\"\" Set FBA objective to maximize ATP production. \"\"\"\n",
    "    reaction_variables = ((rxn.forward_variable, rxn.reverse_variable) for rxn in oxpho_rxns)\n",
    "    variables = chain(*reaction_variables)\n",
    "    model.objective = model.problem.Objective(Zero, direction=\"max\", sloppy=True, name=\"maxATP\")\n",
    "    model.objective.set_linear_coefficients({v: 1.0 for v in variables})\n",
    "    return model.optimize()\n",
    "\n",
    "def remove_cyclic_atp_reactions(model, atp_rxns_to_remove, biomass_rxn):\n",
    "    \"\"\" Remove reactions consuming ATP in a cyclic fashion and check for safety. \"\"\"\n",
    "    \n",
    "    safe_rxn_irrev = []\n",
    "\n",
    "    # Copy the original model\n",
    "    temp_model = model.copy()\n",
    "\n",
    "    # Set the objective for the temporary model\n",
    "    temp_model.objective = biomass_rxn\n",
    "    sol_bio_control = temp_model.optimize()\n",
    "\n",
    "    # Cumulative list of safe reactions to remove or modify\n",
    "    candidate_safe_rmv = []\n",
    "    candidate_safe_irrev = []\n",
    "\n",
    "    for rxn_id in tqdm(atp_rxns_to_remove, desc=\"Processing reactions\"):\n",
    "        with temp_model:\n",
    "            # Try to make the reaction irreversible\n",
    "            if temp_model.reactions.get_by_id(rxn_id).lower_bound != 0:\n",
    "                temp_model.reactions.get_by_id(rxn_id).bounds = (0, 1000)\n",
    "                sol_bio_temp = temp_model.optimize()\n",
    "                \n",
    "                if (round(sol_bio_temp.objective_value, 5) == round(sol_bio_control.objective_value, 5)):\n",
    "                    candidate_safe_irrev.append(rxn_id)\n",
    "                    \n",
    "                    # Test cumulative effect of all candidate modifications\n",
    "                    for rxn in candidate_safe_irrev:\n",
    "                        temp_model.reactions.get_by_id(rxn).bounds = (0, 1000)\n",
    "                    sol_bio_cumulative = temp_model.optimize()\n",
    "\n",
    "                    # If the cumulative effect is still safe, add to the final modification list\n",
    "                    if round(sol_bio_cumulative.objective_value, 5) == round(sol_bio_control.objective_value, 5):\n",
    "                        safe_rxn_irrev = list(candidate_safe_irrev)\n",
    "                    else:\n",
    "                        # If not safe, undo the last added irreversible modification\n",
    "                        candidate_safe_irrev.remove(rxn_id)\n",
    "                        print(f\"Making {rxn_id} irreversible is not safe, reverting.\")\n",
    "\n",
    "    # Make irreversible reactions that can be safely modified\n",
    "    for rxn in safe_rxn_irrev:\n",
    "        if model.reactions.get_by_id(rxn).lower_bound != 0:\n",
    "            model.reactions.get_by_id(rxn).bounds = (0, 1000)\n",
    "    \n",
    "    return model, safe_rxn_irrev\n",
    "\n",
    "# Set objectives\n",
    "biomass_rxn = 'biomass_cho_s'\n",
    "model.objective = biomass_rxn\n",
    "biomass_control = model.optimize('maximize')\n",
    "\n",
    "# Find ATP related reactions\n",
    "atp_related_mets = ['atp_c', 'atp_n', 'atp_m', 'atp_x', 'atp_l', 'atp_g', 'atp_r', 'atp_e', 'datp_c', 'dadp_c', 'gtp_c', 'gdp_c',\n",
    "                    'utp_c', 'udp_c', 'ctp_c', 'cdp_c', 'ump_c', 'mlthf_c', 'mlthf_m', 'dgtp_c', 'dgdp_c', 'adxrd_c', 'adxrd_m',\n",
    "                    'adxo_2_2_m', 'adxo_2_2_c', 'udpg_c', 'udpgal_c', 'succ_m', 'succoa_m', '4met2obut_c', 'q10h2_m', 'q10_m']\n",
    "atp_met_indices = [model.metabolites.get_by_id(met) for met in atp_related_mets]\n",
    "atp_rxns_indices = get_atp_related_reactions(model, atp_met_indices)\n",
    "\n",
    "# Create stoichiometric matrix\n",
    "stoich_matrix = create_stoichiometric_matrix(model)\n",
    "atp_consumption_idx = find_low_flux_reactions(model, atp_rxns_indices, atp_met_indices, stoich_matrix)\n",
    "\n",
    "# Maximize ATP production\n",
    "oxpho_rxns = [r for r in model.reactions if 'OXIDATIVE PHOSPHORYLATION' in r.subsystem]\n",
    "solution_maxATP = perform_fba_for_max_atp(model, oxpho_rxns)\n",
    "\n",
    "# Check flux of ATP consuming reactions\n",
    "atp_loop_rxn_rmv = []\n",
    "\n",
    "model.objective = biomass_rxn\n",
    "sol = model.optimize('maximize')\n",
    "atp_rate = np.vstack([sol[atp_consumption_idx], solution_maxATP[atp_consumption_idx]])\n",
    "\n",
    "# Find low flux ATP reactions\n",
    "atp_rxn_lowFlux = [rxn_id for rxn_id, rate in zip(atp_consumption_idx, np.sum(atp_rate, axis=0)) if rate <= 2e-12]\n",
    "\n",
    "# Filter protected subsystems and exchanges\n",
    "protected_subsystems = ['BIOMASS', 'OXIDATIVE PHOSPHORYLATION']\n",
    "atp_loop_rxn_rmv += [rxn for rxn in atp_rxn_lowFlux if model.reactions.get_by_id(rxn).subsystem not in protected_subsystems]\n",
    "\n",
    "# Ensure ATPM and exchange reactions are not removed\n",
    "atp_loop_rxn_rmv = [r_id for r_id in atp_loop_rxn_rmv if r_id != 'ATPM' and not r_id.startswith(\"EX_\")]\n",
    "\n",
    "# Remove duplicates in the list\n",
    "atp_loop_rxn_rmv = set(atp_loop_rxn_rmv)\n",
    "\n",
    "# Remove cyclic ATP reactions and check safety\n",
    "pruned_model, safe_rxn_irrev = remove_cyclic_atp_reactions(model, atp_loop_rxn_rmv, biomass_rxn)\n",
    "\n",
    "print(f\"Reactions consuming ATP in a cyclic fashion and safe to make irreversible: {len(safe_rxn_irrev)}\")\n",
    "\n",
    "# Final biomass\n",
    "pruned_model.objective = biomass_rxn\n",
    "sol_bio = pruned_model.optimize('maximize')\n",
    "\n",
    "print(f\"Old Bio: {biomass_control.objective_value:.3f}, New Bio: {sol_bio.objective_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pruned_model as model:\n",
    "    objective = 'biomass_cho_s'\n",
    "    model.objective = objective\n",
    "    '''\n",
    "    model.reactions.SCP22x.knock_out()\n",
    "    model.reactions.TMNDNCCOAtx.knock_out()\n",
    "    model.reactions.OCCOAtx.knock_out()\n",
    "    model.reactions.TMNDNCCOAtx.knock_out()\n",
    "    model.reactions.r0391.knock_out()\n",
    "    model.reactions.BiGGRxn67.knock_out()\n",
    "    model.reactions.r2247.knock_out()\n",
    "    model.reactions.r2280.knock_out()\n",
    "    model.reactions.r2246.knock_out()\n",
    "\n",
    "    \n",
    "    model.reactions.r2279.knock_out()\n",
    "    model.reactions.r2245.knock_out()\n",
    "    model.reactions.r2305.knock_out()\n",
    "    model.reactions.r2317.knock_out()\n",
    "    model.reactions.r2335.knock_out()\n",
    "    model.reactions.HMR_0293.knock_out()\n",
    "    model.reactions.HMR_7741.knock_out()\n",
    "    model.reactions.r0509.knock_out()\n",
    "    model.reactions.r1453.knock_out()\n",
    "    model.reactions.HMR_4343.knock_out()\n",
    "\n",
    "    \n",
    "    model.reactions.ACONTm.knock_out()\n",
    "    model.reactions.PDHm.knock_out()\n",
    "    model.reactions.r0426.knock_out()\n",
    "    model.reactions.r0383.knock_out()\n",
    "    model.reactions.r0555.knock_out()\n",
    "    model.reactions.r1393.knock_out()\n",
    "    model.reactions.NICRNS.knock_out()\n",
    "    model.reactions.get_by_id('GAUGE-R00648').knock_out()\n",
    "    model.reactions.get_by_id('GAUGE-R03326').knock_out()\n",
    "    model.reactions.get_by_id('GapFill-R08726').knock_out()\n",
    "\n",
    "    \n",
    "    model.reactions.RE2915M.knock_out()\n",
    "    model.reactions.HMR_3288.knock_out()\n",
    "    model.reactions.HMR_1325.knock_out()\n",
    "    model.reactions.HMR_7599.knock_out()\n",
    "    model.reactions.r1431.knock_out()\n",
    "    model.reactions.r1433.knock_out()\n",
    "    model.reactions.RE2439C.knock_out()\n",
    "    model.reactions.r0082.knock_out()\n",
    "    model.reactions.r0791.knock_out()\n",
    "    model.reactions.r1450.knock_out()\n",
    "\n",
    "    \n",
    "    model.reactions.get_by_id('GAUGE-R00270').knock_out()\n",
    "    model.reactions.get_by_id('GAUGE-R02285').knock_out()\n",
    "    model.reactions.get_by_id('GAUGE-R04283').knock_out()\n",
    "    model.reactions.get_by_id('GAUGE-R06127').knock_out()\n",
    "    model.reactions.get_by_id('GAUGE-R06128').knock_out()\n",
    "    model.reactions.get_by_id('GAUGE-R06238').knock_out()\n",
    "    model.reactions.get_by_id('GAUGE-R00524').knock_out()\n",
    "    model.reactions.RE3477C.knock_out()\n",
    "\n",
    "    model.reactions.AAPSAS.knock_out()\n",
    "    model.reactions.RE3347C.knock_out()\n",
    "    model.reactions.HMR_0960.knock_out()\n",
    "    model.reactions.HMR_0980.knock_out()\n",
    "    model.reactions.RE3476C.knock_out()\n",
    "    model.reactions.r0708.knock_out()\n",
    "    model.reactions.r0777.knock_out()\n",
    "    model.reactions.r0084.knock_out()\n",
    "    model.reactions.r0424.knock_out()\n",
    "    model.reactions.r0698.knock_out()\n",
    "\n",
    "    model.reactions.get_by_id('3HDH260p').knock_out()\n",
    "    model.reactions.HMR_3272.knock_out()\n",
    "    model.reactions.ACOAD183n3m.knock_out()\n",
    "    model.reactions.HMR_1996.knock_out()\n",
    "    model.reactions.get_by_id('GapFill-R01463').knock_out()\n",
    "    model.reactions.get_by_id('GapFill-R04807').knock_out()\n",
    "    model.reactions.r1468.knock_out()\n",
    "    model.reactions.r2435.knock_out()\n",
    "    model.reactions.r0655.knock_out()\n",
    "    model.reactions.r0603.knock_out()\n",
    "\n",
    "    model.reactions.r0541.knock_out()\n",
    "    model.reactions.RE0383C.knock_out()\n",
    "    model.reactions.HMR_1329.knock_out()\n",
    "    model.reactions.TYRA.knock_out()\n",
    "    model.reactions.NRPPHRt_2H.knock_out()\n",
    "    model.reactions.get_by_id('GAUGE-R07364').knock_out()\n",
    "    model.reactions.get_by_id('GapFill-R03599').knock_out()\n",
    "    model.reactions.ARD.knock_out()\n",
    "    model.reactions.RE3095C.knock_out()\n",
    "    model.reactions.RE3104C.knock_out()\n",
    "    model.reactions.RE3104R.knock_out()\n",
    "\n",
    "    model.reactions.ACONT.knock_out()\n",
    "    model.reactions.ACONTm.knock_out()\n",
    "    model.reactions.ICDHxm.knock_out()\n",
    "    model.reactions.ICDHy.knock_out()\n",
    "    model.reactions.AKGDm.knock_out()\n",
    "    model.reactions.r0083.knock_out()\n",
    "    model.reactions.r0425.knock_out()\n",
    "    model.reactions.r0556.knock_out()\n",
    "    model.reactions.NH4t4r.knock_out()\n",
    "    model.reactions.PROPAT4te.knock_out()\n",
    "    \n",
    "    model.reactions.r0085.knock_out()\n",
    "    model.reactions.r0156.knock_out()\n",
    "    model.reactions.r0464.knock_out()\n",
    "    model.reactions.ABUTDm.knock_out()\n",
    "    model.reactions.OIVD1m.knock_out()\n",
    "    model.reactions.OIVD2m.knock_out()\n",
    "    model.reactions.OIVD3m.knock_out()\n",
    "    model.reactions.r2194.knock_out()\n",
    "    model.reactions.r2202.knock_out()\n",
    "    model.reactions.HMR_9617.knock_out()\n",
    "\n",
    "    model.reactions.r2197.knock_out()\n",
    "    model.reactions.r2195.knock_out()\n",
    "    model.reactions.get_by_id('2OXOADOXm').knock_out()\n",
    "    model.reactions.r2328.knock_out()\n",
    "    model.reactions.r0386.knock_out()\n",
    "    model.reactions.r0451.knock_out()\n",
    "    model.reactions.FAS100COA.knock_out()\n",
    "    model.reactions.FAS120COA.knock_out()\n",
    "    model.reactions.FAS140COA.knock_out()\n",
    "    model.reactions.FAS80COA_L.knock_out()\n",
    "\n",
    "    model.reactions.r0604.knock_out()\n",
    "    model.reactions.r0670.knock_out()\n",
    "    model.reactions.r2334.knock_out()\n",
    "    model.reactions.r0193.knock_out()\n",
    "    model.reactions.r0595.knock_out()\n",
    "    model.reactions.r0795.knock_out()\n",
    "    model.reactions.GLYCLm.knock_out()\n",
    "    model.reactions.MACACI.knock_out()\n",
    "    model.reactions.r2193.knock_out()\n",
    "    model.reactions.r0779.knock_out()\n",
    "    model.reactions.r0669.knock_out()\n",
    "    model.reactions.UDCHOLt.knock_out()\n",
    "    model.reactions.r2146.knock_out()\n",
    "    model.reactions.r2139.knock_out()\n",
    "    model.reactions.r0391.knock_out()\n",
    "    '''\n",
    "    for rxn in model.boundary:\n",
    "        if rxn.id in ['EX_h2o_e', 'EX_h_e', 'EX_o2_e', 'EX_hco3_e', 'EX_so4_e', 'EX_pi_e']:\n",
    "            rxn.bounds = (-1000, 1000)\n",
    "        elif rxn.id in ['SK_Asn_X_Ser_Thr_r', 'SK_Tyr_ggn_c', 'SK_Ser_Thr_g', 'SK_pre_prot_r']:\n",
    "            rxn.bounds = (-0.001, 1000)\n",
    "        elif rxn.id.startswith((\"EX_\", \"SK_\", \"DM_\")):\n",
    "            rxn.bounds = (0, 1000)  # Close uptake rates for others\n",
    "\n",
    "    for reaction in model.reactions:\n",
    "        if reaction.id == 'EX_etoh_e': #Model creates infeasible solutions when secreting etoh\n",
    "            continue\n",
    "        elif reaction.id == 'ATPM': # Add ATP Maintenance Cost\n",
    "            reaction.lower_bound = 1000\n",
    "        for r,v in uptsec_zela.items():\n",
    "            if reaction.id == r:\n",
    "                reaction.upper_bound = 1000\n",
    "                reaction.lower_bound = v[('U7','P2 to P4')]\n",
    "    pfba_solution = cobra.flux_analysis.pfba(model)\n",
    "    pfba_obj = pfba_solution.fluxes[objective]\n",
    "    pfba_atp = pfba_solution.fluxes['ATPM']\n",
    "    print(f'Simulated ATP Maintencance is: {pfba_atp}')\n",
    "    print(f'Simulated growth rate is: {pfba_obj}')\n",
    "    \n",
    "    for i,f in pfba_solution.fluxes.items():\n",
    "        if abs(f) > 1:\n",
    "            print(i,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Biomass prediction using exp. data <a id='biomass'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import cobra\n",
    "from cobra import Reaction\n",
    "from cobra.io import load_json_model, read_sbml_model, load_matlab_model\n",
    "from cobra.exceptions import Infeasible\n",
    "from cobra.sampling import ACHRSampler\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing context-specific models models\n",
    "model_directory = '../Data/Context_specific_models/'\n",
    "\n",
    "# Model Names\n",
    "wt_model_names = ['WT_P4_Bio141', 'WT_P4_Bio142', 'WT_P4_Bio143',\n",
    "                  'WT_P6_Bio141', 'WT_P6_Bio142', 'WT_P6_Bio143']\n",
    "\n",
    "zela_model_names = ['ZeLa_P2_Bio145', 'ZeLa_P2_Bio146', 'ZeLa_P2_Bio147', 'ZeLa_P2_Bio148',\n",
    "                    'ZeLa_P4_Bio144', 'ZeLa_P4_Bio145', 'ZeLa_P4_Bio146', 'ZeLa_P4_Bio147', 'ZeLa_P4_Bio148',\n",
    "                    'ZeLa_P6_Bio144', 'ZeLa_P6_Bio146', 'ZeLa_P6_Bio147', 'ZeLa_P6_Bio148',\n",
    "                    'ZeLa_P8_Bio144', 'ZeLa_P8_Bio145', 'ZeLa_P8_Bio146', 'ZeLa_P8_Bio147', 'ZeLa_P8_Bio148']\n",
    "\n",
    "# Dictionaries to store the loaded models\n",
    "wt_models = {}\n",
    "zela_models = {}\n",
    "\n",
    "# List all .mat files in the directory\n",
    "model_files = [f for f in os.listdir(model_directory) if f.endswith('.mat')]\n",
    "\n",
    "# Iterate through the .mat files and load only the models that match predefined strings\n",
    "for model_file in model_files:\n",
    "    # Full path to the model file\n",
    "    model_path = os.path.join(model_directory, model_file)\n",
    "    \n",
    "    # Check if the file corresponds to a WT model\n",
    "    for model_name in wt_model_names:\n",
    "        if model_name in model_file:\n",
    "            wt_models[model_name] = load_matlab_model(model_path)\n",
    "            wt_models[model_name].id = model_name\n",
    "            print(f\"Loaded WT model: {model_name}\")\n",
    "            break  # Stop checking other names since this file is already processed\n",
    "    \n",
    "    # Check if the file corresponds to a ZeLa model\n",
    "    for model_name in zela_model_names:\n",
    "        if model_name in model_file:\n",
    "            zela_models[model_name] = load_matlab_model(model_path)\n",
    "            zela_models[model_name].id = model_name\n",
    "            print(f\"Loaded ZeLa model: {model_name}\")\n",
    "            break  # Stop checking other names since this file is already processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATP loop generating reactions\n",
    "\n",
    "atp_reactions_list = [\n",
    "    'SCP22x', 'TMNDNCCOAtx', 'OCCOAtx', 'r0391', 'BiGGRxn67', 'r2247', 'r2280', 'r2246', 'r2279', 'r2245', \n",
    "    'r2305', 'r2317', 'r2335', 'HMR_0293', 'HMR_7741', 'r0509', 'r1453', 'HMR_4343', 'ACONTm', 'PDHm', \n",
    "    'r0426', 'r0383', 'r0555', 'r1393', 'NICRNS', 'GAUGE-R00648', 'GapFill-R08726', \n",
    "    'RE2915M', 'HMR_3288', 'HMR_1325', 'HMR_7599', 'r1431', 'r1433', 'RE2439C', 'r0082', 'r0791', 'r1450', \n",
    "    'GAUGE-R00270', 'GAUGE-R02285', 'GAUGE-R04283', 'GAUGE-R06127', 'GAUGE-R06128', 'GAUGE-R06238', \n",
    "    'GAUGE-R00524', 'GAUGE-R03326', 'RE3477C', 'AAPSAS', 'RE3347C', 'HMR_0960', 'HMR_0980', 'RE3476C', \n",
    "    'r0708', 'r0777', 'r0084', 'r0424', 'r0698', '3HDH260p', 'HMR_3272', 'ACOAD183n3m', 'HMR_1996', \n",
    "    'GapFill-R01463', 'GapFill-R04807', 'r1468', 'r2435', 'r0655', 'r0603', 'r0541', 'RE0383C', 'HMR_1329', \n",
    "    'TYRA', 'NRPPHRt_2H', 'GAUGE-R07364', 'GapFill-R03599', 'ARD', 'RE3095C', 'RE3104C', 'RE3104R', 'ACONT', \n",
    "    'ACONTm', 'ICDHxm', 'ICDHy', 'AKGDm', 'r0083', 'r0425', 'r0556', 'NH4t4r', 'PROPAT4te', 'r0085', \n",
    "    'r0156', 'r0464', 'ABUTDm', 'OIVD1m', 'OIVD2m', 'OIVD3m', 'r2194', 'r2202', 'HMR_9617', 'r2197', \n",
    "    'r2195', '2OXOADOXm', 'r2328', 'r0386', 'r0451', 'FAS100COA', 'FAS120COA', 'FAS140COA', 'FAS80COA_L', \n",
    "    'r0604', 'r0670', 'r2334', 'r0193', 'r0595', 'r0795', 'GLYCLm', 'MACACI', 'r2193', 'r0779', 'r0669', \n",
    "    'UDCHOLt', 'r2146', 'r2139'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load uptake and secretion rate dict\n",
    "\n",
    "with open('../Data/Uptake_Secretion_Rates/uptake_secretion_raw_wt_dict.pkl', 'rb') as file:\n",
    "    uptsec_wt = pickle.load(file)\n",
    "\n",
    "with open('../Data/Uptake_Secretion_Rates/uptake_secretion_raw_zela_dict.pkl', 'rb') as file:\n",
    "    uptsec_zela = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sanity Check. Make sure all the exchange reactions in the experimental data are present in the model and that the models ar growing\n",
    "\n",
    "for name,model in zela_models.items():\n",
    "    print('---------------------------------------')\n",
    "    print(f'------------{model.id}------------')\n",
    "    print('')\n",
    "    print(f'Objective:{model.objective}')\n",
    "    print('')\n",
    "    print(f'GR1: {model.slim_optimize()}')\n",
    "    exchanges = list(uptsec_wt.keys())\n",
    "    \n",
    "    model_ex = [r.id for r in model.boundary]\n",
    "    model_reactions = [r.id for r in model.reactions]\n",
    "    \n",
    "    # Remove ATP loop reactions\n",
    "    for atp_reaction in atp_reactions_list:\n",
    "        if atp_reaction in model_reactions:\n",
    "            # Knock out the reaction temporarily\n",
    "            reaction = model.reactions.get_by_id(atp_reaction)\n",
    "            original_bounds = reaction.bounds  # Store the original bounds to revert later\n",
    "            reaction.knock_out()\n",
    "            \n",
    "            # Test if the model remains feasible after knocking out the reaction\n",
    "            try:\n",
    "                new_gr = model.slim_optimize()\n",
    "                print(f'GR2 (After knocking out {atp_reaction}): {new_gr}')\n",
    "                \n",
    "                # Check if the model's growth rate is infeasible or close to zero\n",
    "                if math.isnan(new_gr) or new_gr < 1e-6:\n",
    "                    print(f'{atp_reaction} causes infeasibility. Reverting knockout.')\n",
    "                    reaction.bounds = original_bounds  # Revert the bounds if infeasible\n",
    "                else:\n",
    "                    print(f'{atp_reaction} successfully knocked out without infeasibility.')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'Error optimizing model after knocking out {atp_reaction}: {e}')\n",
    "                # Revert the reaction bounds if an error occurs\n",
    "                reaction.bounds = original_bounds\n",
    "\n",
    "    print('')\n",
    "    print('Missing reactions from exp data:')\n",
    "    for ex in exchanges:\n",
    "        if ex not in model_ex:\n",
    "            print(ex)\n",
    "    print('---------------------------------------')\n",
    "    print('---------------------------------------')\n",
    "    print('')\n",
    "    print('')\n",
    "\n",
    "\n",
    "for name,model in wt_models.items():\n",
    "    print('---------------------------------------')\n",
    "    print(f'------------{model.id}------------')\n",
    "    print('')\n",
    "    print(f'Objective:{model.objective}')\n",
    "    print('---------------------------------------')\n",
    "    print(f'GR: {model.slim_optimize()}')\n",
    "    exchanges = list(uptsec_wt.keys())\n",
    "    model_ex = [r.id for r in model.boundary]\n",
    "    model_reactions = [r.id for r in model.reactions]\n",
    "    \n",
    "    # Remove ATP loop reactions\n",
    "    for atp_reaction in atp_reactions_list:\n",
    "        if atp_reaction in model_reactions:\n",
    "            # Knock out the reaction temporarily\n",
    "            reaction = model.reactions.get_by_id(atp_reaction)\n",
    "            original_bounds = reaction.bounds  # Store the original bounds to revert later\n",
    "            reaction.knock_out()\n",
    "            \n",
    "            # Test if the model remains feasible after knocking out the reaction\n",
    "            try:\n",
    "                new_gr = model.slim_optimize()\n",
    "                print(f'GR2 (After knocking out {atp_reaction}): {new_gr}')\n",
    "                \n",
    "                # Check if the model's growth rate is infeasible or close to zero\n",
    "                if math.isnan(new_gr) or new_gr < 1e-6:\n",
    "                    print(f'{atp_reaction} causes infeasibility. Reverting knockout.')\n",
    "                    reaction.bounds = original_bounds  # Revert the bounds if infeasible\n",
    "                else:\n",
    "                    print(f'{atp_reaction} successfully knocked out without infeasibility.')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'Error optimizing model after knocking out {atp_reaction}: {e}')\n",
    "                # Revert the reaction bounds if an error occurs\n",
    "                reaction.bounds = original_bounds\n",
    "\n",
    "    \n",
    "    for ex in exchanges:\n",
    "        if ex not in model_ex:\n",
    "            print(ex)\n",
    "    print('---------------------------------------')\n",
    "    print('---------------------------------------')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfba_solutions_fluxes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WT\n",
    "\n",
    "results = []\n",
    "\n",
    "objective = 'biomass_cho_s'\n",
    "\n",
    "# Adjust the lower bound values according to the experimental growth rates in order to indetify bottlenecks\n",
    "intervals = {'P0 to P2':'P2', 'P2 to P4':'P4', 'P4 to P6':'P6', 'P6 to P8':'P8', 'P8 to P12':'P12', 'P12 to P14':'P14'}\n",
    "replicates = {'U1':'Bio141', 'U2':'Bio142', 'U3':'Bio143'}\n",
    "\n",
    "for name,model in wt_models.items():\n",
    "    print(f\"Processing model: {name}\")\n",
    "    # Set lower bounds of the reactions according to the experimental data\n",
    "    for interval_key, interval_model_time in intervals.items():\n",
    "        if interval_model_time in name:  # Match model name with interval\n",
    "            for rep_key, rep_suffix in replicates.items():\n",
    "                if rep_suffix in name:  # Match replicate with model name\n",
    "\n",
    "                     with model as modified_model:\n",
    "\n",
    "                        # Open the bounds for the biomass reaction \n",
    "                        modified_model.reactions.biomass_cho_s.bounds = (0,1000)\n",
    "                         \n",
    "                        # Create a copy of the modified_model before making changes\n",
    "                        pre_modification_model = modified_model.copy()\n",
    "                         \n",
    "                        for rxn in modified_model.boundary:\n",
    "                            # Keep boundaries open for essential metabolites\n",
    "                            if rxn.id in ['EX_h2o_e', 'EX_h_e', 'EX_o2_e', 'EX_hco3_e', 'EX_so4_e', 'EX_pi_e']:\n",
    "                                rxn.bounds = (-1000, 1000)\n",
    "                            elif rxn.id in ['SK_Asn_X_Ser_Thr_r', 'SK_Tyr_ggn_c', 'SK_Ser_Thr_g', 'SK_pre_prot_r']:\n",
    "                                rxn.bounds = (-0.001, 1000)\n",
    "                            elif rxn.id.startswith((\"EX_\", \"SK_\", \"DM_\")):\n",
    "                                rxn.bounds = (0, 1000)  # Close uptake rates for others\n",
    "                        \n",
    "                        print(f'Calculating Growth Rate for WT Condition:{rep_key,interval_key}')\n",
    "                        exp_gr = uptsec_wt['exp_growth_rate'][(rep_key,interval_key)]\n",
    "                        print(f'Experimental growth rate is: {exp_gr}')\n",
    "                        for reaction in modified_model.reactions:\n",
    "                            if reaction.id == 'EX_etoh_e': #Model creates infeasible solutions when secreting etoh\n",
    "                                continue\n",
    "                            elif reaction.id == 'ATPM': # Add ATP Maintenance Cost\n",
    "                                reaction.lower_bound = 8\n",
    "                            for r,v in uptsec_wt.items():\n",
    "                                if reaction.id == r:\n",
    "                                    reaction.upper_bound = 1000\n",
    "                                    reaction.lower_bound = v[(rep_key,interval_key)]\n",
    "                                    \n",
    "                        try:\n",
    "                            pfba_solution = cobra.flux_analysis.pfba(modified_model)\n",
    "                            pfba_obj = pfba_solution.fluxes[objective]\n",
    "                            pfba_atp = pfba_solution.fluxes['ATPM']\n",
    "                            print(f'Simulated ATP Maintencance is: {pfba_atp}')\n",
    "                            print(f'Simulated growth rate is: {pfba_obj}')\n",
    "            \n",
    "                            # If pFBA succeeds, proceed to sampling\n",
    "                            pfba_model_to_sample = modified_model\n",
    "                            \n",
    "                        except Infeasible:\n",
    "                            print(f'Infeasible solution for replicate {rep_key} interval {interval_key}')\n",
    "                            print('Reverting to the original model and retrying pFBA...')\n",
    "\n",
    "                            for rxn in pre_modification_model.boundary:\n",
    "                            # Keep boundaries open for essential metabolites\n",
    "                                if rxn.id in ['EX_h2o_e', 'EX_h_e', 'EX_o2_e', 'EX_hco3_e', 'EX_so4_e', 'EX_pi_e']:\n",
    "                                    rxn.bounds = (-1000, 1000)\n",
    "                                elif rxn.id in ['SK_Asn_X_Ser_Thr_r', 'SK_Tyr_ggn_c', 'SK_Ser_Thr_g', 'SK_pre_prot_r']:\n",
    "                                    rxn.bounds = (-0.001, 1000)\n",
    "                            \n",
    "                            pfba_solution = cobra.flux_analysis.pfba(pre_modification_model)\n",
    "                            pfba_obj = pfba_solution.fluxes[objective]\n",
    "                            pfba_atp = pfba_solution.fluxes['ATPM']\n",
    "                            print(f'Simulated ATP Maintencance is: {pfba_atp}')\n",
    "                            print(f'Simulated growth rate with original model is: {pfba_obj}')\n",
    "\n",
    "                            # If pFBA with original model succeeds, proceed to sampling\n",
    "                            pfba_model_to_sample = pre_modification_model\n",
    "\n",
    "                        results.append([rep_suffix, interval_key, exp_gr, pfba_obj])\n",
    "                        # Save the solution with metadata\n",
    "                        pfba_solutions_fluxes.append({\n",
    "                            \"model\": pre_modification_model.id,\n",
    "                            \"condition\": interval_key,\n",
    "                            \"fluxes\": pfba_solution.fluxes\n",
    "                        })\n",
    "\n",
    "                        \n",
    "                         # Perform flux sampling using ACHRSampler\n",
    "                        #print(\"Performing flux sampling...\")\n",
    "                        #achr_sampler = ACHRSampler(pfba_model_to_sample)\n",
    "                        #samples = 5000 \n",
    "                        #sampled_fluxes = achr_sampler.sample(samples)\n",
    "                        \n",
    "                        # Validate and save the sampled fluxes\n",
    "                        #if 'v' not in achr_sampler.validate(sampled_fluxes).flatten():\n",
    "                        #    print(f\"Error in sampling for {rep_key}, {interval_key}\")\n",
    "                        #else:\n",
    "                        #    f_name = f\"../Simulations/flux_sampling/Sampling_{name}_{samples}.pkl\"\n",
    "                        #    with open(f_name, 'wb') as file:\n",
    "                        #        pickle.dump(sampled_fluxes, file)\n",
    "                        \n",
    "# Creating a DataFrame\n",
    "df_wt = pd.DataFrame(results, columns=['Hue', 'Category', 'X Axis', 'Y Axis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df_wt\n",
    "# Define markers for categories\n",
    "markers = {\n",
    "    'P0 to P2': 'p',  # Circle\n",
    "    'P2 to P4': 'o',  # Circle\n",
    "    'P4 to P6': 's',   # Square\n",
    "}\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each group with different colors for hue and different shapes for categories\n",
    "hues = df['Hue'].unique()\n",
    "colors = plt.colormaps.get_cmap('tab10')\n",
    "\n",
    "for hue_idx, hue in enumerate(hues):\n",
    "    hue_subset = df[df['Hue'] == hue]\n",
    "    for category, marker in markers.items():\n",
    "        subset = hue_subset[hue_subset['Category'] == category]\n",
    "        plt.scatter(subset['X Axis'], subset['Y Axis'], label=f'{hue} - {category}', marker=marker, s=100, color=colors(hue_idx))\n",
    "\n",
    "# Add the identity line y = x\n",
    "plt.plot([0.00, 0.055], [0.00, 0.055], color='red', linestyle='--')\n",
    "\n",
    "# Set evenly distributed ticks from 0.01 to 0.08\n",
    "ticks = [i / 100.0 for i in range(1, 11)]\n",
    "plt.xticks(ticks=ticks, labels=[f'{i/100.0:.2f}' for i in range(1, 11)])\n",
    "plt.yticks(ticks=ticks, labels=[f'{i/100.0:.2f}' for i in range(1, 11)])\n",
    "\n",
    "# Set limits for both axes\n",
    "plt.xlim(0.0, 0.055)\n",
    "plt.ylim(0.0, 0.055)\n",
    "\n",
    "# Setting the same scale for both axes\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Experimental Growth Rate')\n",
    "plt.ylabel('Simulated Growth Rate')\n",
    "plt.title('WT')\n",
    "plt.legend(title='Hue - Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('../Simulations/growth_rate_pred/bar_plot_growth_rate_wt.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZeLa\n",
    "\n",
    "results = []\n",
    "\n",
    "objective = 'biomass_cho_s'\n",
    "\n",
    "# Adjust the lower bound values according to the experimental growth rates in order to indetify bottlenecks\n",
    "intervals = {'P0 to P2':'P2', 'P2 to P4':'P4', 'P4 to P6':'P6', 'P6 to P8':'P8', 'P8 to P12':'P12', 'P12 to P14':'P14'}\n",
    "replicates = {'U4':'Bio144', 'U5':'Bio145', 'U6':'Bio146', 'U7':'Bio147', 'U8':'Bio148'}\n",
    "\n",
    "for name,model in zela_models.items():\n",
    "    print(f\"Processing model: {name}\")\n",
    "    # Set lower bounds of the reactions according to the experimental data\n",
    "    for interval_key, interval_model_time in intervals.items():\n",
    "        if interval_model_time in name:  # Match model name with interval\n",
    "            for rep_key, rep_suffix in replicates.items():\n",
    "                if rep_suffix in name:  # Match replicate with model name\n",
    "                    \n",
    "                     with model as modified_model:\n",
    "\n",
    "                        # Open the bounds for the biomass reaction \n",
    "                        modified_model.reactions.biomass_cho_s.bounds = (0,1000)\n",
    "                         \n",
    "                        # Create a copy of the modified_model before making changes\n",
    "                        pre_modification_model = modified_model.copy()\n",
    " \n",
    "                        for rxn in modified_model.boundary:\n",
    "                            if rxn.id in ['EX_h2o_e', 'EX_h_e', 'EX_o2_e', 'EX_hco3_e', 'EX_so4_e', 'EX_pi_e']:\n",
    "                                rxn.bounds = (-1000, 1000)\n",
    "                            elif rxn.id in ['SK_Asn_X_Ser_Thr_r', 'SK_Tyr_ggn_c', 'SK_Ser_Thr_g', 'SK_pre_prot_r']:\n",
    "                                rxn.bounds = (-0.001, 1000)\n",
    "                            elif rxn.id.startswith((\"EX_\", \"SK_\", \"DM_\")):\n",
    "                                rxn.bounds = (0, 1000)  # Close uptake rates for others\n",
    "\n",
    "                        print(f'Calculating Growth Rate for ZeLa Condition:{rep_key,interval_key}')\n",
    "                        exp_gr = uptsec_zela['exp_growth_rate'][(rep_key,interval_key)]\n",
    "                        print(f'Experimental growth rate is: {exp_gr}')\n",
    "                        for reaction in modified_model.reactions:\n",
    "                            if reaction.id == 'EX_etoh_e': #Model creates infeasible solutions when secreting etoh\n",
    "                                continue\n",
    "                            elif reaction.id == 'ATPM': # Add ATP Maintenance Cost\n",
    "                                reaction.lower_bound = 8\n",
    "                            for r,v in uptsec_zela.items():\n",
    "                                if reaction.id == r:\n",
    "                                    reaction.upper_bound = 1000\n",
    "                                    reaction.lower_bound = v[(rep_key,interval_key)]\n",
    "                                    \n",
    "                        try:\n",
    "                            pfba_solution = cobra.flux_analysis.pfba(modified_model)\n",
    "                            pfba_obj = pfba_solution.fluxes[objective]\n",
    "                            pfba_atp = pfba_solution.fluxes['ATPM']\n",
    "                            print(f'Simulated ATP Maintencance is: {pfba_atp}')\n",
    "                            print(f'Simulated growth rate is: {pfba_obj}')\n",
    "                            \n",
    "                        except Infeasible:\n",
    "                            print(f'Infeasible solution for replicate {rep_key} interval {interval_key}')\n",
    "                            print('Reverting to the original model and retrying pFBA...')\n",
    "\n",
    "                            for rxn in pre_modification_model.reactions:\n",
    "                                if rxn.id in ['EX_h2o_e', 'EX_h_e', 'EX_o2_e', 'EX_hco3_e', 'EX_so4_e', 'EX_pi_e']:\n",
    "                                    rxn.bounds = (-1000, 1000)\n",
    "                                elif rxn.id in ['SK_Asn_X_Ser_Thr_r', 'SK_Tyr_ggn_c', 'SK_Ser_Thr_g', 'SK_pre_prot_r']:\n",
    "                                    rxn.bounds = (-0.001, 1000)\n",
    "                                elif rxn.id == 'ATPM': # Add ATP Maintenance Cost\n",
    "                                    rxn.lower_bound = 8\n",
    "                                \n",
    "                            pfba_solution = cobra.flux_analysis.pfba(pre_modification_model)\n",
    "                            pfba_obj = pfba_solution.fluxes[objective]\n",
    "                            pfba_atp = pfba_solution.fluxes['ATPM']\n",
    "                            print(f'Simulated ATP Maintencance is: {pfba_atp}')\n",
    "                            print(f'Simulated growth rate with original model is: {pfba_obj}')\n",
    "                            \n",
    "                        results.append([rep_suffix, interval_key, exp_gr, pfba_obj])\n",
    "\n",
    "                        # Save the solution with metadata\n",
    "                        pfba_solutions_fluxes.append({\n",
    "                            \"model\": pre_modification_model.id,\n",
    "                            \"condition\": interval_key,\n",
    "                            \"fluxes\": pfba_solution.fluxes\n",
    "                        })\n",
    "                         \n",
    "                        '''\n",
    "                        # Perform flux sampling using ACHRSampler\n",
    "                        print(\"Performing flux sampling...\")\n",
    "                        achr_sampler = ACHRSampler(pfba_model_to_sample)\n",
    "                        samples = 1 \n",
    "                        sampled_fluxes = achr_sampler.sample(samples)\n",
    "                        \n",
    "                        # Validate and save the sampled fluxes\n",
    "                        if 'v' not in achr_sampler.validate(sampled_fluxes).flatten():\n",
    "                            print(f\"Error in sampling for {rep_key}, {interval_key}\")\n",
    "                        else:\n",
    "                            f_name = f\"../Simulations/flux_sampling/Sampling_{name}_{samples}.pkl\"\n",
    "                            with open(f_name, 'wb') as file:\n",
    "                                pickle.dump(sampled_fluxes, file)\n",
    "                        '''\n",
    "    \n",
    "# Creating a DataFrame\n",
    "df_zela = pd.DataFrame(results, columns=['Hue', 'Category', 'X Axis', 'Y Axis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df_zela\n",
    "# Define markers for categories\n",
    "markers = {\n",
    "    'P0 to P2': 'p',\n",
    "    'P2 to P4': 'o',  # Circle\n",
    "    'P4 to P6': 's',   # Square\n",
    "    'P6 to P8': 'v',\n",
    "}\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each group with different colors for hue and different shapes for categories\n",
    "hues = df['Hue'].unique()\n",
    "colors = plt.colormaps.get_cmap('tab10')\n",
    "\n",
    "for hue_idx, hue in enumerate(hues):\n",
    "    hue_subset = df[df['Hue'] == hue]\n",
    "    for category, marker in markers.items():\n",
    "        subset = hue_subset[hue_subset['Category'] == category]\n",
    "        plt.scatter(subset['X Axis'], subset['Y Axis'], label=f'{hue} - {category}', marker=marker, s=100, color=colors(hue_idx))\n",
    "\n",
    "# Add the identity line y = x\n",
    "plt.plot([0.00, 0.055], [0.00, 0.055], color='red', linestyle='--')\n",
    "\n",
    "# Set evenly distributed ticks from 0.01 to 0.08\n",
    "ticks = [i / 100.0 for i in range(1,11)]\n",
    "plt.xticks(ticks=ticks, labels=[f'{i/100.0:.2f}' for i in range(1, 11)])\n",
    "plt.yticks(ticks=ticks, labels=[f'{i/100.0:.2f}' for i in range(1, 11)])\n",
    "\n",
    "# Set limits for both axes\n",
    "plt.xlim(0.0, 0.055)\n",
    "plt.ylim(0.0, 0.055)\n",
    "\n",
    "# Setting the same scale for both axes\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Experimental Growth Rate')\n",
    "plt.ylabel('Simulated Growth Rate')\n",
    "plt.title('ZeLa')\n",
    "plt.legend(title='Hue - Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('../Simulations/growth_rate_pred/bar_plot_growth_rate_zela.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for reaction, values in uptsec_zela.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Organize data for plotting\n",
    "    batches = sorted(set(k[0] for k in values.keys()))\n",
    "    timepoints = ['P0 to P2', 'P2 to P4', 'P4 to P6', 'P6 to P8', 'P8 to P12', 'P12 to P14']\n",
    "    \n",
    "    for batch in batches:\n",
    "        batch_data = [values.get((batch, tp), 0) for tp in timepoints]\n",
    "        plt.plot(timepoints, batch_data, marker='o', label=batch)\n",
    "    \n",
    "    plt.title(f'Changes in {reaction} over time')\n",
    "    plt.xlabel('Timepoints')\n",
    "    plt.ylabel('Values')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for reaction, values in uptsec_wt.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Organize data for plotting\n",
    "    batches = sorted(set(k[0] for k in values.keys()))\n",
    "    timepoints = ['P0 to P2', 'P2 to P4', 'P4 to P6', 'P6 to P8', 'P8 to P12', 'P12 to P14']\n",
    "    \n",
    "    for batch in batches:\n",
    "        batch_data = [values.get((batch, tp), 0) for tp in timepoints]\n",
    "        plt.plot(timepoints, batch_data, marker='o', label=batch)\n",
    "    \n",
    "    plt.title(f'Changes in {reaction} over time')\n",
    "    plt.xlabel('Timepoints')\n",
    "    plt.ylabel('Values')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Flux Enrichment Analysis <a id='fea'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1\n",
    "# Use the fluxes from the growth rate calculations to filter reactions with fluxes\n",
    "# Define a cut off for the flux ??? # Plot to visualization of the flux distribution\n",
    "# Run Flux Enrichment Analysis on those reactions to see pathways enriched when optimized by biomass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2\n",
    "# Transcriptomic data from cell batches / biorreactiors\n",
    "# Overlay this into the recons and extract the reactions associated to the genes\n",
    "# Extract a reaction vector / \n",
    "# Run Flux Enrichment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hypergeom\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "def flux_enrichment_analysis(generic_model, rxn_list, attribute='subsystem'):\n",
    "    \n",
    "    # Check if the attribute exists in the first reaction as a proxy for all\n",
    "    if not hasattr(model.reactions[0], attribute):\n",
    "        raise ValueError(f'Attribute {attribute} not found in model reactions')\n",
    "\n",
    "    # Extract attribute information for all reactions\n",
    "    attribute_values = [getattr(rxn, attribute, 'None') for rxn in model.reactions]\n",
    "    unique_attributes = set(attribute_values)\n",
    "    \n",
    "    # Count occurrences in the model and in the reaction set\n",
    "    model_counts = {attr: attribute_values.count(attr) for attr in unique_attributes}\n",
    "    rxn_set_counts = {attr: 0 for attr in unique_attributes}\n",
    "    for rxn in rxn_list:\n",
    "        rxn_attr = getattr(model.reactions.get_by_id(rxn), attribute, 'None')\n",
    "        rxn_set_counts[rxn_attr] += 1\n",
    "\n",
    "    # Calculate p-values using hypergeometric test\n",
    "    M = len(model.reactions)  # Total number of reactions\n",
    "    n = len(rxn_list)  # Size of reaction set\n",
    "    p_values = []\n",
    "    for attr in unique_attributes:\n",
    "        N = model_counts[attr]  # Total reactions in group\n",
    "        x = rxn_set_counts[attr]  # Reactions in group and in set\n",
    "        p_value = hypergeom.sf(x-1, M, N, n)\n",
    "        p_values.append(p_value)\n",
    "\n",
    "    # Adjust p-values for multiple testing\n",
    "    _, adj_p_values, _, _ = multipletests(p_values, method='fdr_bh')\n",
    "\n",
    "    # Compile results\n",
    "    results = pd.DataFrame({\n",
    "        'Group': list(unique_attributes),\n",
    "        'P-value': p_values,\n",
    "        'Adjusted P-value': adj_p_values,\n",
    "        'Enriched set size': [rxn_set_counts[attr] for attr in unique_attributes],\n",
    "        'Total set size': [model_counts[attr] for attr in unique_attributes],\n",
    "    }).sort_values(by='Adjusted P-value')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: FEA on reactions active during growth rate optimization\n",
    "Use the fluxes from the growth rate calculations to filter reactions with fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate a vector of active reactions for each one of the conditions\n",
    "\n",
    "active_reactions = []\n",
    "\n",
    "for sol in pfba_solutions_fluxes:\n",
    "    rxns_fluxes = []\n",
    "    for n,f in sol['fluxes'].items():\n",
    "        if f != 0:\n",
    "            rxns_fluxes.append(n)\n",
    "    \n",
    "    active_reactions.append({\n",
    "        \"batch\": sol['model'],\n",
    "        \"condition\": sol['condition'],\n",
    "        \"flux_vector\": rxns_fluxes\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load generic model\n",
    "model = load_json_model('iCHO3595_unblocked.json')\n",
    "\n",
    "# Add atp demand reaction\n",
    "DM_atp = Reaction('DM_atp_c')\n",
    "model.add_reactions([DM_atp])\n",
    "model.reactions.DM_atp_c.build_reaction_from_string('atp_c -->')\n",
    "model.reactions.DM_atp_c.bounds = (0.01, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate FEA results for each one of the vectors generated for each condition\n",
    "\n",
    "fea_results = []\n",
    "\n",
    "# Load generic model\n",
    "#model = load_json_model('iCHO3595_unblocked.json')\n",
    "\n",
    "for fluxes in active_reactions:\n",
    "    results = flux_enrichment_analysis(model, fluxes['flux_vector'], 'subsystem')\n",
    "    fea_results.append({\n",
    "        \"Batch\": fluxes['batch'],\n",
    "        \"Condition\": fluxes['condition'],\n",
    "        \"Results\": results\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transform p-values to -log10\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for result in fea_results:\n",
    "    batch = result['Batch']\n",
    "    temp_df = result['Results'][['Group', 'P-value']].copy()\n",
    "    temp_df.columns = ['Group', f'P-value_{batch}']\n",
    "    if all_data.empty:\n",
    "        all_data = temp_df\n",
    "    else:\n",
    "        all_data = pd.merge(all_data, temp_df, on='Group', how='outer')\n",
    "\n",
    "# Remove groups with a 0 value in all conditions (assuming a '0' value indicates non-significance)\n",
    "significant_filter = (all_data.drop(columns='Group') < 0.05).any(axis=1)\n",
    "filtered_data = all_data[significant_filter]\n",
    "filtered_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Transform the p-values\n",
    "for col in filtered_data.columns:\n",
    "    if col.startswith('P-value'):\n",
    "        filtered_data[f'-log10_{col}'] = -np.log10(filtered_data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Extract relevant columns for heatmap\n",
    "heatmap_data = filtered_data[[col for col in filtered_data.columns if col.startswith('-log10')]]\n",
    "\n",
    "# Clean column names\n",
    "heatmap_data.columns = heatmap_data.columns.str.replace(r\"-log10_P-value_\", \"\", regex=True)\n",
    "\n",
    "# Normalize the data (z-score)\n",
    "normalized_data = heatmap_data.apply(zscore, axis=1)\n",
    "\n",
    "# Prepare heatmap data\n",
    "normalized_data.index = filtered_data['Group']\n",
    "\n",
    "# Reorder columns: Group P2, P4, P6, and P8 together\n",
    "columns_order = []\n",
    "for phase in ['P2', 'P4', 'P6', 'P8']:\n",
    "    columns_order.extend([col for col in normalized_data.columns if phase in col])\n",
    "\n",
    "# Reorder the DataFrame\n",
    "normalized_data = normalized_data[columns_order]\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(normalized_data, annot=True, cmap=\"viridis\", cbar_kws={'label': 'Z-score of -log10(P-value)'}, vmin=-1.5, vmax=1.5)\n",
    "plt.title('Heatmap of Z-score Normalized -log10(P-values) Across Conditions', fontsize=20)\n",
    "plt.xlabel('Conditions', fontsize=15)\n",
    "plt.ylabel('Groups', fontsize=15)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../Simulations/flux_enrichment_analysis/FEA_heatmap_all.png', format='png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the columns based on the presence of \"P2 to P4\" or \"P4 to P6\"\n",
    "subset_df = heatmap_data.filter(regex='_P4_|_P6_')\n",
    "\n",
    "# Normalize the data (z-score)\n",
    "normalized_data = subset_df.apply(zscore, axis=1)\n",
    "\n",
    "# Prepare heatmap data\n",
    "normalized_data.index = filtered_data['Group']\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(normalized_data, annot=True, cmap=\"viridis\", cbar_kws={'label': 'Z-score of -log10(P-value)'}, vmin=-1.5, vmax=1.5)\n",
    "plt.title('Heatmap of Z-score Normalized -log10(P-values) Across Conditions', fontsize=20)\n",
    "plt.xlabel('Conditions', fontsize=15)\n",
    "plt.ylabel('Groups', fontsize=15)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../Simulations/flux_enrichment_analysis/FEA_heatmap_p2_p6.png', format='png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
