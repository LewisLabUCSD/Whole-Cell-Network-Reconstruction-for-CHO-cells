{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "907aceed",
   "metadata": {},
   "source": [
    "# Reactions\n",
    "This notebook contains all the steps followed in order to reconcile the existing metabolic reconstruction in CHO cells. It si divided into two parts: **1. Network Reconstruction** and **2. Identification of duplicated reactions**\n",
    "\n",
    "[1. Network Reconstruction](#reconstruction) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1.1 Datasets generation and merge**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1.2 Normalization of the data** <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1.3 Group all the data into a unified dataset** <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1.4 Addition of the Recon3D CHO ortholog GPRs into the reconstruction** <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1.5 Divide the dataset in two to facilitate reading and curation in Google Sheets** <br>\n",
    "\n",
    "[2. Identification of Duplicated Reactions](#duplicated) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**2.1 Retrieve information from the Google Sheet datasets reactions and metabolites**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**2.2 Build a model and feed it the information from the df generated** <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**2.3 Save and validate the model** <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0896294",
   "metadata": {},
   "source": [
    "## 1. Network Reconstruction <a id='reconstruction'></a>\n",
    "These include the generation of datasets (1), normalization of the data (2), merging all four reconstructions into a unified dataset (3), compiling the generated reconstruction into a cobra model in order to identify duplicated reactions (4), fixing duplicated reactions using BiGG ID annotation (5), adding Recon3D GPR information (6), and finally dividing the dataset into two different datasets that will be further curated in Google Sheets (7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450f12c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93ce2b55",
   "metadata": {},
   "source": [
    "### 1.1 Datasets generation and merge\n",
    "Dataset generation from previous reconstructions (CHO_DG44, iCHO1766, iCHO2101, iCHO2291)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f9ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read excel files and create the dfs\n",
    "\n",
    "#Camels CHO_DG44 metabolic reconstruction\n",
    "camel_df = pd.read_excel('../Data/Reconciliation/datasets/CHO_DG44.xlsx', header = 1)\n",
    "\n",
    "#Hefzi's iCHO1766 metabolic reconstruction\n",
    "hefzi_df = pd.read_excel('../Data/Reconciliation/datasets/hefzi_final.xlsx')\n",
    "\n",
    "#Foudaliha's iCHO2101 metabolic reconstruction\n",
    "fouladiha_df = pd.read_excel('../Data/Reconciliation/datasets/iCHO2101.xlsx', 'Supplementary Table 10', header = 1)\n",
    "\n",
    "#Yeo's iCHO2291 metabolic reconstruction\n",
    "iCHO2291 = pd.read_excel('../Data/Reconciliation/datasets/iCHO2291_final.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0eca726",
   "metadata": {},
   "source": [
    "### 1.2 Normalization of the data\n",
    "All dataset are normalized into the same shape and format and then combined into one big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a3124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standarization of the columns names\n",
    "camel_df.rename(columns = {'Reaction ID':'Reaction', 'Initial reaction in model':'Reaction Formula', 'Reaction name':'Reaction Name', 'Justification':'Curation Notes'}, inplace = True)\n",
    "fouladiha_df.rename(columns = {'Abbreviation':'Reaction', 'Description':'Reaction Name', 'Reaction':'Reaction Formula', 'GPR':'GPR_fou'}, inplace = True)\n",
    "\n",
    "# Addition of tag columns for organizational purposes\n",
    "camel_df.insert(loc=0, column='cam', value='X')\n",
    "camel_df.insert(loc=1, column='hef', value=np.nan)\n",
    "camel_df.insert(loc=2, column='fou', value=np.nan)\n",
    "camel_df.insert(loc=3, column='yeo', value=np.nan)\n",
    "\n",
    "hefzi_df.insert(loc=0, column='cam', value=np.nan)\n",
    "hefzi_df.insert(loc=1, column='hef', value='X')\n",
    "hefzi_df.insert(loc=2, column='fou', value=np.nan)\n",
    "hefzi_df.insert(loc=3, column='yeo', value=np.nan)\n",
    "\n",
    "fouladiha_df.insert(loc=0, column='cam', value=np.nan)\n",
    "fouladiha_df.insert(loc=1, column='hef', value=np.nan)\n",
    "fouladiha_df.insert(loc=2, column='fou', value='X')\n",
    "fouladiha_df.insert(loc=3, column='yeo', value=np.nan)\n",
    "\n",
    "iCHO2291.insert(loc=0, column='cam', value=np.nan)\n",
    "iCHO2291.insert(loc=1, column='hef', value=np.nan)\n",
    "iCHO2291.insert(loc=2, column='fou', value=np.nan)\n",
    "iCHO2291.insert(loc=3, column='yeo', value='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a6ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate cols list with the column names from all datasets\n",
    "cols = hefzi_df.columns.to_list()+fouladiha_df.columns.to_list()+iCHO2291.columns.to_list()+camel_df.columns.to_list()\n",
    "\n",
    "# Eliminate repetitive values in the 'cols' list\n",
    "cols = [cols[i] for i in range(len(cols)) if i == cols.index(cols[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_col(df):\n",
    "    '''\n",
    "    This function adds the columns from the cols list \n",
    "    that are not present in the df\n",
    "    '''\n",
    "    df.columns\n",
    "    add_col = []\n",
    "    for col in cols:\n",
    "        if col not in df.columns:\n",
    "            add_col.append(col)\n",
    "    df = df.reindex(columns = df.columns.tolist() + add_col)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify columns for all datasets\n",
    "hefzi_df = add_col(hefzi_df)\n",
    "fouladiha_df = add_col(fouladiha_df)\n",
    "iCHO2291 = add_col(iCHO2291)\n",
    "camel_df = add_col(camel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ec5b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns in all datasets the same way\n",
    "fouladiha_df = fouladiha_df[['cam','hef', 'fou', 'yeo', 'Reaction', 'Reaction Name', 'Reaction Formula', 'GPR_hef','GPR_fou','GPR_yeo', 'Subsystem', 'Genes', 'Protein', 'EC Number', 'Mol wt', 'kcat_forward', 'kcat_backward', 'Reversible','Lower bound', 'Upper bound', 'Objective', 'Curation Notes', 'References', 'Reaction ID Camels Models']]\n",
    "iCHO2291 = iCHO2291[['cam','hef', 'fou', 'yeo', 'Reaction', 'Reaction Name', 'Reaction Formula', 'GPR_hef','GPR_fou','GPR_yeo', 'Subsystem', 'Genes', 'Protein', 'EC Number', 'Mol wt', 'kcat_forward', 'kcat_backward', 'Reversible','Lower bound', 'Upper bound', 'Objective', 'Curation Notes', 'References', 'Reaction ID Camels Models']]\n",
    "hefzi_df = hefzi_df[['cam','hef', 'fou', 'yeo', 'Reaction', 'Reaction Name', 'Reaction Formula', 'GPR_hef','GPR_fou','GPR_yeo', 'Subsystem', 'Genes', 'Protein', 'EC Number', 'Mol wt', 'kcat_forward', 'kcat_backward', 'Reversible','Lower bound', 'Upper bound', 'Objective', 'Curation Notes', 'References', 'Reaction ID Camels Models']]\n",
    "camel_df = camel_df[['cam','hef', 'fou', 'yeo', 'Reaction', 'Reaction Name', 'Reaction Formula', 'GPR_hef','GPR_fou','GPR_yeo', 'Subsystem', 'Genes', 'Protein', 'EC Number', 'Mol wt', 'kcat_forward', 'kcat_backward', 'Reversible','Lower bound', 'Upper bound', 'Objective', 'Curation Notes', 'References', 'Reaction ID Camels Models']]\n",
    "\n",
    "camel_df['Reaction'] = camel_df['Reaction'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203bbe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the dfs into a unified df\n",
    "all_dfs = pd.concat([camel_df, hefzi_df, fouladiha_df, iCHO2291])\n",
    "all_dfs = all_dfs.reset_index(drop = True)\n",
    "\n",
    "#Unify reaction names\n",
    "all_dfs['Reaction'] = all_dfs['Reaction'].str.replace('_cho', '')\n",
    "all_dfs['Reaction'] = all_dfs['Reaction'].str.replace(r\"(e)\", \"_e_\", regex = False)\n",
    "all_dfs['Reaction'] = all_dfs['Reaction'].str.replace(\"[\", \"_\")\n",
    "all_dfs['Reaction'] = all_dfs['Reaction'].str.replace(\"]\", \"_\")\n",
    "\n",
    "all_dfs #20940 rows/reactions (many of them repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044513b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the underscore at the end of some reactions\n",
    "\n",
    "rxns = []\n",
    "idx = []\n",
    "\n",
    "for i,row in all_dfs.iterrows():\n",
    "    if str(row['Reaction']).endswith('_'):\n",
    "        s = re.sub('_$', '', row['Reaction'])\n",
    "        rxns.append(s)\n",
    "        idx.append(i)\n",
    "        \n",
    "all_dfs['Reaction'].update(pd.Series(rxns,index=idx))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8119e796",
   "metadata": {},
   "source": [
    "### 1.3 Group all the data into a unified dataset\n",
    "The combined dataset generated above \"all_dfs\" is grouped by the Reaction BiGG ID to obtain a dataset with unique reaction identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data into a unified dataset\n",
    "\n",
    "all_dfs2 = all_dfs.groupby('Reaction').first()\n",
    "all_dfs2['Reaction Formula'] = all_dfs2['Reaction Formula'].str.replace('[','_')\n",
    "all_dfs2['Reaction Formula'] = all_dfs2['Reaction Formula'].str.replace(']','')\n",
    "all_dfs2['Reaction Formula'] = all_dfs2['Reaction Formula'].str.replace(' => | =>',' --> ')\n",
    "all_dfs2['Reaction Formula'] = all_dfs2['Reaction Formula'].str.replace(' <-- | <--',' <=> ')\n",
    "all_dfs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3861e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Demand Reaccion into a different df and remove from reconstruction. \n",
    "# Keep demand reactions from extracellular space\n",
    "\n",
    "all_dfs2 = all_dfs2.reset_index()\n",
    "demand_reactions = pd.DataFrame(columns = all_dfs2.columns)\n",
    "\n",
    "for index, rxn in all_dfs2.iterrows():\n",
    "    rxn = rxn['Reaction Formula']\n",
    "    a,b = re.split('<=>|-->',rxn)\n",
    "    if (b == '' or b == ' ') and not a.endswith('_e '):\n",
    "        temp_df = all_dfs2[all_dfs2['Reaction Formula'] == rxn]\n",
    "        demand_reactions = pd.concat([demand_reactions,temp_df])\n",
    "        all_dfs2.drop(index, inplace=True)\n",
    "\n",
    "demand_reactions = demand_reactions.reset_index(drop=True)\n",
    "demand_reactions.to_excel('../Data/Reconciliation/datasets/demand_reactions.xlsx')\n",
    "demand_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a3f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs2 = all_dfs2.reset_index(drop=True)\n",
    "all_dfs2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4af7ae59",
   "metadata": {},
   "source": [
    "### 1.4 Addition of the Recon3D CHO ortholog GPRs into the reconstruction\n",
    "The information from the dataset generated in the notebook \"GPR Annotation\" containing all the information from Recon3D GPRS in human and its corresponding CHO orthologs is mapped into our reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19817d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dict with recon3d reactions as keys and the CHO GPRs as values.\n",
    "recon3d = pd.read_excel('../Data/GPR_Curation/recon3D_chogprs.xlsx')\n",
    "recon3d_dict = recon3d.set_index('m_reaction')['CHO GPR'].to_dict()\n",
    "recon3d_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af3bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 'recon3d_dict' into the all_dfs3 dataframe\n",
    "# the reaction IDs should be the same as those in our reconstruction\n",
    "\n",
    "all_dfs3 = all_dfs2.reset_index()\n",
    "all_dfs3['GPR_Recon3D'] = all_dfs3['Reaction'].map(recon3d_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd24a607",
   "metadata": {},
   "source": [
    "### 1.5 Divide the dataset in two to facilitate reading and curation in Google Sheets\n",
    "The dataset all_dfs3 is divided into two different datasets: all_dfs4 contains mainly all the information regarding GPRs assigned from previous reconstructions. all_dfs5 contains the rest of the attributes in the reconstruction such as EC number, bounds, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90db5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_dfs4 contains mainly information of the reactions GPRs\n",
    "all_dfs4 = all_dfs3[['Reaction', 'Reaction Name', 'Reaction Formula', 'Subsystem', 'GPR_hef', 'GPR_fou', 'GPR_yeo', 'GPR_Recon3D', 'Curation Notes', 'References']]\n",
    "all_dfs4.insert(8,'GPR_final', '')\n",
    "all_dfs4.to_excel('../Data/Reconciliation/datasets/all_dfs4.xlsx')\n",
    "all_dfs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65952ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_dfs5 contains information of the rest of the attributes in our reconstruction\n",
    "all_dfs5 = all_dfs3[['Reaction', 'Genes', 'Protein', 'EC Number', 'Mol wt', 'kcat_forward', 'kcat_backward', 'Reversible', 'Lower bound', 'Upper bound', 'Objective']]\n",
    "all_dfs5.to_excel('../Data/Reconciliation/datasets/all_dfs5.xlsx')\n",
    "all_dfs5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb752ef7",
   "metadata": {},
   "source": [
    "## 2. Identifications of Duplicated Reactions <a id='duplicated'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a36be791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from requests_html import HTMLSession\n",
    "from tqdm.notebook import tqdm\n",
    "from cobra import Model, Reaction, Metabolite\n",
    "\n",
    "from utils import duplicated_reactions\n",
    "from google_sheet import GoogleSheet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93bd8ed0",
   "metadata": {},
   "source": [
    "### 2.1 Compile all_df2 dataframe into a cobra model to identify duplicated reactions\n",
    "Generation of a cobra model from the dataset containing the grouped reactions \"all_dfs2\". This model will be used to identify duplicated reactions from the stoichiometric matrix of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a9c0f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the necessary datasets for the identification of the duplicated reactions\n",
    "KEY_FILE_PATH = 'credentials.json'\n",
    "SPREADSHEET_ID_v3 = '1MlBXeHIKw8k8fZyXm-sN__AHTRSunJxar_-bqvukZws'\n",
    "\n",
    "# Initialize the GoogleSheet object\n",
    "sheet = GoogleSheet(SPREADSHEET_ID_v3, KEY_FILE_PATH)\n",
    "\n",
    "# Read data from the Google Sheet\n",
    "sheet_rxns = 'Rxns'\n",
    "sheet_attributes = 'Attributes'\n",
    "\n",
    "reactions = sheet.read_google_sheet(sheet_rxns)\n",
    "rxns_attributes = sheet.read_google_sheet(sheet_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "695479a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-03-24\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_dfs2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miCHOxxxx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m lr \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mall_dfs2\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      5\u001b[0m     r \u001b[38;5;241m=\u001b[39m Reaction(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReaction\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m     lr\u001b[38;5;241m.\u001b[39mappend(r)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_dfs2' is not defined"
     ]
    }
   ],
   "source": [
    "model = Model(\"iCHOxxxx\")\n",
    "lr = []\n",
    "\n",
    "for _, row in all_dfs2.iterrows():\n",
    "    r = Reaction(row['Reaction'])\n",
    "    lr.append(r)\n",
    "    \n",
    "model.add_reactions(lr)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf61fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add reaction formulas\n",
    "for i,r in enumerate(tqdm(model.reactions)):\n",
    "    r.build_reaction_from_string(all_dfs2['Reaction Formula'][i])\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed1849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preview of the model with all its reactions and metabolites\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_reactions = duplicated_reactions(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de801ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of duplicated reactions\n",
    "duplicated_reactions.index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9d684b4",
   "metadata": {},
   "source": [
    "### 5. Fix duplicated reactions in the dataset from the list duplicated_reactions obtained above\n",
    "Duplicated reactions are itereated in a for loop and mapped in the original dataset. A request is made in the \n",
    "BiGG database http://bigg.ucsd.edu with each of the duplicated reactions. If any of the duplicated reactions is in BiGG, the other reaction automatically changes its name to the one located in Bigg. This way we unifiy the names of our reactions to those in BiGG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e94e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs2 = all_dfs2.reset_index()\n",
    "\n",
    "i = 0\n",
    "for rxn in tqdm(duplicated_reactions.index):\n",
    "    \n",
    "    session = HTMLSession()\n",
    "    \n",
    "    response=session.get('http://bigg.ucsd.edu/models/iCHOv1/reactions/'+rxn[0])\n",
    "    if response.status_code == 200:\n",
    "        all_dfs2['Reaction'][all_dfs2['Reaction'] == rxn[1]] = rxn[0]\n",
    "        print(f'1 Reaction {rxn[1]} changed for {rxn[0]} in CHOv1')\n",
    "        i += 1\n",
    "    \n",
    "    elif response.status_code != 200:\n",
    "        response=session.get('http://bigg.ucsd.edu/universal/reactions/'+rxn[0]) \n",
    "        if response.status_code == 200:\n",
    "            all_dfs2['Reaction'][all_dfs2['Reaction'] == rxn[1]] = rxn[0]\n",
    "            print(f'2 Reaction {rxn[1]} changed for {rxn[0]} in Bigg')\n",
    "            i += 1\n",
    "            \n",
    "        elif response.status_code != 200:\n",
    "            response=session.get('http://bigg.ucsd.edu/models/iCHOv1/reactions/'+rxn[1])\n",
    "            if response.status_code == 200:\n",
    "                all_dfs2['Reaction'][all_dfs2['Reaction'] == rxn[0]] = rxn[1]\n",
    "                print(f'3 Reaction {rxn[0]} changed for {rxn[1]} in CHOv1')\n",
    "                i += 1\n",
    "                \n",
    "            elif response.status_code != 200:\n",
    "                response=session.get('http://bigg.ucsd.edu/universal/reactions/'+rxn[1])\n",
    "                if response.status_code == 200:\n",
    "                    all_dfs2['Reaction'][all_dfs2['Reaction'] == rxn[0]] = rxn[1]\n",
    "                    print(f'4 Reaction {rxn[0]} changed for {rxn[1]} in Bigg')\n",
    "                    i += 1\n",
    "                elif response.status_code != 200:\n",
    "                    all_dfs2['Reaction'][all_dfs2['Reaction'] == rxn[1]] = rxn[0]\n",
    "                    print(f'5 Reaction {rxn[0]} changed for {rxn[1]} not present in Bigg DB')\n",
    "                    i += 1\n",
    "\n",
    "print(len(duplicated_reactions))\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_dfs3 a procesed dataset with unique reactions, a combination of the 4 previous reconstructions\n",
    "all_dfs3 = all_dfs2.groupby('Reaction').first()\n",
    "del all_dfs3['index']\n",
    "all_dfs3.to_excel('../Data/Reconciliation/datasets/all_dfs3.xlsx')\n",
    "all_dfs3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "477914c3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8646a57",
   "metadata": {},
   "source": [
    "### 8. Identification and removal of duplicated reactions in the CHO Network + Recon 3D dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84de331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from requests_html import HTMLSession\n",
    "from tqdm.notebook import tqdm\n",
    "from cobra import Model, Reaction, Metabolite\n",
    "\n",
    "from utils import duplicated_reactions\n",
    "from google_sheet import GoogleSheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d2bcdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Name</strong></td>\n",
       "                <td>iCHO</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>15e0bac80</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of metabolites</strong></td>\n",
       "                <td>0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of reactions</strong></td>\n",
       "                <td>10547</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of genes</strong></td>\n",
       "                <td>0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of groups</strong></td>\n",
       "                <td>0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Objective expression</strong></td>\n",
       "                <td>0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Compartments</strong></td>\n",
       "                <td></td>\n",
       "            </tr>\n",
       "          </table>"
      ],
      "text/plain": [
       "<Model iCHO at 0x15e0bac80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### ----- Create a model from the reactions sheet ----- #####\n",
    "model = Model(\"iCHO\")\n",
    "lr = []\n",
    "for _, row in reactions.iterrows():\n",
    "    r = Reaction(row['Reaction'])\n",
    "    lr.append(r)    \n",
    "model.add_reactions(lr)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00893fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- Add information to each one of the reactions ----- #####\n",
    "for i,r in enumerate(tqdm(model.reactions)):\n",
    "    print(r.id)\n",
    "    r.build_reaction_from_string(reactions['Reaction Formula'][i])\n",
    "    r.name = reactions['Reaction Name'][i]\n",
    "    r.subsystem = reactions['Subsystem'][i]\n",
    "    r.lower_bound = float(rxns_attributes['Lower bound'][i])\n",
    "    r.upper_bound = float(rxns_attributes['Upper bound'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "442ff757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 158, 4455],\n",
       "       [1745, 2263],\n",
       "       [2141, 2143],\n",
       "       [3164, 9094],\n",
       "       [3269, 7616],\n",
       "       [3305, 9208],\n",
       "       [5198, 8822],\n",
       "       [6548, 9122],\n",
       "       [7802, 7803],\n",
       "       [8917, 9365],\n",
       "       [9021, 9537],\n",
       "       [9027, 9541]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_reactions = duplicated_reactions(model)\n",
    "duplicated_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e3cae52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1cb651e9d544daa8d9d19f402a82048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Reaction 3HAD240p changed for HMR_3063 present BiGG database\n",
      "4 Reaction DECR101n6p changed for FAOXC102C101x present BiGG database\n",
      "1 Reaction FA182ACPH changed for FA1821ACPH present in CHOv1 model\n",
      "2 Reaction GTPDH changed for r0120 present in CHOv1 model\n",
      "2 Reaction HACD181 changed for RE3243R present in CHOv1 model\n",
      "2 Reaction HCARNS changed for r0465 present in CHOv1 model\n",
      "4 Reaction HMR_9734 changed for TYRDHINDOX present BiGG database\n",
      "2 Reaction PPADCOAL changed for r0220 present in CHOv1 model\n",
      "1 Reaction RE3492C changed for RE3491C present in CHOv1 model\n",
      "2 Reaction UPPDC2 changed for r0774 present in CHOv1 model\n",
      "2 Reaction XOLEST182CEH changed for r1180 present in CHOv1 model\n",
      "2 Reaction XOLEST204CEH changed for r1184 present in CHOv1 model\n",
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for rxn in tqdm(duplicated_reactions):\n",
    "    \n",
    "    session = HTMLSession()\n",
    "    \n",
    "    response=session.get('http://bigg.ucsd.edu/models/iCHOv1/reactions/'+reactions['Reaction'][rxn[0]])\n",
    "    if response.status_code == 200:\n",
    "        if reactions['Reaction'][rxn[0]] == rxns_attributes['Reaction'][rxn[0]] and reactions.loc[rxn[1], 'Reaction'] == rxns_attributes.loc[rxn[1], 'Reaction']:\n",
    "            print(f'1 Reaction {reactions.iloc[rxn[1],1]} changed for {reactions.iloc[rxn[0],1]} present in CHOv1 model')\n",
    "            reactions.loc[rxn[1], 'Reaction'] = reactions['Reaction'][rxn[0]]\n",
    "            rxns_attributes.loc[rxn[1], 'Reaction'] = rxns_attributes['Reaction'][rxn[0]]\n",
    "            i += 1\n",
    "    \n",
    "    elif response.status_code != 200:\n",
    "        response=session.get('http://bigg.ucsd.edu/models/iCHOv1/reactions/'+reactions['Reaction'][rxn[1]])\n",
    "        if response.status_code == 200:\n",
    "            if reactions['Reaction'][rxn[0]] == rxns_attributes['Reaction'][rxn[0]] and reactions.loc[rxn[1], 'Reaction'] == rxns_attributes.loc[rxn[1], 'Reaction']:\n",
    "                print(f'2 Reaction {reactions.iloc[rxn[0],1]} changed for {reactions.iloc[rxn[1],1]} present in CHOv1 model')\n",
    "                reactions.loc[rxn[0], 'Reaction'] = reactions['Reaction'][rxn[1]]\n",
    "                rxns_attributes.loc[rxn[0], 'Reaction'] = rxns_attributes['Reaction'][rxn[1]]\n",
    "                i += 1\n",
    "            \n",
    "        elif response.status_code != 200:\n",
    "            response=session.get('http://bigg.ucsd.edu/universal/reactions/'+reactions['Reaction'][rxn[0]])\n",
    "            if response.status_code == 200:\n",
    "                if reactions['Reaction'][rxn[0]] == rxns_attributes['Reaction'][rxn[0]] and reactions.loc[rxn[1], 'Reaction'] == rxns_attributes.loc[rxn[1], 'Reaction']:\n",
    "                    print(f'3 Reaction {reactions.iloc[rxn[1],1]} changed for {reactions.iloc[rxn[0],1]} present BiGG database')\n",
    "                    reactions.loc[rxn[1], 'Reaction'] = reactions['Reaction'][rxn[0]]\n",
    "                    rxns_attributes.loc[rxn[1], 'Reaction'] = rxns_attributes['Reaction'][rxn[0]]\n",
    "                    i += 1\n",
    "                \n",
    "            elif response.status_code != 200:\n",
    "                response=session.get('http://bigg.ucsd.edu/universal/reactions/'+reactions['Reaction'][rxn[1]])\n",
    "                if response.status_code == 200:\n",
    "                    if reactions['Reaction'][rxn[0]] == rxns_attributes['Reaction'][rxn[0]] and reactions.loc[rxn[1], 'Reaction'] == rxns_attributes.loc[rxn[1], 'Reaction']:\n",
    "                        print(f'4 Reaction {reactions.iloc[rxn[0],1]} changed for {reactions.iloc[rxn[1],1]} present BiGG database')\n",
    "                        reactions.loc[rxn[0], 'Reaction'] = reactions['Reaction'][rxn[1]]\n",
    "                        rxns_attributes.loc[rxn[0], 'Reaction'] = rxns_attributes['Reaction'][rxn[1]]\n",
    "                        i += 1\n",
    "                elif response.status_code != 200:\n",
    "                    if reactions['Reaction'][rxn[0]] == rxns_attributes['Reaction'][rxn[0]] and reactions.loc[rxn[1], 'Reaction'] == rxns_attributes.loc[rxn[1], 'Reaction']:\n",
    "                        print(f'5 Reaction {reactions.iloc[rxn[1],1]} changed for {reactions.iloc[rxn[0],1]} not present in Bigg DB')\n",
    "                        reactions.loc[rxn[1], 'Reaction'] = reactions['Reaction'][rxn[0]]\n",
    "                        rxns_attributes.loc[rxn[1], 'Reaction'] = rxns_attributes['Reaction'][rxn[0]]\n",
    "                        i += 1\n",
    "\n",
    "print(len(duplicated_reactions))\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f770d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the original column order\n",
    "column_order_rxns = reactions.columns.tolist()\n",
    "column_order_att = rxns_attributes.columns.tolist()\n",
    "\n",
    "# Group by 'BiGG ID' and keep the first non-null value in each group, then reset the index\n",
    "reactions = reactions.groupby('Reaction').first().reset_index()\n",
    "rxns_attributes = rxns_attributes.groupby('Reaction').first().reset_index()\n",
    "\n",
    "# Rearrange the columns to the original order\n",
    "reactions = reactions[column_order_rxns]\n",
    "rxns_attributes = rxns_attributes[column_order_att]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86b641c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Sheet updated.\n"
     ]
    }
   ],
   "source": [
    "# Update the Google Sheet with the modified DataFrame\n",
    "sheet.update_google_sheet(sheet_rxns, reactions)\n",
    "sheet.update_google_sheet(sheet_attributes, rxns_attributes)\n",
    "print(\"Google Sheet updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a101d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reaction IDs in the Rxns and Attributes Sheets are equal\n",
      "\n",
      "Reaction Formulas in the Rxns and Attributes Sheets are equal\n"
     ]
    }
   ],
   "source": [
    "# Check that Reactions IDs and formulas are equal in \"Rxns\" and \"Attributes\" sheets\n",
    "reactions = sheet.read_google_sheet(sheet_rxns)\n",
    "rxns_attributes = sheet.read_google_sheet(sheet_attributes)\n",
    "\n",
    "rxnsIDseq = list(reactions['Reaction']) == list(rxns_attributes['Reaction'])\n",
    "if rxnsIDseq:\n",
    "    print('Reaction IDs in the Rxns and Attributes Sheets are equal\\n')\n",
    "else:\n",
    "    rxns_sheet_ids = set(list(reactions['Reaction']))\n",
    "    attr_sheet_ids = set(list(rxns_attributes['Reaction']))\n",
    "    print(f'Reaction IDs that are in Rxns Sheet and not in Attributes Sheet {rxns_sheet_forms - attr_sheet_forms}\\n')\n",
    "    print(f'Reaction IDs that are in Attributes Sheet and not in Rxns Sheet {attr_sheet_forms - rxns_sheet_forms}\\n')\n",
    "\n",
    "rxnsforseq = list(reactions['Reaction Formula']) == list(rxns_attributes['Reaction Formula'])\n",
    "if rxnsforseq:\n",
    "    print('Reaction Formulas in the Rxns and Attributes Sheets are equal')\n",
    "else:\n",
    "    rxns_sheet_forms = set(list(reactions['Reaction Formula']))\n",
    "    attr_sheet_forms = set(list(rxns_attributes['Reaction Formula']))\n",
    "    print(f'Reaction formulas that are in Rxns Sheet and not in Attributes Sheet {rxns_sheet_forms - attr_sheet_forms}\\n')\n",
    "    print(f'Reaction formulas that are in Attributes Sheet and not in Rxns Sheet {attr_sheet_forms - rxns_sheet_forms}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35881c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67192b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe6c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0225749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09b8c7aa",
   "metadata": {},
   "source": [
    "## Divide into compartments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb6d64f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobra.io import load_json_model\n",
    "import pandas as pd\n",
    "\n",
    "# model = read_sbml_model('iCHOv3_CHO_05072023.xml')\n",
    "model = load_json_model('iCHOv3_CHO_05072023.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13461d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subsystems: 137\n"
     ]
    }
   ],
   "source": [
    "subsystem_list = []\n",
    "for r in model.reactions:\n",
    "    subsystem_list.append(r.subsystem)\n",
    "print(\"Number of unique subsystems:\", len(set(subsystem_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f46553ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subsystem</th>\n",
       "      <th>RXN Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>AMINO ACID DERIVATIVE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>ASCORBATE AND ALDARATE METABOLISM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>VITAMIN K METABOLISM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>NUCLEOTIDE SUGAR METABOLISM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>PENTOSE AND GLUCURONATE INTERCONVERSIONS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>PROTEIN ASSEMBLY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>COENZYME B BIOSYNTHESIS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>BIOMASS AND MAINTENANCE FUNCTIONS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Subsystem  RXN Counts\n",
       "129                     AMINO ACID DERIVATIVE           1\n",
       "130         ASCORBATE AND ALDARATE METABOLISM           1\n",
       "131                      VITAMIN K METABOLISM           1\n",
       "132               NUCLEOTIDE SUGAR METABOLISM           1\n",
       "133  PENTOSE AND GLUCURONATE INTERCONVERSIONS           1\n",
       "134                          PROTEIN ASSEMBLY           1\n",
       "135                   COENZYME B BIOSYNTHESIS           1\n",
       "136         BIOMASS AND MAINTENANCE FUNCTIONS           1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsystem_counts = pd.Series(subsystem_list).value_counts().reset_index()\n",
    "subsystem_counts.columns = ['Subsystem', 'RXN Counts']\n",
    "subsystem_counts[subsystem_counts['RXN Counts'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24e5419c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CYP2R1: h_c + nadph_c + o2_c + vitd3_c --> 25hvitd3_c + h2o_c + nadp_c\n"
     ]
    }
   ],
   "source": [
    "# TODO -Remove blocked reactions from packages\n",
    "#      -Define the high-importance reactions for biomass production\n",
    "#      -Rename subsystems with very few reactions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
